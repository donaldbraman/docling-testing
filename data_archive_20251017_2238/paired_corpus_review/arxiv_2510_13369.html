<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market</title>
<!--Generated on Wed Oct 15 09:55:39 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="/static/browse/0.3.4/css/arxiv-html-papers-20250916.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2510.13369v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S1" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S2" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Task-Based Frameworks, Automation, and AI: A Review</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S2.SS1" title="In 2 Task-Based Frameworks, Automation, and AI: A Review ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Methodologies</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S2.SS2" title="In 2 Task-Based Frameworks, Automation, and AI: A Review ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Evidence of Labor Market Effects of automation exposure</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S3" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Outlook Toward Generative AI and Early-Career Unemployment</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S3.SS1" title="In 3 Outlook Toward Generative AI and Early-Career Unemployment ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Recent Research on the Labor Market Effects of Generative AI</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S3.SS2" title="In 3 Outlook Toward Generative AI and Early-Career Unemployment ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Recent Research on Early Career Unemployment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S3.SS3" title="In 3 Outlook Toward Generative AI and Early-Career Unemployment ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Theoretical-Based Outlook Toward the Future of Work</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S4" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S4.SS1" title="In 4 Methodology ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Theory</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S4.SS2" title="In 4 Methodology ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S4.SS3" title="In 4 Methodology ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Prompting and Weighting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S4.SS4" title="In 4 Methodology ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Aggregation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S5" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S5.SS1" title="In 5 Results ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Summary Statistics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S5.SS2" title="In 5 Results ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Wages and Employment</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S6" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Validation of Index</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S6.SS1" title="In 6 Validation of Index ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Comparison to Earlier Efforts</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S6.SS2" title="In 6 Validation of Index ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Comparison between models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S6.SS3" title="In 6 Validation of Index ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Validation of Theory</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S7" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S7.SS1" title="In 7 Discussion ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Validity of Methodology</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S7.SS2" title="In 7 Discussion ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Tacit Knowledge and Early-Career Unemployment</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S8" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<div class="ltx_titlepage">
<div class="ltx_block">
<p class="ltx_p ltx_align_center"><span class="ltx_text" style="font-size:173%;">Cambridge ERA AI Governance Research Fellowship
<br class="ltx_break"/></span></p>
<span class="ltx_rule ltx_align_center" style="width:345.0pt;height:1.5pt;--ltx-bg-color:black;display:inline-block;"> </span>
<p class="ltx_p ltx_align_center"><span class="ltx_text ltx_font_bold" style="font-size:173%;">A theory-based AI automation exposure index:
<br class="ltx_break"/>Applying Moravec’s Paradox to the US labor market <span class="ltx_text ltx_font_medium">
<span class="ltx_rule" style="width:345.0pt;height:1.5pt;--ltx-bg-color:black;display:inline-block;"> </span></span></span></p>
<p class="ltx_p ltx_align_center"><span class="ltx_text" style="font-size:120%;">Mentor: Herbie Bradley
<br class="ltx_break"/>Research Manager: Nandini Shiralkar
<br class="ltx_break"/></span></p>
<p class="ltx_p ltx_align_center"><span class="ltx_text ltx_font_bold" style="font-size:144%;">Jacob Schaal<span class="ltx_text ltx_font_medium">
<br class="ltx_break"/><span class="ltx_text" style="font-size:83%;">London School of Economics
<br class="ltx_break"/></span></span></span></p>
<p class="ltx_p ltx_align_center"><span class="ltx_text ltx_font_bold" style="font-size:120%;">Abstract:<span class="ltx_text ltx_font_medium">
<br class="ltx_break"/>This paper develops a theory-driven automation exposure index based on Moravec’s Paradox. Scoring 19,000 O*NET tasks on performance variance, tacit knowledge, data abundance, and algorithmic gaps reveals that management, STEM, and sciences occupations show the highest exposure. In contrast, maintenance, agriculture, and construction show the lowest. The positive relationship between wages and exposure challenges the notion of skill-biased technological change if AI substitutes for workers. At the same time, tacit knowledge exhibits a positive relationship with wages consistent with seniority-biased technological change. This index identifies fundamental automatability rather than current capabilities, while also validating the AI annotation method pioneered by <cite class="ltx_cite ltx_citemacro_citet">Eloundou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib13" title="">2024</a>)</cite> with a correlation of 0.72. The non-positive relationship with pre-LLM indices suggests a paradigm shift in automation patterns.</span></span></p>
</div>
</div>
<nav class="ltx_TOC ltx_list_toc ltx_toc_toc"><h6 class="ltx_title ltx_title_contents">Contents</h6>
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S1" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S2" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Task-Based Frameworks, Automation, and AI: A Review</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S2.SS1" title="In 2 Task-Based Frameworks, Automation, and AI: A Review ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Methodologies</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S2.SS2" title="In 2 Task-Based Frameworks, Automation, and AI: A Review ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Evidence of Labor Market Effects of automation exposure</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S3" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Outlook Toward Generative AI and Early-Career Unemployment</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S3.SS1" title="In 3 Outlook Toward Generative AI and Early-Career Unemployment ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Recent Research on the Labor Market Effects of Generative AI</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S3.SS2" title="In 3 Outlook Toward Generative AI and Early-Career Unemployment ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Recent Research on Early Career Unemployment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S3.SS3" title="In 3 Outlook Toward Generative AI and Early-Career Unemployment ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Theoretical-Based Outlook Toward the Future of Work</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S4" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S4.SS1" title="In 4 Methodology ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Theory</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S4.SS2" title="In 4 Methodology ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S4.SS3" title="In 4 Methodology ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Prompting and Weighting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S4.SS4" title="In 4 Methodology ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Aggregation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S5" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S5.SS1" title="In 5 Results ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Summary Statistics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S5.SS2" title="In 5 Results ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Wages and Employment</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S6" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Validation of Index</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S6.SS1" title="In 6 Validation of Index ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Comparison to Earlier Efforts</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S6.SS2" title="In 6 Validation of Index ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Comparison between models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S6.SS3" title="In 6 Validation of Index ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Validation of Theory</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S7" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S7.SS1" title="In 7 Discussion ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Validity of Methodology</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S7.SS2" title="In 7 Discussion ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Tacit Knowledge and Early-Career Unemployment</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S8" title="In A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Conclusion</span></a></li>
</ol></nav>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p">The labor market effects of artificial intelligence (AI) have entered mainstream discussion recently: For instance, the Financial Times asked in a headline: "Is AI killing graduate jobs?" <cite class="ltx_cite ltx_citemacro_citep">(Murray et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib28" title="">2025</a>)</cite> On the other hand, automation has affected the labor market for decades, and AI remains particularly weak in some domains that are easy for humans, which is called Moravec’s Paradox <cite class="ltx_cite ltx_citemacro_citep">(Moravec, <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib27" title="">1988</a>)</cite>.

<br class="ltx_break"/>I introduce a theory-based index using this paradox. Evolutionary optimization could explain this (Erdil, 2024), as functions that are perceived as difficult for humans have high variance in human performance, likely because they were developed late in evolution, such as mathematics or coding. For instance, AlphaGo beat the world’s best Go Player Lee Sedol in 2016 which is a highly strategic and complex board game. On the other hand, physical and somatosensory skills exhibit low variance among (non-disabled) people. Additional theoretical reasons are data abundance, tacit knowledge, and the algorithmic efficiency gap. <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>All annotated task-level and occupation-level exposure scores are available at <a class="ltx_ref ltx_href" href="https://bit.ly/4pguKNd" title="">https://bit.ly/4pguKNd</a></span></span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p">First, tasks with more digital training data are more manageable for AIs to perform. Second, some tasks require a lot of tacit knowledge, which is sometimes referred to as Polanyi’s Paradox <cite class="ltx_cite ltx_citemacro_citep">(Autor, <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib3" title="">2014</a>)</cite>. The algorithmic efficiency gap relates to the ways in which the brain has naturally evolved for specific tasks, in contrast to neural networks that have a different architecture, such as visual segmentation or sensorimotor control.
Current AI automation indices disagree by over 70%.<cite class="ltx_cite ltx_citemacro_cite">Webb (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib34" title="">2019</a>)</cite>’s patents correlate only 0.31 with Felten’s benchmarks <cite class="ltx_cite ltx_citemacro_citep">(Felten et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib15" title="">2021a</a>)</cite>.
My theory-based approach reveals a striking pattern: management and STEM occupations exhibit the highest exposure to automation. At the same time, maintenance and construction workers face the lowest risk, suggesting that AI may reduce rather than exacerbate wage inequality. This is consistent with the majority of current empirical studies (e.g. <cite class="ltx_cite ltx_citemacro_citet">Noy and Zhang (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib29" title="">2023</a>)</cite>, at least within occupation).
In general, existing AI automation exposure indices rely on current capabilities, whether they’re task feature analyses, patent mapping, or expert surveys, and don’t address general automatizability. This limits the usefulness of these indices. Older indices are hardly related to newer ones (e.g., post-LLM), which raises doubts about the entire research area.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p">My contribution includes two substantive findings and one methodological validation. First, I present a theory-based automation index, rather than one based on current technological capabilities, which offers predictions that may remain stable as AI advances. Second, I demonstrate that tacit knowledge, which exhibits a unique positive relationship with wages while being negatively correlated with my other theoretical dimensions, aligns with recent evidence of seniority-biased technological change, where early-career workers face disproportionate displacement.
Methodologically, I validate that the AI annotation approach is remarkably robust. Despite using a completely different prompt than Eloundou et al. (2024), I achieve a correlation of 0.72 with their results, and inter-model correlations exceed 0.8 for reasoning models. This demonstrates the robustness of the AI annotation method.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p">This working paper proceeds as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p">Chapter <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S2" title="2 Task-Based Frameworks, Automation, and AI: A Review ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_tag">2</span></a> reviews the literature</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p">Chapter <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S3" title="3 Outlook Toward Generative AI and Early-Career Unemployment ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_tag">3</span></a> overviews recent literature on the effects of generative AI, especially on early-career workers, followed by a brief theoretical outlook</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p">Chapter <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S4" title="4 Methodology ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_tag">4</span></a> explains the theory and empirical methodology</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p">Chapter <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S5" title="5 Results ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_tag">5</span></a> presents the results</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i5.p1">
<p class="ltx_p">Chapter <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S7" title="7 Discussion ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_tag">7</span></a> discusses the approach and the results</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i6.p1">
<p class="ltx_p">Chapter <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#S8" title="8 Conclusion ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_tag">8</span></a> concludes</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Task-Based Frameworks, Automation, and AI: A Review</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p">The relationship between artificial intelligence and unemployment has become a heated topic in economic discourse. AI, as well as other forms of automation, both destroy and create jobs. This overview examines how various methodologies attempt to understand AI’s potentially transformative role.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Methodologies</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p">The literature reveals three broad methodologies to predict or explain automation: Task patent mapping (e.g., <cite class="ltx_cite ltx_citemacro_cite">Webb (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib34" title="">2019</a>)</cite>), — at least for predictions— automation forecasting surveys (e.g., <cite class="ltx_cite ltx_citemacro_cite">Gruetzemacher et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib19" title="">2020</a>)</cite>), and task feature analysis <cite class="ltx_cite ltx_citemacro_citep">(Autor, <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib6" title="">2013</a>)</cite>. I harness the latter approach since it is the most common and empirically sound in the literature. It allows for fine-grained analysis of the specific activities a worker performs, typically in a job.
One of the core challenges for the two task-based methods is the difficulty in capturing the nuanced interplay between AI, task structure, and the human workforce. AI’s impact on the labor market is not uniform; it varies across industries, job types, and tasks. Task-based approaches do not carefully distinguish between the full and partial automation within jobs and the deskilling of specific jobs due to a shift towards "less-skilled" tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p2">
<p class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">Webb (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib34" title="">2019</a>)</cite> introduces an innovative approach, employing text analysis to measure the exposure of job tasks to automation technologies. By comparing job task descriptions with patent texts, Webb’s method can predict which occupations are more likely to be affected by new technologies, such as AI. This approach directly links technological advancements with their potential impacts on specific job tasks. AI exposure is also strongly correlated with the average wage in a particular occupation. Webb’s findings suggest that, unlike previous automation technologies, AI primarily targets high-skilled tasks, which may reduce wage inequality, except for the highest earners. This seems prescientific, given the latest evidence discussed later about generative AI (e.g., <cite class="ltx_cite ltx_citemacro_cite">Noy and Zhang (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib29" title="">2023</a>)</cite>).

<br class="ltx_break"/>In contrast, <cite class="ltx_cite ltx_citemacro_cite">Gruetzemacher et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib19" title="">2020</a>)</cite> presents a survey-based study focusing on AI’s potential for extreme labor displacement. The survey, conducted among AI conference attendees in 2018, reveals that practitioners expect a significant portion of current human tasks to be automated by AI in the near and mid-term. The median prediction suggests that 60% of tasks are completed within ten years. More strikingly, there’s a forecasted 50% probability of AI systems being able to automate 90% of human tasks within 25 years and 99% within 50 years. The study seems relevant for more long-term and speculative predictions about job losses due to AI. Still, a consensus among computer scientists only tells so much about the labor market. I prefer an approach immediately grounded in labor market data, which does not require faith in expert predictions.

<br class="ltx_break"/>Therefore, I take a more conceptual and standard route with the task feature analysis, which is described by <cite class="ltx_cite ltx_citemacro_cite">Autor (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib6" title="">2013</a>)</cite>. This approach shifts the focus to the specific tasks that labor and capital perform. Autor argues that changes in allocating these tasks, influenced by technological advancements and globalization, have led to a restructuring of labor demand. This restructuring, which took the form of labor market polarization over the last decades, manifests as increased demand for high-skill and low-skill jobs coupled with a decline in middle-skill jobs <cite class="ltx_cite ltx_citemacro_citep">(Autor and Dorn, <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib7" title="">2013</a>)</cite>. The task approach provides a framework to understand how AI and automation may reallocate tasks, reshaping job structures and wage patterns. AI annotation, in particular, is a valuable method for systematically analyzing the features of a wide range of tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p3">
<p class="ltx_p">A recent method for analyzing the effect of AI on tasks is AI annotation, as pioneered by Eloundou et al. (2024). They annotate the O*NET task database via GPT-4 and human annotators to get automation scores for over 19,000 tasks. Their preferred exposure metric measures whether the adoption of GPT-4 would potentially lead to a 50% time reduction.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p4">
<p class="ltx_p">GPT-4 and humans rate the skills of large language models (LLMs) as surprisingly similar, illustrating the expansion of tasks that AI can achieve. According to the working paper, 80% of the US workforce will be affected by AI in their work life, with 19% experiencing that at least half of their functions are impacted.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p5">
<p class="ltx_p">The relevance of this exposure index for AI usage has been confirmed using large-scale Bing Copilot data, with correlation factors exceeding 0.7 <cite class="ltx_cite ltx_citemacro_citep">(Tomlinson et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib32" title="">2025</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p6">
<p class="ltx_p">Their approach inspires mine and follows their methodology, but is theoretically grounded in multiple theories and doesn’t depend on current capabilities. On the other hand, it doesn’t follow for precise categorization based on time savings or tool usage.

<br class="ltx_break"/>The methodologies employed by <cite class="ltx_cite ltx_citemacro_cite">Webb (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib34" title="">2019</a>)</cite>, <cite class="ltx_cite ltx_citemacro_cite">Gruetzemacher et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib19" title="">2020</a>)</cite>, and <cite class="ltx_cite ltx_citemacro_cite">Autor (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib6" title="">2013</a>)</cite> illustrate the multifaceted challenges in predicting and understanding AI’s impact on the labor market. These studies highlight the need for nuanced, context-specific approaches to understanding the complex dynamics of AI-driven labor market transformations. These methods differ significantly in which jobs are most exposed to AI. The ongoing debate on AI’s role in job displacement versus job creation continues to evolve, reflecting the rapid advancements in AI technologies and their diverse applications in the labor market. As I will discuss later, labor economists’ methods are also in danger of becoming obsolete by AI progress <cite class="ltx_cite ltx_citemacro_citep">(Felten et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib17" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Evidence of Labor Market Effects of automation exposure</h3>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">Acemoglu and Restrepo (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib2" title="">2020</a>)</cite> finds adverse effects of robots on wages and employment. <cite class="ltx_cite ltx_citemacro_cite">Brynjolfsson et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib11" title="">2018</a>)</cite> analyzes the labor market impact of machine learning, while <cite class="ltx_cite ltx_citemacro_cite">Restrepo (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib31" title="">2023</a>)</cite> comprehensively surveys the existing automation literature. <cite class="ltx_cite ltx_citemacro_cite">Autor (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib4" title="">2024</a>)</cite>hypothesizes that AI differs from robots and that this might cause wage polarization to reverse.

<br class="ltx_break"/><cite class="ltx_cite ltx_citemacro_cite">Acemoglu and Restrepo (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib2" title="">2020</a>)</cite> examine the impact of industrial robots on US labor markets. It theorizes that robots may decrease employment and wages, with their local impacts being estimable through exposure variation to robots, defined by industry-level advances in robotics and local industry employment. The study finds robust adverse effects of robots on employment and wages across commuting zones. It differentiates the impact of robots from other capital and technologies, showing that one robot per thousand workers reduces the employment-to-population ratio by 0.2 percentage points and wages by 0.42%.
Unlike prior research that often focused on task automation, Acemoglu and Restrepo provide a nuanced analysis of job automation. However, the potential difference in the nature of robots (tangible, rivalrous assets) compared to AI algorithms (intangible, non-rivalrous) remains a limitation of the external validity. Therefore, AI might affect wages and unemployment differently from robots. This distinction is crucial in avoiding false analogies about the effects of AI on the labor market.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">Brynjolfsson et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib11" title="">2018</a>)</cite> comprehensively analyzes tasks affected by machine learning (ML), closely related to AI. The study assesses the "Suitability for Machine Learning" (SML) of various functions in the O*NET database, which contains occupational skills from the US Department of Labor, providing the background for my analysis. In contrast, earlier research relied on expert predictions regarding the automatizability of tasks. They reveal that ML impacts different occupations than earlier waves of automation, with most jobs comprising at least some SML tasks. The key findings include that few occupations are fully automatable using ML, and realizing ML’s potential usually requires redesigning job task content.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p3">
<p class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">Restrepo (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib31" title="">2023</a>)</cite> comprehensively surveys existing literature on the impact of automation on labor markets. The paper compiles and synthesizes diverse research findings, shedding light on the multifaceted nature of automation’s impact. Restrepo pays particular attention to task-based models and their implications in understanding how automation influences job displacement. This review stands out for its breadth, covering various methodologies and empirical evidence that collectively depict a nuanced picture of automation’s role in reshaping labor dynamics. The paper highlights the complexities involved in evaluating the impact of automation and AI on employment, wages, and task allocation within the labor market. He concludes with a section on AI by separating generative AI from other technologies and calling for future research on the developing topic.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p4">
<p class="ltx_p">Autor (2024) hypothesizes that AI could reverse wage polarization in recent decades. It enhances the expertise of ordinary workers and enables a broader segment of the labor market to process information for critical decisions. Higher AI exposure for high-wage jobs is in line with this hypothesis.
Reflecting on these insightful works, it is clear that the AI revolution presents a paradox. On one hand, there is an undeniable potential for AI to catalyze unprecedented productivity growth <cite class="ltx_cite ltx_citemacro_citep">(Trammell and Korinek, <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib33" title="">2023</a>)</cite>. On the other hand, this technological leap forward presents significant challenges, including labor displacement and widening inequality. Collectively, these papers highlight the uniqueness and transformative power of AI, the importance of focusing on technology-specific exposure indices, and the need for ongoing observation of the labor market by policymakers.
As I will show now for generative AI, the distributional effects of innovation shift rapidly depending on the underlying technology.
</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Outlook Toward Generative AI and Early-Career Unemployment</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Recent Research on the Labor Market Effects of Generative AI</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p">Following the release of ChatGPT in November 2022, this form of AI has impacted the labor market in a manner that prior automation indices had hardly predicted. To gain an accurate understanding of AI’s current and potential future effects on wages and unemployment, examining the most up-to-date research is indispensable. Some experiments empirically evaluate AI’s short-term effects and mostly find more negative effects for higher-educated workers (<cite class="ltx_cite ltx_citemacro_cite">Noy and Zhang (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib29" title="">2023</a>)</cite>; <cite class="ltx_cite ltx_citemacro_cite">Hui et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib21" title="">2023</a>)</cite>). The last few years after the pandemic have been characterized by a hot labor market, drastically reducing wage inequalities <cite class="ltx_cite ltx_citemacro_citep">(Autor et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib5" title="">2023</a>)</cite>. A cautious note that encapsulates the early stage of the literature comes from <cite class="ltx_cite ltx_citemacro_cite">Otis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib30" title="">2023</a>)</cite>, whose randomized controlled trial showed that a GPT4-powered chatbot increased the wage differential between Kenyan entrepreneurs.

<br class="ltx_break"/><cite class="ltx_cite ltx_citemacro_cite">Noy and Zhang (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib29" title="">2023</a>)</cite> expose their experiment participants to writing tasks specified for their jobs. They measure the time taken, output quality, and job satisfaction. The treatment group has the opportunity to revise their writing based on feedback from ChatGPT. This raises productivity by reducing the necessary time by 0.8 standard deviations, while improving the quality of the text by 0.4 standard deviations. These are rather large effect sizes, but they are only measured on specific tasks and have only short-term effects. These findings are consistent with <cite class="ltx_cite ltx_citemacro_cite">Hui et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib21" title="">2023</a>)</cite>, who find that freelancers’ quality mediates the impact of AI, with higher-skilled freelancers on the Upwork platform being more affected.
Nonetheless, they found that the introduction of ChatGPT in November 2022 had harmful effects on the wages and employment of freelancers. Workers in the most affected occupations experience highly significant reductions of 2% in orders and 5% in wages. Whether these effects persist over the long term and how AI impacts the overall welfare of all stakeholders remains an interesting area for future research.
Since the annotators do not stem from diverse backgrounds of workers, subjectivity and limited experience curb the quality of the labeling. How these changes in task performance alter various industries and nations remains equally relevant for future research in analyzing the limitations of LLMs for labor. Nonetheless, the perspective of AI as a general-purpose technology remains convincing.

<br class="ltx_break"/>This technology impacts a tight labor market: Labor is highly sought after, which led to solid wage rises since the pandemic, especially for low-skilled workers <cite class="ltx_cite ltx_citemacro_citep">(Autor et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib5" title="">2023</a>)</cite>. Consequently, the rise in wage inequality over the last four decades could be reversed by a third over three years. Although this wasn’t the result of AI, the first results consistently hint at a future decline in the college wage premium. A good indicator that the state of the labor market causes wage increases is the concentration of these increases among job-changing workers, or technically speaking, among workers with high labor supply elasticity. Therefore, the strong labor market gave workers more bargaining power, which they utilized by increasing their quit elasticity. In general, the labor market is in the hottest state in decades, underlining the fortunate timing of AI <cite class="ltx_cite ltx_citemacro_citep">(Autor et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib5" title="">2023</a>)</cite>. On the other hand, wage increases also provide more substantial incentives for more automation. The focus of the following subsection will be how this will play out over the longer term.

<br class="ltx_break"/>A recent field experiment by <cite class="ltx_cite ltx_citemacro_cite">Otis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib30" title="">2023</a>)</cite> investigates the effects of a GPT-4-powered business mentor via WhatsApp for Kenyan entrepreneurs. Though not immediately relevant to the labor market, it challenges conceptions of AI-induced wage compression. The study proxies wages by observed productivity, in the form of revenues and profits of entrepreneurs of varying skill levels. In contrast to the literature previously discussed, they estimate an adverse effect of 0.11 standard deviations for low-skilled entrepreneurs, while high performers improve by 0.20 standard deviations. Therefore, the income gap increases contrary to the findings of other research. This might be because low-performing entrepreneurs focus on more challenging business tasks, indicating that they are negatively selected into these functions. Therefore, this is not inconsistent with the prior-discussed literature, which demonstrates that low performers gain more from AI at a given task. High-skilled entrepreneurs may also possess the necessary tacit knowledge to utilize AI effectively.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Recent Research on Early Career Unemployment</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Brynjolfsson et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib10" title="">n.d.</a>)</cite> use Eloundou’s AI annotation-based index to show that early-career workers in the most exposed occupations have experienced a 13% relative decline in employment. This decline is particularly pronounced in occupations where AI automates rather than augments human labor. They harness Anthropic’s Economic Index <cite class="ltx_cite ltx_citemacro_citep">(Handa et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib20" title="">2025</a>)</cite> to classify the jobs. They suggest that tacit knowledge might explain the advantage of more experienced workers in a labor market impacted by AI. I will test tacit knowledge as one factor of my exposure index.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Lichtinger and Hosseini Maasoum (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib25" title="">2025</a>)</cite> validates this result. They utilize large-scale job posting data to classify firms as AI adopters, while also employing Eloundou’s pioneering index. Those AI-adopting firms started 2023 to reduce their early-career hiring by 22%. They call it seniority-biased technological change, which, in contrast to skill-biased technological change, doesn’t drive a wedge between workers with high and low education but between senior and junior workers due to tacit knowledge.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Theoretical-Based Outlook Toward the Future of Work</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">Korinek and Juelfs (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib23" title="">2022</a>)</cite> explore the consequences for workers of an advanced AI that substitutes for human labor. Therefore, labor might become abundant if machines can perform every task more efficiently than humans. This could drastically curtail labor demand, leading to falling wages. Under this scenario, the authors advocate for phasing out labor, starting with less productive workers, and introducing a universal basic income based on the principles of a utilitarian social planner. This is only one, and a rather pessimistic, prediction about the future of work. Empirical research remains of utmost importance to improve economic predictions. One instance is the following analysis of what I believe is the first theory-based automation exposure index.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Methodology</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Theory</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p">To the best of my knowledge, this is the first theory-based automation exposure index and is based on <cite class="ltx_cite ltx_citemacro_citet">Erdil (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib14" title="">2024</a>)</cite>. I consider four factors that contribute to the general automatizability of a given task, which isn’t limited by the current capabilities of AI. These four subhypotheses is Moravec’s Paradox proxied by performance variance, data abundance, tacit knowledge, and the algorithmic efficiency gap.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p">First, Moravec’s Paradox suggests that easy tasks are often complex for humans, and vice versa. A potential explanation tested here is that evolutionary optimization can help resolve this paradox. Tasks that are perceived as hard for humans exhibit high variance between them, as they were developed late in evolution, such as mathematics and coding. <cite class="ltx_cite ltx_citemacro_citet">Mitchell et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib26" title="">2025</a>)</cite> deliver neurobiological evidence that late-evolved skills show higher variability in the location of tasks in the brain. Meanwhile, tasks that are easy for humans, such as somatosensory tasks, exhibit low variance for humans but are more challenging for AI, as humans have had more time during evolution to optimize their performance. Thus, performance variance serves as a proxy for the evolutionary optimization explanation of Moravec’s Paradox.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p">Second, data abundance predicts how well AI can perform a task. If a model is trained on more data of a specific task, it gets better at it. This also holds for general-purpose AI that is trained on a broad dataset and can perform a wide range of tasks. Reasoning models are increasingly trained on high-quality human data, showing the continuing importance of data.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p4">
<p class="ltx_p">Third, tacit knowledge, sometimes called implicit knowledge, means that the task requires something hard to verbalize, such as intuition, wisdom, and experience.
Thus, it might be hard to teach AIs if people can’t communicate with each other. <cite class="ltx_cite ltx_citemacro_citet">Autor (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib3" title="">2014</a>)</cite> calls this Polanyi’s Paradox and identifies it as a main driver of labor market outcomes. Furthermore, <cite class="ltx_cite ltx_citemacro_citet">Bresnahan (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib9" title="">2024</a>)</cite>also sees tacit knowledge as an obstacle to automation. Workers tend to learn this on the job, and thus this factor varies the most between junior and senior employees.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p5">
<p class="ltx_p">Fourth, the human brain is inherently better developed for some tasks than neural networks. While AIs are trained on more compute and data already, they don’t yet outperform humans across the board, indicating that the brain retains some algorithmic advantages. I refer to this as the algorithmic efficiency gap. Humans learn better from limited data and are more sample-efficient<cite class="ltx_cite ltx_citemacro_citep">(Lake et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib24" title="">2017</a>)</cite>. For instance, the human brain can better process somatosensory inputs, whereas it does not have any algorithmic advantage in reading and summarizing large amounts of text. In fact, AIs can already perform this task faster with a decent level of quality.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p6">
<p class="ltx_p">I hypothesize that all four factors can explain automatibility and can serve as an addition to capability-based exposure indices, that might get outdated sooner. I will refer to these factors as subhypotheses at times.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Data</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p">My primary dataset is over 19,000 task statements and over 900 occupations from O*NET that cover the whole US labor market. This dataset from the US Department of Labor is widely regarded as the best source for neutral and comprehensive labor market coverage, and multiple prior indices have used it. The fine-grained tasks of the dataset provide a comprehensive overview of the entire labor market.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p">To bring the exposure to the labor market, I harness the Occupational Employment and Wage Statistics (OEWS) from the US Bureau of Labor Statistics. This dataset delivers high-quality and extensive data, and I use the most recent 2024 series and the 2021 series for comparison with other indices, primarily Eloundou et al. (2024).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p">For the validation, I also use the indices of <cite class="ltx_cite ltx_citemacro_citet">Brynjolfsson et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib11" title="">2018</a>)</cite>), <cite class="ltx_cite ltx_citemacro_citet">Felten et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib16" title="">2021b</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Webb (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib34" title="">2019</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Eloundou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib13" title="">2024</a>)</cite>, and <cite class="ltx_cite ltx_citemacro_citet">Frey and Osborne (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib18" title="">2017</a>)</cite>. I follow the standardization method of Eloundou et al. (2024), who also thankfully shared their data with me.
However, most of the data was created by me through AI annotation, as described in the following sections.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Prompting and Weighting</h3>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p">I granted the AI access in the user prompt to the occupation and the detailed O*NET task statement, which provides a fine-grained description of the tasks the AI performs. The system prompt contains explicit annotation advice, including a detailed description of the criterion, the description of each exposure level, and an example for each level of exposure. This basic structure, which includes a 0-2 ranking, is based on Eloundou et al. (2024). In contrast to GPT-4’s time reduction under tool usage, the exposure levels don’t have a clear interpretation. But what causes the limited ranking from 0-2 - the lack of scope sensitivity of models - also might make the 50 times reduction difficult for LLMs to comprehend. Appendix <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#Ax1" title="Appendix ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title">Appendix</span></a> shows the whole system prompt.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p2">
<p class="ltx_p">O*NET classifies tasks as core to an occupation when they’re relevant and essential to an occupation. Following prior literature, I weight these core tasks twice for occupational indices.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Aggregation</h3>
<div class="ltx_para ltx_noindent" id="S4.SS4.p1">
<p class="ltx_p">I average the hypotheses with equal weighting and also average the output of the three AI models, GPT o4-mini, Claude 4 Sonnet, and Gemini 2.5 Flash. This reduces idiosyncratic model bias, making the results more robust. The success rate of Claude and OpenAI is quite high, but for Gemini, it is around 60%. I restrict the analysis to occupations with successful annotations from at least two models and partly reduce the number of tasks to compare them on the SOC-6 level with other indices, which fuse some occupations (N=681). I only include functions in the analysis that have at least two models. All three models were reasonably close to the state of the art, but Gemini 2.5 Flash is the fastest and least capable model, standing out as an outlier on benchmarks.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.p2">
<p class="ltx_p">All four subhypotheses could serve as independent indices and are treated as such during the validation.</p>
</div>
<figure class="ltx_figure" id="S4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="169" id="S4.F1.g1" src="graphics/Screenshot2025-08-21.png" width="381"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" style="font-size:90%;">Overview of Steps in Data Creation</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS4.p3">
<p class="ltx_p">The main specification for the annotation is:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="E_{j}=\frac{\sum_{i}w_{i}\cdot 0.25\cdot(PV_{i}+TK_{i}+DA_{i}+AG_{i})}{\sum_{i}w_{i}}" class="ltx_Math" display="block" id="S4.E1.m1" intent=":literal"><semantics><mrow><msub><mi>E</mi><mi>j</mi></msub><mo>=</mo><mfrac><mrow><msub><mo>∑</mo><mi>i</mi></msub><mrow><msub><mi>w</mi><mi>i</mi></msub><mo lspace="0.222em" rspace="0.222em">⋅</mo><mn>0.25</mn><mo lspace="0.222em" rspace="0.222em">⋅</mo><mrow><mo stretchy="false">(</mo><mrow><mrow><mi>P</mi><mo lspace="0em" rspace="0em">​</mo><msub><mi>V</mi><mi>i</mi></msub></mrow><mo>+</mo><mrow><mi>T</mi><mo lspace="0em" rspace="0em">​</mo><msub><mi>K</mi><mi>i</mi></msub></mrow><mo>+</mo><mrow><mi>D</mi><mo lspace="0em" rspace="0em">​</mo><msub><mi>A</mi><mi>i</mi></msub></mrow><mo>+</mo><mrow><mi>A</mi><mo lspace="0em" rspace="0em">​</mo><msub><mi>G</mi><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><msub><mo>∑</mo><mi>i</mi></msub><msub><mi>w</mi><mi>i</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">E_{j}=\frac{\sum_{i}w_{i}\cdot 0.25\cdot(PV_{i}+TK_{i}+DA_{i}+AG_{i})}{\sum_{i}w_{i}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">PV, TK, DA, and AG represent the four subhypotheses on the task level i, which I explained in more detail in the theory section. w represents the weight, which is double if it’s a core task. I also normalize to the span 0-2, such that the left-hand side, E, represents the average overall automation score at the occupation level j.
The relationship to other exposure indices and to a simple labor market benchmark is consistent with this predictive approach.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Summary Statistics</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p">The following occupations have the highest and lowest exposure in the database.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" style="font-size:90%;">Occupations with the most extreme scores</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r"><span class="ltx_text ltx_font_bold">Highest Exposure</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column"><span class="ltx_text ltx_font_bold">Lowest Exposure</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Online Merchants</td>
<td class="ltx_td ltx_align_left ltx_border_t">Riggers</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Logistics Analysts</td>
<td class="ltx_td ltx_align_left">Electrical Power-Line Installers and Repairers</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Graphic Designers</td>
<td class="ltx_td ltx_align_left">Rock Splitters, Quarry</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Market Research Analyst</td>
<td class="ltx_td ltx_align_left">Refractory Materials Repairers</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Pharmacy Technicians*</td>
<td class="ltx_td ltx_align_left">Roustabouts, Oil and Gas</td>
</tr>
</tbody>
</table>
</figure><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Pharmacy Technicians showed the highest model disagreement and may represent a classification anomaly. </span></span></span>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p">This suggests that digital tasks are most exposed to pattern recognition. Anthropic has experimented with an autonomous online merchant, which yielded mediocre results with promising signs. Physical tasks show the lowest exposure. Pharmacy Technicians might be the odd ones out here, but they showed the highest model disagreement and may represent a classification anomaly.
Via text recognition, I found that management, STEM, and sciences are the most exposed job categories, while maintenance, agriculture, and construction are the least exposed categories. I also grouped the over 900 occupations into 10 job categories, and the following table shows the results.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" style="font-size:90%;">Job categories with the most extreme scores</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r"><span class="ltx_text ltx_font_bold">Highest Exposure</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column"><span class="ltx_text ltx_font_bold">Lowest Exposure</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Management</td>
<td class="ltx_td ltx_align_left ltx_border_t">Maintenance</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">STEM</td>
<td class="ltx_td ltx_align_left">Agriculture</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Sciences</td>
<td class="ltx_td ltx_align_left">Construction</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Wages and Employment</h3>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p">The relationship of exposure with wages is positive. Initially, higher salaries are associated with greater exposure, which is consistent with wage compression resulting from AI and the increased exposure of highly educated jobs. Exposure may lead to the best-paying jobs, potentially due to the development of judgment skills (Gans et al.). Still, not even the means are significantly falling, so this has to be interpreted cautiously.</p>
</div>
<figure class="ltx_figure" id="S5.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F2.fig1" style="width:165.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="165" id="S5.F2.g1" src="graphics/exposure_vs_logwage_2021.png" width="229"/>
<figcaption class="ltx_caption ltx_centering">2021</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F2.fig2" style="width:165.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="165" id="S5.F2.g2" src="graphics/exposure_vs_logwage_2024.png" width="229"/>
<figcaption class="ltx_caption ltx_centering">2024</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" style="font-size:90%;">Largely positive relationship between wages and exposure with confidence interval for the mean</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p">The binscatter plots depict the exposure to language models (LLMs) in various occupations. Employment and wage data are sourced from the BLS-OEWS survey conducted in May 2021 (for comparison with other indices, such as <cite class="ltx_cite ltx_citemacro_cite">Eloundou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib12" title="">2023</a>)</cite>, which is highly consistent, and May 2024 for more recent data. The appendix <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#Ax1.SSx3" title="Wages and Subhypotheses ‣ Appendix ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title">Wages and Subhypotheses</span></a> shows for each subhypothesis the corresponding wage plot.</p>
</div>
<figure class="ltx_figure" id="S5.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F3.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="344" id="S5.F3.sf1.g1" src="graphics/exposure_vs_logemp_2021.png" width="476"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">(a)</span> </span><span class="ltx_text" style="font-size:90%;">2021</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F3.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="344" id="S5.F3.sf2.g1" src="graphics/exposure_vs_logemp_2024.png" width="476"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">(b)</span> </span><span class="ltx_text" style="font-size:90%;">2024</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" style="font-size:90%;">Relationship between exposure and log employment on occupation level (2021 vs 2024)</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS2.p3">
<p class="ltx_p">As in prior literature, there’s no clear relationship between the number of workers employed in an occupation and its AI exposure, with potentially greater exposure in more common occupations. This suggests that the share of workers affected by automation would be at least as high as the share of occupations, but a more detailed interpretation isn’t warranted. Appendix <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#Ax1.SSx2" title="Relationship between Human and AI-annotated Automation Score and Labor Market Data such as Wages and Employment (Eloundou et al., 2024) ‣ Appendix ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title">Relationship between Human and AI-annotated Automation Score and Labor Market Data such as Wages and Employment <cite class="ltx_cite ltx_citemacro_citep">(Eloundou et al., <span class="ltx_ref">2024</span>)</cite></span></a> shows that the relationship of my index with labor market data is consistent with Eloundou’s et al.(2024) estimates for both employment and wages. This holds for both their AI-annotated and human-rated data. This remarkable, typical pattern also shows up in the direct comparison with other indices in the following section. This validates both the AI annotation approach due to the similarity with human ratings, and cross-validates their two approaches. As will be seen in the next chapter, this isn’t the only point of consistency and cross-validation between Eloundou et al. (2024)’s measure and mine.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Validation of Index</h2>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Comparison to Earlier Efforts</h3>
<div class="ltx_para ltx_noindent" id="S6.SS1.p1">
<p class="ltx_p">This paper aims to contribute to the diverse literature on AI exposure indices. Previous studies have employed various methods and yielded diverse results, as outlined in earlier sections. The correlation with Eloundou et al. (2024) is particularly high, with 0.72, as the basic methodology is similar. Nonetheless, the completely different prompts exhibit such a high correlation, which validates the standard AI annotation methodology, as the exposure indices seem robust to prompting. The regression table indices indicate that each subhypothesis, on its own, is a valid exposure index, given the substantial share of variance it can explain. It suggests that automation exposure is very multi-dimensional, as even the overall index provides little additional explanation. This is consistent with a considerable difficulty in finding proper unidimensional indices. The overall index is negatively correlated with Webb’s software and robot indices, while being positively correlated with the AI index. It is negatively correlated to the three pre-LLM AI exposure indices of Frey and Osborne (2017), Felten et al. (2021), and Brynjolfsson et al. (2017). It’s negatively correlated to routine manual jobs, but positively associated with routine cognitive, which is consistent with the summary statistics in the previous sections, and the job categories shown there. The positive relationship to Eloundou et al’s preferred beta measure is encouraging.</p>
</div>
<figure class="ltx_table" id="S6.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" style="font-size:90%;">Regression of Automation Measures on Prior Literature</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:345.0pt;height:219.9pt;vertical-align:-108.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-120.9pt,77.0pt) scale(0.587969691862484,0.587969691862484) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5"><span class="ltx_text ltx_font_italic">Dependent variable:</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_center ltx_border_t">Overall Index</td>
<td class="ltx_td ltx_align_center ltx_border_t">Productivity Variance</td>
<td class="ltx_td ltx_align_center ltx_border_t">Data Abundance</td>
<td class="ltx_td ltx_align_center ltx_border_t">Tacit Knowledge</td>
<td class="ltx_td ltx_align_center ltx_border_t">Algorithmic Gap</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_center">(1)</td>
<td class="ltx_td ltx_align_center">(2)</td>
<td class="ltx_td ltx_align_center">(3)</td>
<td class="ltx_td ltx_align_center">(4)</td>
<td class="ltx_td ltx_align_center">(5)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Software (Webb)</th>
<td class="ltx_td ltx_align_center ltx_border_t">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m1" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.00012</td>
<td class="ltx_td ltx_align_center ltx_border_t">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m2" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.00178<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.00057</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.00103<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.00118<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗</span></sup>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_center">(0.00040)</td>
<td class="ltx_td ltx_align_center">(0.00045)</td>
<td class="ltx_td ltx_align_center">(0.00045)</td>
<td class="ltx_td ltx_align_center">(0.00043)</td>
<td class="ltx_td ltx_align_center">(0.00043)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Robot (Webb)</th>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m6" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.00169<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m8" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.00156<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m10" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.00182<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.00149<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m13" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.00212<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_center">(0.00044)</td>
<td class="ltx_td ltx_align_center">(0.00049)</td>
<td class="ltx_td ltx_align_center">(0.00049)</td>
<td class="ltx_td ltx_align_center">(0.00048)</td>
<td class="ltx_td ltx_align_center">(0.00047)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">AI (Webb)</th>
<td class="ltx_td ltx_align_center">0.00122<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.00217<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.00086<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m18" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.00157<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.00153<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_center">(0.00035)</td>
<td class="ltx_td ltx_align_center">(0.00040)</td>
<td class="ltx_td ltx_align_center">(0.00040)</td>
<td class="ltx_td ltx_align_center">(0.00038)</td>
<td class="ltx_td ltx_align_center">(0.00038)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Suitability for ML</th>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m21" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.20122<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m23" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.66181<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.51138<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.90404<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.71782<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_center">(0.05236)</td>
<td class="ltx_td ltx_align_center">(0.05885)</td>
<td class="ltx_td ltx_align_center">(0.05877)</td>
<td class="ltx_td ltx_align_center">(0.05664)</td>
<td class="ltx_td ltx_align_center">(0.05641)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Routine Cognitive</th>
<td class="ltx_td ltx_align_center">0.04717<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m29" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.07199<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.05422<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.03645<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.05279<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_center">(0.00859)</td>
<td class="ltx_td ltx_align_center">(0.00965)</td>
<td class="ltx_td ltx_align_center">(0.00964)</td>
<td class="ltx_td ltx_align_center">(0.00929)</td>
<td class="ltx_td ltx_align_center">(0.00925)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Routine Manual</th>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m34" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.04415<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m36" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.01220</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m37" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.06786<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.01039</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m39" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.00869</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_center">(0.01173)</td>
<td class="ltx_td ltx_align_center">(0.01318)</td>
<td class="ltx_td ltx_align_center">(0.01316)</td>
<td class="ltx_td ltx_align_center">(0.01269)</td>
<td class="ltx_td ltx_align_center">(0.01264)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">AI Exposure (Felten)</th>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m40" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.03137<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.00260</td>
<td class="ltx_td ltx_align_center">0.04476<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m43" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.11142<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.00775</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_center">(0.01300)</td>
<td class="ltx_td ltx_align_center">(0.01461)</td>
<td class="ltx_td ltx_align_center">(0.01459)</td>
<td class="ltx_td ltx_align_center">(0.01406)</td>
<td class="ltx_td ltx_align_center">(0.01401)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Frey-Osborne Automation</th>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m45" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.16016<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m47" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.16729<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m49" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.07953<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.10097<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.05432</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_center">(0.02622)</td>
<td class="ltx_td ltx_align_center">(0.02947)</td>
<td class="ltx_td ltx_align_center">(0.02943)</td>
<td class="ltx_td ltx_align_center">(0.02836)</td>
<td class="ltx_td ltx_align_center">(0.02825)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Eloundou <math alttext="\beta" class="ltx_Math" display="inline" id="S6.T3.m52" intent=":literal"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center">0.50409<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.17899<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.74291<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">0.18811<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">1.06082<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_center">(0.05121)</td>
<td class="ltx_td ltx_align_center">(0.05756)</td>
<td class="ltx_td ltx_align_center">(0.05747)</td>
<td class="ltx_td ltx_align_center">(0.05539)</td>
<td class="ltx_td ltx_align_center">(0.05517)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Constant</th>
<td class="ltx_td ltx_align_center">1.32248<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">2.94626<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m60" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>0.86286<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m62" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>1.79062<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">
<math alttext="-" class="ltx_Math" display="inline" id="S6.T3.m64" intent=":literal"><semantics><mo>−</mo><annotation encoding="application/x-tex">-</annotation></semantics></math>1.93400<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_center">(0.17469)</td>
<td class="ltx_td ltx_align_center">(0.19635)</td>
<td class="ltx_td ltx_align_center">(0.19607)</td>
<td class="ltx_td ltx_align_center">(0.18896)</td>
<td class="ltx_td ltx_align_center">(0.18822)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Observations</th>
<td class="ltx_td ltx_align_center ltx_border_t">681</td>
<td class="ltx_td ltx_align_center ltx_border_t">681</td>
<td class="ltx_td ltx_align_center ltx_border_t">681</td>
<td class="ltx_td ltx_align_center ltx_border_t">681</td>
<td class="ltx_td ltx_align_center ltx_border_t">681</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">R<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">2</span></sup>
</th>
<td class="ltx_td ltx_align_center">0.65489</td>
<td class="ltx_td ltx_align_center">0.71368</td>
<td class="ltx_td ltx_align_center">0.67720</td>
<td class="ltx_td ltx_align_center">0.74663</td>
<td class="ltx_td ltx_align_center">0.75309</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Adjusted R<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">2</span></sup>
</th>
<td class="ltx_td ltx_align_center">0.65026</td>
<td class="ltx_td ltx_align_center">0.70984</td>
<td class="ltx_td ltx_align_center">0.67287</td>
<td class="ltx_td ltx_align_center">0.74323</td>
<td class="ltx_td ltx_align_center">0.74978</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Residual Std. Error (df = 671)</th>
<td class="ltx_td ltx_align_center">0.16240</td>
<td class="ltx_td ltx_align_center">0.18254</td>
<td class="ltx_td ltx_align_center">0.18228</td>
<td class="ltx_td ltx_align_center">0.17568</td>
<td class="ltx_td ltx_align_center">0.17498</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">F Statistic (df = 9; 671)</th>
<td class="ltx_td ltx_align_center">141.47940<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">185.83410<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">156.40830<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">219.69980<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
<td class="ltx_td ltx_align_center">227.39810<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt"><span class="ltx_text ltx_font_italic">Note:</span></th>
<td class="ltx_td ltx_align_right ltx_border_tt" colspan="5">
<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>p<math alttext="&lt;" class="ltx_Math" display="inline" id="S6.T3.m74" intent=":literal"><semantics><mo>&lt;</mo><annotation encoding="application/x-tex">&lt;</annotation></semantics></math>0.05; <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗</span></sup>p<math alttext="&lt;" class="ltx_Math" display="inline" id="S6.T3.m76" intent=":literal"><semantics><mo>&lt;</mo><annotation encoding="application/x-tex">&lt;</annotation></semantics></math>0.01; <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗∗∗</span></sup>p<math alttext="&lt;" class="ltx_Math" display="inline" id="S6.T3.m78" intent=":literal"><semantics><mo>&lt;</mo><annotation encoding="application/x-tex">&lt;</annotation></semantics></math>0.001</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_right" colspan="5">Standard errors at 6digit SOC level in parentheses.</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_right" colspan="5">Webb measures on 0-100 scale. Routine measures standardized.</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S6.SS1.p2">
<p class="ltx_p">This table shows the regression of my exposure scores on prior measures of occupational exposure to AI and automation. Each measure is kept in its original scale, with the exception of routine cognitive and routine manual scores from (Acemoglu and Autor, 2011). Those two scores are standardized to have a mean of zero and a variance of 1. I also look at the correlation with the various indices separately in the following correlation triangle:</p>
</div>
<figure class="ltx_figure" id="S6.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="302" id="S6.F4.g1" src="graphics/Rplot.png" width="476"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" style="font-size:90%;">Correlations with various exposure indices </span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S6.SS1.p3">
<p class="ltx_p">Naturally, most subhypotheses contribute positively to the overall index as can be seen in the lowest row. Tacit knowledge is negatively correlated with the other indices and thsu contributes negatively to the overall index (has a negative beta).
The correlation with Eloundou et al. (2024) is particularly high, with 0.72, as the basic methodology is similar. Nonetheless, the completely different prompts exhibiut such a high correlation, which validates the standard AI annotation methodology as the exposure indices seem robust to prompting.
The indices are largely ranked temporarily, and it’s easy to visually see that more recent efforts correlate strongly with previous efforts as the triangle transitions from blue to red when the distance from the hypotenuse increases. This also confirms that indices based on current capabilities are fast outdated; only time will tell whether this theory-based index will be helpful for longer.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Comparison between models</h3>
<div class="ltx_para ltx_noindent" id="S6.SS2.p1">
<p class="ltx_p">I also use multiple AI models for annotation, which have slightly different opinions on automatibility. The reasoning models of OpenAI and Anthropic have a very high correlation of 0.81, but in general, the correlations are pretty high, validating the AI annotation approach. Flash is a smaller and faster model and serves as the outlier, with Claude scoring jobs often in between OpenAI and Gemini. The correlation with itself is also below ,one, as it depends on the random seed when the temperature is above 0.</p>
</div>
<figure class="ltx_table" id="S6.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" style="font-size:90%;">Correlation triangle between models</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t"><span class="ltx_text ltx_font_bold">Correlation</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">OpenAI GPT o4-mini</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Gemini 2.5 Flash</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Claude 4 Sonnet</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">OpenAI GPT o4-mini</th>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Gemini 2.5 Flash</th>
<td class="ltx_td ltx_align_center">0.60</td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b">Claude 4 Sonnet</th>
<td class="ltx_td ltx_align_center ltx_border_b">0.81</td>
<td class="ltx_td ltx_align_center ltx_border_b">0.71</td>
<td class="ltx_td ltx_border_b"></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p">Here, pharmacy technicians are the job with the highest model disagreement, and in general, it’s the smallest model flash that produces the 15 most prominent outliers. This is consistent with scaling laws also holding for this classification task. The specific examples provided may help clarify this.</p>
</div>
<figure class="ltx_figure" id="S6.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="381" id="S6.F5.g1" src="graphics/top_disagreement_occupations.png" width="476"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" style="font-size:90%;">Top disagreement across occupations</span></figcaption>
</figure>
<figure class="ltx_figure" id="S6.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="357" id="S6.F6.g1" src="graphics/subcategory_disagreement.png" width="476"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" style="font-size:90%;">Disagreement across subcategories</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S6.SS2.p3">
<p class="ltx_p">The average disagreement between models is the largest for the algorithmic efficiency gap, but not by much; still, a better definition might have been most helpful here. The anticorrelated tacit knowledge shows the lowest disagreement, which makes this outlier result more robust. In general, Gemini seems to classify technicians in unusual environments such as pharmacy, library, and ophthalmology. This indicates that reasoning models can abstract better away from naming conventions and take the context better into account.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Validation of Theory</h3>
<div class="ltx_para ltx_noindent" id="S6.SS3.p1">
<p class="ltx_p">This index closely follows the theoretical predictions by <cite class="ltx_cite ltx_citemacro_citet">Erdil (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib14" title="">2024</a>)</cite>. Thus, it’s a faithful implementation of its theory and the four subhypotheses. This piece predicts four broad tasks that will be automated earlier: scientific research, software engineering, art without sensomotorical skills, and management. This is highly consistent with the three job categories with the highest exposure in Table 2 (management, STEM, and science). Furthermore, a graphic designer is the third most exposed occupation and probably archetypal for "art without sensomotorical skills". This might partly be caused by anchoring bias from the system prompt, for example, as debugging software is given as an example for high data abundance, and writing technical documentation for software is an algorithmic advantage that humans have. This indicates that superficial similarities to the prompt, as seen in <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#Ax1.SSx1" title="System Prompt ‣ Appendix ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title">System Prompt</span></a>, might contribute to the high exposure classification of software engineering. However, these don’t even feature among the most exposed occupations (although Logistics and Market Research could be seen as related). Software engineering falls under STEM jobs, but overall, the high consistency beyond software engineering is hardly driven by these classification examples superficially. Tacit knowledge, which is the primary explanation for graduate unemployment, exhibits the highest covariance with previous indices. However, tacit knowledge also shows a highly positive relationship with wages, which is consistent with the notion that highly educated jobs are among the first to be automated.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Discussion</h2>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Validity of Methodology</h3>
<div class="ltx_para ltx_noindent" id="S7.SS1.p1">
<p class="ltx_p">The general methodology of AI annotation pioneered by Eloundou et al. (2024) holds up quite well and seems robust to the concrete specification, as various results demonstrate. The theory-based approach might be a good combination of the strengths of expert surveys and a systematic O*NET-based approach, but the results are too preliminary for a final judgment. The methodology is also robust to the choice of models, though reasoning models might perform slightly better.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p2">
<p class="ltx_p">These results are consistent with Moravec’s Paradox and its explanation as evolutionary optimization. It shows the potential for theory-based exposure indices that might be more robust and useful for a longer time. If AI were substitutive, it would indicate a wage compression and a fall in inequality, holding capital income constant. This has interesting political economy implications: Richer, higher-educated voters might have more to lose from AI adoption, which might exacerbate polarization on the topic of AI.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p3">
<p class="ltx_p">The validity of the classification itself is also controversial. The LLMs might also classify based on rudimentary commonalities between the job name and the subcategory at hand. Indeed, Gemini 2.5 Flash shows this in an egregious way and classifies all jobs with the name technicians, whether pharmacy, biological, histology, medical, food science, library or forest technicians, as much more exposed than the reasoning models. In general, classification is a much easier and much better-defined task than those in the O*NET database, and the AI classification seems somewhat useful and follows the classification examples. It’s also consistent with rudimentary human classification, but further research should investigate this. Eloundou et al. (2024) showed the consistency of AI-nad human-based annotation.
</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p4">
<p class="ltx_p">Future research could examine the expertise required in this job and thus attempt to create a more detailed picture of the ambivalent effects automation has on jobs, which differ depending on whether low-skilled tasks or high-skilled tasks of an occupation are automated <cite class="ltx_cite ltx_citemacro_citep">(Autor and Thompson, <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib8" title="">2025</a>)</cite>. This would require no tonly the calculation of average exposure of an occupation but also the ranking of tasks regarding the required expertise.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p5">
<p class="ltx_p">Researchers could use these to study labor market impact across different time periods, as the index isn’t based on specific model capabilities. All the data are open-sourced and can be used for this. Studies deploying other indices could be easily replicated as long as they use the O*NET classification</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p6">
<p class="ltx_p">Future research could also address some limitations of this study. When examining labor market outcomes with exposure, it remains a challenge to avoid endogeneity concerns. However, some studies discussed in the following subchapter attempt to overcome this by controlling for firm-level shocks, using difference-in-difference and triple-difference estimations. At times, the theoretical grounding of the hypotheses hasn’t been validated rigorously before. Additionally, further research would be needed to investigate the causality of exposure on labor market outcomes. The treatment of Gemini’s outcome, which changes some estimations, such as for Pharmacy Technicians, significantly, could introduce sample selection bias, as Gemini only classified 60% tasks. A direct verification with human annotators would strengthen the credibility of the AI annotation; however, Eloundou et al. (2024) demonstrated the validity of the methodology. The weighting of the four factors could have also followed another pattern, but the separate treatment of the factors allows for the exploration of the differences.
Overall, creating a meaningful AI automation exposure index remains a challenging task. Still, AI annotation doesn’t seem to perform worse than other methods, especially older pre-LLM ones. Nonetheless, it remains to be seen how temporally stable this exposure index is.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Tacit Knowledge and Early-Career Unemployment</h3>
<div class="ltx_para ltx_noindent" id="S7.SS2.p1">
<p class="ltx_p">Recent research validates the usefulness of the post-LLM AI annotation method as a tool for predicting the impact of AI on the labor market. This is to my knowledge the first evidence for the adverse effect of AI exposure on the labor market. Both <cite class="ltx_cite ltx_citemacro_citet">Lichtinger and Hosseini Maasoum (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib25" title="">2025</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Brynjolfsson et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib10" title="">n.d.</a>)</cite>
hypothesize that tacit knowledge, which is learned on the job and hard to verbalize, explains the seniority-biased technological change. In my framework, tacit knowledge is the only factor that is negatively correlated with wages as Appendix <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#Ax1.SSx3" title="Wages and Subhypotheses ‣ Appendix ‣ A Theory-Based AI Automation Exposure Index: Applying Moravec’s Paradox to the US Labor Market"><span class="ltx_text ltx_ref_title">Wages and Subhypotheses</span></a> shows. This is consistent with two strands of literature: A general higher exposure of highly-educated workers to AI compared to lower-educated ones, as low-skilled workers see higher productivity boosts from AI <cite class="ltx_cite ltx_citemacro_citep">(Noy and Zhang, <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib29" title="">2023</a>)</cite>, indicating complementarity. On the other hand, highly educated but not yet very highly skilled job entrants with a college degree have less tacit knowledge that would protect them from the substitutive effect of AI. This is consistent with my finding that higher-paid workers have more tacit knowledge. This factor is also the only one that shows a negative relationship with wages and is negatively correlated with the other subhypotheses. This could mean that seniority-biased technological change could be followed by reverse skill-biased technological change over time, if AI exposure in other domains also becomes substitutive.
If the adverse effects on early-career workers persist, this would also have long-term negative effects on the intergenerational transmission of knowledge. <cite class="ltx_cite ltx_citemacro_cite">Ide (<a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib22" title="">2025</a>)</cite> demonstrates that if the lack of on the job learning opportunities continues, there might be less labor supply for senior roles in the future, which could reduce productivity growth by 0.05 to 0.35 percentage points.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S8.p1">
<p class="ltx_p">This theory-based approach to automation exposure offers multiple key contributions. First, it provides a principled framework grounded in evolutionary theory rather than current technological capabilities. Second, the positive wage relationship suggests AI may reduce inequality by automating high-skill cognitive work while preserving manual jobs, holding capital income constant. Third, the high correlation with Eloundou (0.72) validates the approach, while negative correlations with pre-LLM indices highlight the paradigm shift in automation patterns. Future work should test these predictions as AI capabilities evolve. The high correlations between the models, and especially the reasoning models, are promising, as is the robustness of the AI annotation method to the direct specification. Policymakers can place at least comparable levels of trust in the AI annotation method as in previous, pre-LLM methods.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>
<section class="ltx_subsection" id="Ax1.SSx1">
<h3 class="ltx_title ltx_title_subsection">System Prompt</h3>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p1">
<p class="ltx_p">"Score each task 0, 1, or 2 (where 2 = most automatable).</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p2">
<p class="ltx_p">Consider the occupation context when scoring. Output JSON: {"PV": X, "DA": Y, "TK": Z, "AG": W}</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p3">
<p class="ltx_p">You are an expert economist analyzing tasks for automation potential across four theoretical frameworks. Your analysis will inform academic research on labor market impacts.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p4">
<p class="ltx_p">For each task, provide precise scores (0, 1 or 2) in JSON format (where 2= most automatable): {"PV": X, "DA": Y, "TK": Z, "AG": W}</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p5">
<p class="ltx_p"># Performance Variance Taxonomy</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p6">
<p class="ltx_p">Consider how much performance varies between trained professionals when completing this task. Performance variance reflects whether humans have evolved to optimize for this task - high variance suggests the task hasn’t been optimized through evolution and may be easier to systematize.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p7">
<p class="ltx_p">Assume you are evaluating the productivity gap between workers with the same training and experience within the same profession. Consider measurable outputs like speed, accuracy, quality, or efficiency.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p8">
<p class="ltx_p">Please label the given task according to the taxonomy below.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p9">
<p class="ltx_p">##
PV0 – Low variance</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p10">
<p class="ltx_p">Label tasks 0 if professionals show a low productivity gap between workers. These are tasks where most trained professionals perform at similar levels.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p11">
<p class="ltx_p">## PV1 – Moderate variance</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p12">
<p class="ltx_p">Label tasks 1 if there is a medium productivity gap between workers. These tasks show some performance differences but professionals generally achieve comparable results.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p13">
<p class="ltx_p">## PV2 – High variance</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p14">
<p class="ltx_p">Label tasks 2 if there is a high productivity gap between workers. These tasks show significant performance differences between professionals, suggesting humans haven’t uniformly mastered them.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p15">
<p class="ltx_p">## Classification examples:</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p16">
<p class="ltx_p">Task: Perform routine blood draws from patients</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p17">
<p class="ltx_p">Label: 0</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p18">
<p class="ltx_p">Explanation: Trained phlebotomists show minimal variance in successful blood draw rates and patient comfort levels.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p19">
<p class="ltx_p">Task: Evaluate and select providers of services according to customer requirements.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p20">
<p class="ltx_p">Label: 1</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p21">
<p class="ltx_p">Explanation: Sales professionals show moderate variance in customer satisfaction and sales success rates: some variance in understanding customers</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p22">
<p class="ltx_p">Task: Develop algorithmic trading strategies for financial markets</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p23">
<p class="ltx_p">Label: 2</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p24">
<p class="ltx_p">Explanation: Quantitative traders show huge variance in returns, with top performers generating consistent alpha while average traders barely beat market indices or lose money</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p25">
<p class="ltx_p"># Data Abundance Taxonomy</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p26">
<p class="ltx_p">Consider the availability of digital training data for this task. Tasks with massive online datasets of examples can be more easily learned by computational systems.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p27">
<p class="ltx_p">Think about whether examples of this task being performed exist in digital form online, in databases, or in digital archives. Consider text descriptions, code, documents, or other digital records.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p28">
<p class="ltx_p">Please label the given task according to the taxonomy below.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p29">
<p class="ltx_p">## DA0 – Limited digital data</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p30">
<p class="ltx_p">Label tasks 0 if hardly any digital examples of the task exist online. These tasks are primarily demonstrated physically or have limited digital documentation.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p31">
<p class="ltx_p">## DA1 – Moderate digital data</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p32">
<p class="ltx_p">Label tasks 1 if a moderate amount of examples exist digitally. Some documentation and examples are available but coverage is incomplete.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p33">
<p class="ltx_p">## DA2 – Abundant digital data</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p34">
<p class="ltx_p">Label tasks 2 if many examples exist online. These tasks have extensive digital documentation, tutorials, examples, and records.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p35">
<p class="ltx_p">## Classification examples:</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p36">
<p class="ltx_p">Task: Debug software code and fix errors</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p37">
<p class="ltx_p">Label: 2</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p38">
<p class="ltx_p">Explanation: Billions of code debugging examples exist on GitHub, Stack Overflow, and programming forums.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p39">
<p class="ltx_p">Task: Collaborate with system architects, software architects, design analysts, and others to understand business or industry requirements.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p40">
<p class="ltx_p">Label: 1</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p41">
<p class="ltx_p">Explanation: Some digital documentation exists in the form of business requirement documents. some data on collaboration, but enough data on each role</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p42">
<p class="ltx_p">Task: Adjust industrial machinery by feel and sound</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p43">
<p class="ltx_p">Label: 0</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p44">
<p class="ltx_p">Explanation: This tactile task has minimal digital documentation beyond basic manuals.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p45">
<p class="ltx_p"># Tacit Knowledge Taxonomy</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p46">
<p class="ltx_p">Consider how much tacit knowledge, gained through education and especially experience, is required for this task. Tacit knowledge includes judgment, intuition, and skills that are difficult to articulate or codify and those tasks are hard for entry-level graduates to fullfill.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p47">
<p class="ltx_p">Evaluate whether the task is typically performed by entry-level workers or requires years of training and seniority.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p48">
<p class="ltx_p">Please label the given task according to the taxonomy below.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p49">
<p class="ltx_p">## TK0 – High tacit knowledge required</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p50">
<p class="ltx_p">Label tasks 0 if they require extensive training, education, and seniority. These tasks are predominantly performed by senior professionals with years of experience.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p51">
<p class="ltx_p">## TK1 – Moderate tacit knowledge required</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p52">
<p class="ltx_p">Label tasks 1 if they require some training and education but can be performed adequately by mid-level professionals.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p53">
<p class="ltx_p">## TK2 – Minimal tacit knowledge required</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p54">
<p class="ltx_p">Label tasks 2 if they require little training or education and can be performed by entry-level workers following clear procedures.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p55">
<p class="ltx_p">## Classification examples:</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p56">
<p class="ltx_p">Task: Enter data from paper forms into spreadsheets</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p57">
<p class="ltx_p">Label: 2</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p58">
<p class="ltx_p">Explanation: Requires minimal training beyond basic computer literacy and can be performed by entry-level workers.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p59">
<p class="ltx_p">Task: Coordinate services for events, such as accommodation and transportation for participants, facilities, catering, signage, displays, special needs requirements, printing and event security.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p60">
<p class="ltx_p">Label: 1</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p61">
<p class="ltx_p">Explanation: some required to ease coordination, but largely procedural, not judgemental. Coordination is largely procedural - following checklists, timelines, and standard processes. While it requires organizational skills and attention to detail, these can be learned relatively quickly. Mid-level event coordinators routinely handle these logistics. The main skill is project management, not deep expertise or intuition.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p62">
<p class="ltx_p">Task: Inspect event facilities to ensure that they conform to customer requirements.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p63">
<p class="ltx_p">Label: 0</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p64">
<p class="ltx_p">Explanation: Need to know where to look to find issues, and how to assess them. Requires extensive experience in event management and facility inspection. Customer requirements are often underspecified and need to be inferred from context. Facilities try to hide issues, so need to be able to spot them.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p65">
<p class="ltx_p"># Algorithmic Efficiency Gap Taxonomy</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p66">
<p class="ltx_p">Consider whether this task requires a lot of  physical manipulation, multimodal sensory input, or embodied interaction with the physical world. These requirements create efficiency gaps where humans maintain advantages.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p67">
<p class="ltx_p">Evaluate if the task could be performed purely through digital interfaces or requires a lot of physical presence and sensory feedback. The human (brain) is more efficient in some domains such as multimodal sensory input, Physical world modelling and embodiment and physical sensoring.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p68">
<p class="ltx_p">This taxonomy classifies tasks based on domains where the human brain maintains computational efficiency advantages. These advantages stem from our evolved neural architecture’s specialized capabilities, not just physical embodiment.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p69">
<p class="ltx_p">Key Domains of Human Brain Efficiency are Multimodal Integration &amp; Embodied Cognition, Social-Emotional Processing, Creative Synthesis &amp; Abstraction, Contextual Flexibility &amp; Common Sense and Efficient Learning from Sparse Data.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p70">
<p class="ltx_p">Please label the given task according to the taxonomy below.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p71">
<p class="ltx_p">## AG0 – High human brain efficiency advantage</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p72">
<p class="ltx_p">Label tasks 0 if they require significant physical manipulation, multimodal sensory integration (touch, proprioception, spatial awareness), embodied presence, complex social-emotional processing, creative synthesis, or contextual common sense reasoning.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p73">
<p class="ltx_p">## AG1 – Moderate human brain efficiency advantage</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p74">
<p class="ltx_p">Label tasks 1 if they involve some physical components, occasional multimodal inputs or some social/contextual interpretation, o</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p75">
<p class="ltx_p">## AG2 – Minimal human brain efficiency advantage</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p76">
<p class="ltx_p">Label tasks 2 if they can be performed largely through digital interfaces without physical manipulation, multimodal sensing, or significant need for social understanding, creativity, or contextual reasoning.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p77">
<p class="ltx_p">## Classification examples:</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p78">
<p class="ltx_p">Task: Write technical documentation for software</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p79">
<p class="ltx_p">Label: 2</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p80">
<p class="ltx_p">Explanation: Purely digital task requiring no physical manipulation or sensory input beyond reading and typing.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p81">
<p class="ltx_p">Task: Direct and coordinate activities of businesses or departments concerned with the production, pricing, sales, or distribution of products.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p82">
<p class="ltx_p">Label: 1</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p83">
<p class="ltx_p">Explanation: It requires some social skills, but not the main part of the task.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p84">
<p class="ltx_p">Task: Repair plumbing in residential buildings</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p85">
<p class="ltx_p">Label: 0</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p86">
<p class="ltx_p">Explanation: Requires physical manipulation, spatial reasoning, tactile feedback, and adaptation to unique physical environments.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p87">
<p class="ltx_p">CRITICAL: Base rankings  on the detailed criteria above. Consider the COMPLETE task description.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ax1.SSx1.p88">
<p class="ltx_p">IMPORTANT: Base your scores on the task description alone. Consider what the task fundamentally requires, not current technological limitations. Also, do not overanchor on the examples provided, but also give scores between them."</p>
</div>
</section>
<section class="ltx_subsection" id="Ax1.SSx2">
<h3 class="ltx_title ltx_title_subsection">Relationship between Human and AI-annotated Automation Score and Labor Market Data such as Wages and Employment <cite class="ltx_cite ltx_citemacro_citep">(Eloundou et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.13369v1#bib.bib13" title="">2024</a>)</cite>
</h3>
<figure class="ltx_figure" id="Ax1.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="251" id="Ax1.F7.g1" src="graphics/Picture1.png" width="333"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text" style="font-size:90%;"> Positive Relationship between Wages and exposure with insignificant inverted U-curve and no relationship between employment numbers and exposure (Eloundou et al., 2024)</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_subsection" id="Ax1.SSx3">
<h3 class="ltx_title ltx_title_subsection">Wages and Subhypotheses</h3>
<figure class="ltx_figure" id="Ax1.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="241" id="Ax1.F8.g1" src="graphics/exposure_ag_w_vs_logwage_2024.png" width="333"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" style="font-size:90%;"> Algorithmic Efficiency gap (AG) exposure vs log wages, 2024</span></figcaption>
</figure>
<figure class="ltx_figure" id="Ax1.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="241" id="Ax1.F9.g1" src="graphics/exposure_da_w_vs_logwage_2024.png" width="333"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span class="ltx_text" style="font-size:90%;"> Data Abundance (DA) exposure vs log wages, 2024</span></figcaption>
</figure>
<figure class="ltx_figure" id="Ax1.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="241" id="Ax1.F10.g1" src="graphics/exposure_pv_w_vs_logwage_2024.png" width="333"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span class="ltx_text" style="font-size:90%;">Productivity Variance (PV) exposure vs log wages, 2024</span></figcaption>
</figure>
<figure class="ltx_figure" id="Ax1.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="241" id="Ax1.F11.g1" src="graphics/exposure_tk_w_vs_logwage_2024.png" width="333"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span class="ltx_text" style="font-size:90%;">Tacit Knowledge (TK) exposure vs log wages, 2024</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Acemoglu and Restrepo (2020)</span>
<span class="ltx_bibblock">
Acemoglu, D. and Restrepo, P. (2020).

</span>
<span class="ltx_bibblock">Robots and Jobs: Evidence from US Labor Markets, <span class="ltx_text ltx_font_italic">Journal of Political Economy</span> <span class="ltx_text ltx_font_bold">128</span>(6): 2188–2244.

<br class="ltx_break"/><a class="ltx_ref" href="https://www.journals.uchicago.edu/doi/10.1086/705716" title="">https://www.journals.uchicago.edu/doi/10.1086/705716</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Autor (2014)</span>
<span class="ltx_bibblock">
Autor, D. (2014).

</span>
<span class="ltx_bibblock">Polanyi’s Paradox and the Shape of Employment Growth, <span class="ltx_text ltx_font_italic">Technical Report w20485</span>, National Bureau of Economic Research, Cambridge, MA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Autor (2024)</span>
<span class="ltx_bibblock">
Autor, D. (2024).

</span>
<span class="ltx_bibblock">Applying AI to Rebuild Middle Class Jobs.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Autor et al. (2023)</span>
<span class="ltx_bibblock">
Autor, D., Dube, A. and McGrew, A. (2023).

</span>
<span class="ltx_bibblock">The unexpected compression: Competition at work in the low wage labor market, <span class="ltx_text ltx_font_italic">Working Paper 31010</span>.

<br class="ltx_break"/><a class="ltx_ref" href="http://www.nber.org/papers/w31010" title="">http://www.nber.org/papers/w31010</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Autor (2013)</span>
<span class="ltx_bibblock">
Autor, D. H. (2013).

</span>
<span class="ltx_bibblock">The “task approach” to labor markets: an overview, <span class="ltx_text ltx_font_italic">Journal for Labour Market Research</span> <span class="ltx_text ltx_font_bold">46</span>(3): 185–199.

<br class="ltx_break"/><a class="ltx_ref" href="https://doi.org/10.1007/s12651-013-0128-z" title="">https://doi.org/10.1007/s12651-013-0128-z</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Autor and Dorn (2013)</span>
<span class="ltx_bibblock">
Autor, D. H. and Dorn, D. (2013).

</span>
<span class="ltx_bibblock">The Growth of Low-Skill Service Jobs and the Polarization of the US Labor Market, <span class="ltx_text ltx_font_italic">American Economic Review</span> <span class="ltx_text ltx_font_bold">103</span>(5): 1553–1597.

<br class="ltx_break"/><a class="ltx_ref" href="https://www-aeaweb-org.emedien.ub.uni-muenchen.de/articles?id=10.1257/aer.103.5.1553" title="">https://www-aeaweb-org.emedien.ub.uni-muenchen.de/articles?id=10.1257/aer.103.5.1553</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Autor and Thompson (2025)</span>
<span class="ltx_bibblock">
Autor, D. and Thompson, N. (2025).

</span>
<span class="ltx_bibblock">Expertise, <span class="ltx_text ltx_font_italic">Working paper / joseph r. schumpeter lecture</span>, Massachusetts Institute of Technology and NBER; MIT FutureTech, CSAIL, and Initiative on the Digital Economy.

</span>
<span class="ltx_bibblock">Presented at the European Economic Association annual meeting in Rotterdam on August 29, 2024, under the title “Does Automation Replace Experts or Complement Expertise? The Answer is Yes.”.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bresnahan (2024)</span>
<span class="ltx_bibblock">
Bresnahan, T. (2024).

</span>
<span class="ltx_bibblock">What innovation paths for AI to become a GPT?, <span class="ltx_text ltx_font_italic">Journal of Economics &amp; Management Strategy</span> <span class="ltx_text ltx_font_bold">33</span>(2): 305–316.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brynjolfsson et al. (n.d.)</span>
<span class="ltx_bibblock">
Brynjolfsson, E., Chandar, B. and Chen, R. (n.d.).

</span>
<span class="ltx_bibblock">Canaries in the Coal Mine? Six Facts about the Recent Employment Effects of Artificial Intelligence.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brynjolfsson et al. (2018)</span>
<span class="ltx_bibblock">
Brynjolfsson, E., Mitchell, T. and Rock, D. (2018).

</span>
<span class="ltx_bibblock">What Can Machines Learn, and What Does It Mean for Occupations and the Economy?, <span class="ltx_text ltx_font_italic">AEA Papers and Proceedings</span> <span class="ltx_text ltx_font_bold">108</span>: 43–47.

<br class="ltx_break"/><a class="ltx_ref" href="https://www.aeaweb.org/articles?id=10.1257/pandp.20181019" title="">https://www.aeaweb.org/articles?id=10.1257/pandp.20181019</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eloundou et al. (2023)</span>
<span class="ltx_bibblock">
Eloundou, T., Manning, S., Mishkin, P. and Rock, D. (2023).

</span>
<span class="ltx_bibblock">GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eloundou et al. (2024)</span>
<span class="ltx_bibblock">
Eloundou, T., Manning, S., Mishkin, P. and Rock, D. (2024).

</span>
<span class="ltx_bibblock">GPTs are GPTs: Labor market impact potential of LLMs, <span class="ltx_text ltx_font_italic">Science</span> <span class="ltx_text ltx_font_bold">384</span>(6702): 1306–1308.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Erdil (2024)</span>
<span class="ltx_bibblock">
Erdil, E. (2024).

</span>
<span class="ltx_bibblock">Moravec’s paradox and its implications.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Felten et al. (2021a)</span>
<span class="ltx_bibblock">
Felten, E., Raj, M. and Seamans, R. (2021a).

</span>
<span class="ltx_bibblock">Occupational, industry, and geographic exposure to artificial intelligence: A novel dataset and its potential uses, <span class="ltx_text ltx_font_italic">Strategic Management Journal</span> <span class="ltx_text ltx_font_bold">42</span>(12): 2195–2217.

<br class="ltx_break"/><a class="ltx_ref" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/smj.3286" title="">https://onlinelibrary.wiley.com/doi/abs/10.1002/smj.3286</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Felten et al. (2021b)</span>
<span class="ltx_bibblock">
Felten, E., Raj, M. and Seamans, R. (2021b).

</span>
<span class="ltx_bibblock">Occupational, industry, and geographic exposure to artificial intelligence: A novel dataset and its potential uses, <span class="ltx_text ltx_font_italic">Strategic Management Journal</span> <span class="ltx_text ltx_font_bold">42</span>(12): 2195–2217.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Felten et al. (2023)</span>
<span class="ltx_bibblock">
Felten, E. W., Raj, M. and Seamans, R. (2023).

</span>
<span class="ltx_bibblock">Occupational heterogeneity in exposure to generative ai, <span class="ltx_text ltx_font_italic">Available at SSRN 4414065</span> .

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Frey and Osborne (2017)</span>
<span class="ltx_bibblock">
Frey, C. B. and Osborne, M. A. (2017).

</span>
<span class="ltx_bibblock">The future of employment: How susceptible are jobs to computerisation?, <span class="ltx_text ltx_font_italic">Technological Forecasting and Social Change</span> <span class="ltx_text ltx_font_bold">114</span>: 254–280.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gruetzemacher et al. (2020)</span>
<span class="ltx_bibblock">
Gruetzemacher, R., Paradice, D. and Lee, K. B. (2020).

</span>
<span class="ltx_bibblock">Forecasting extreme labor displacement: A survey of AI practitioners, <span class="ltx_text ltx_font_italic">Technological Forecasting and Social Change</span> <span class="ltx_text ltx_font_bold">161</span>: 120323.

<br class="ltx_break"/><a class="ltx_ref" href="https://www.sciencedirect.com/science/article/pii/S0040162520311495" title="">https://www.sciencedirect.com/science/article/pii/S0040162520311495</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Handa et al. (2025)</span>
<span class="ltx_bibblock">
Handa, K., Tamkin, A., McCain, M., Huang, S., Durmus, E., Heck, S., Mueller, J., Hong, J., Ritchie, S., Belonax, T., Troy, K. K., Amodei, D., Kaplan, J., Clark, J. and Ganguli, D. (2025).

</span>
<span class="ltx_bibblock">Which Economic Tasks are Performed with AI? Evidence from Millions of Claude Conversations.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hui et al. (2023)</span>
<span class="ltx_bibblock">
Hui, X., Reshef, O. and Zhou, L. (2023).

</span>
<span class="ltx_bibblock">The Short-Term Effects of Generative Artificial Intelligence on Employment: Evidence from an Online Labor Market, <span class="ltx_text ltx_font_italic">Technical Report 4527336</span>, Rochester, NY.

<br class="ltx_break"/><a class="ltx_ref" href="https://papers.ssrn.com/abstract=4527336" title="">https://papers.ssrn.com/abstract=4527336</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ide (2025)</span>
<span class="ltx_bibblock">
Ide, E. (2025).

</span>
<span class="ltx_bibblock">Automation, AI, and the Intergenerational Transmission of Knowledge.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Korinek and Juelfs (2022)</span>
<span class="ltx_bibblock">
Korinek, A. and Juelfs, M. (2022).

</span>
<span class="ltx_bibblock">Preparing for the (Non-Existent?) Future of Work, <span class="ltx_text ltx_font_italic">Working Paper 30172</span>.

<br class="ltx_break"/><a class="ltx_ref" href="https://www.nber.org/papers/w30172" title="">https://www.nber.org/papers/w30172</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lake et al. (2017)</span>
<span class="ltx_bibblock">
Lake, B. M., Ullman, T. D., Tenenbaum, J. B. and Gershman, S. J. (2017).

</span>
<span class="ltx_bibblock">Building machines that learn and think like people, <span class="ltx_text ltx_font_italic">Behavioral and Brain Sciences</span> <span class="ltx_text ltx_font_bold">40</span>: e253.

<br class="ltx_break"/><a class="ltx_ref" href="https://doi.org/10.1017/S0140525X16001837" title="">https://doi.org/10.1017/S0140525X16001837</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lichtinger and Hosseini Maasoum (2025)</span>
<span class="ltx_bibblock">
Lichtinger, G. and Hosseini Maasoum, S. M. (2025).

</span>
<span class="ltx_bibblock">Generative AI as Seniority-Biased Technological Change: Evidence from U.S. Résumé and Job Posting Data.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell et al. (2025)</span>
<span class="ltx_bibblock">
Mitchell, J. L., Fuentes-Jimenez, M., Stone, H. L., Yablonski, M. and Yeatman, J. D. (2025).

</span>
<span class="ltx_bibblock">Visual word form area demonstrates individual and task-agnostic consistency but inter-individual variability, <span class="ltx_text ltx_font_italic">bioRxiv</span> pp. 2025–07.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moravec (1988)</span>
<span class="ltx_bibblock">
Moravec, H. (1988).

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Mind Children: The Future of Robot and Human Intelligence</span>, Harvard University Press, Cambridge, MA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Murray et al. (2025)</span>
<span class="ltx_bibblock">
Murray, C., Strauss, D., Burn-Murdoch, J. and Lim, S. (2025).

</span>
<span class="ltx_bibblock">Is ai killing graduate jobs?, <span class="ltx_text ltx_font_italic">Financial Times</span> .

</span>
<span class="ltx_bibblock">Accessed 2025-09-05.

<br class="ltx_break"/><a class="ltx_ref" href="https://www.ft.com/content/99b6acb7-a079-4f57-a7bd-8317c1fbb728" title="">https://www.ft.com/content/99b6acb7-a079-4f57-a7bd-8317c1fbb728</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Noy and Zhang (2023)</span>
<span class="ltx_bibblock">
Noy, S. and Zhang, W. (2023).

</span>
<span class="ltx_bibblock">Experimental evidence on the productivity effects of generative artificial intelligence, <span class="ltx_text ltx_font_italic">Science</span> <span class="ltx_text ltx_font_bold">381</span>(6654): 187–192.

<br class="ltx_break"/><a class="ltx_ref" href="https://www.science.org/doi/10.1126/science.adh2586" title="">https://www.science.org/doi/10.1126/science.adh2586</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Otis et al. (2023)</span>
<span class="ltx_bibblock">
Otis, N. G., Clarke, R., Delecourt, S., Holtz, D. and Koning, R. (2023).

</span>
<span class="ltx_bibblock">The Uneven Impact of Generative AI on Entrepreneurial Performance.

<br class="ltx_break"/><a class="ltx_ref" href="https://osf.io/hdjpk" title="">https://osf.io/hdjpk</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Restrepo (2023)</span>
<span class="ltx_bibblock">
Restrepo, P. (2023).

</span>
<span class="ltx_bibblock">Automation: Theory, Evidence, and Outlook, <span class="ltx_text ltx_font_italic">Working Paper 31910</span>.

<br class="ltx_break"/><a class="ltx_ref" href="https://www.nber.org/papers/w31910" title="">https://www.nber.org/papers/w31910</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tomlinson et al. (2025)</span>
<span class="ltx_bibblock">
Tomlinson, K., Jaffe, S., Wang, W., Counts, S. and Suri, S. (2025).

</span>
<span class="ltx_bibblock">Working with AI: Measuring the Occupational Implications of Generative AI.

</span>
<span class="ltx_bibblock">Comment: 40 pages Comment: 41 pages.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trammell and Korinek (2023)</span>
<span class="ltx_bibblock">
Trammell, P. and Korinek, A. (2023).

</span>
<span class="ltx_bibblock">Economic Growth under Transformative AI.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Webb (2019)</span>
<span class="ltx_bibblock">
Webb, M. (2019).

</span>
<span class="ltx_bibblock">The impact of artificial intelligence on the labor market, <span class="ltx_text ltx_font_italic">Available at SSRN 3482150</span> .

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Oct 15 09:55:39 2025 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
