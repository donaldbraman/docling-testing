<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation</title>
<!--Generated on Thu Oct 16 17:56:11 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="/static/browse/0.3.4/css/arxiv-html-papers-20250916.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2510.14949v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S1" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S2" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Works</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S3" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span><span class="ltx_text ltx_font_bold">DialectGen</span> Benchmark</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S3.SS1" title="In 3 DialectGen Benchmark ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S3.SS2" title="In 3 DialectGen Benchmark ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Dialect Speaker Validation and Filtering</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4.SS1" title="In 4 Experiments ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4.SS2" title="In 4 Experiments ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Benchmark Experiments</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Mitigation Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.SS1" title="In 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Baseline Methods</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.SS1.SSS0.Px1" title="In 5.1 Baseline Methods ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">UNet Finetuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.SS1.SSS0.Px2" title="In 5.1 Baseline Methods ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">Prompt Revision</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.SS2" title="In 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Our Method</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.SS2.SSS0.Px1" title="In 5.2 Our Method ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">Dialect Learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.SS2.SSS0.Px2" title="In 5.2 Our Method ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">Polysemy Control</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.SS2.SSS0.Px3" title="In 5.2 Our Method ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">KL Regularization</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.SS3" title="In 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Mitigation Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.SS3.SSS1" title="In 5.3 Mitigation Results ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.1 </span>Comparison with the Baselines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.SS3.SSS2" title="In 5.3 Mitigation Results ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.2 </span>Ablation Study</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.SS3.SSS2.Px1" title="In 5.3.2 Ablation Study ‣ 5.3 Mitigation Results ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">Base Model vs. Dialect Learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.SS3.SSS2.Px2" title="In 5.3.2 Ablation Study ‣ 5.3 Mitigation Results ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">Cosine Reg. vs. KL Reg.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.SS3.SSS2.Px3" title="In 5.3.2 Ablation Study ‣ 5.3 Mitigation Results ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">Adding Polysemy Ctrl.</span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S6" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S7" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S8" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Ethics Statement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S9" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Reproducibility Statement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S10" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10 </span>Acknowledgements</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A1" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Qualitative Comparison</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A2" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Implementation Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A2.SS0.SSS0.Px1" title="In Appendix B Implementation Details ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">Data Preparation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A2.SS0.SSS0.Px2" title="In Appendix B Implementation Details ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">Training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A2.SS0.SSS0.Px3" title="In Appendix B Implementation Details ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">About T2Video Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A3" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Model Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A4" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Dataset Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A5" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Human Annotation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A6" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Mitigation Results on Stable Diffusion XL</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A7" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Grammatical vs. Lexical Robustness in Multimodal Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A8" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">H </span>Performance by Dialect</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A9" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span>Use of AI tools</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A10" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">J </span>Future Work</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A10.SS0.SSS0.Px1" title="In Appendix J Future Work ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">Investigating Cultural and Representational Biases</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A10.SS0.SSS0.Px2" title="In Appendix J Future Work ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">Exploring Grammatical and Joint Dialect Variations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A10.SS0.SSS0.Px3" title="In Appendix J Future Work ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">Investigating Downstream Impacts of Dialectal Performance Gaps</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A10.SS0.SSS0.Px4" title="In Appendix J Future Work ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">Extending Evaluation to Multi-Lexeme Prompts</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A10.SS0.SSS0.Px5" title="In Appendix J Future Work ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_title">Applying the Mitigation Strategy to Text-to-Video Models</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yu Zhou<sup class="ltx_sup"><span class="ltx_note ltx_role_footnote" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Core contributors.</span></span></span></sup>
<sup class="ltx_sup"><span class="ltx_note ltx_role_footnote" id="footnotex2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Project lead.</span></span></span></sup>, Sohyun An<sup class="ltx_sup"><span class="ltx_note ltx_role_footnote" id="footnotex3"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Core contributors.</span></span></span></sup>, Haikang Deng<sup class="ltx_sup"><span class="ltx_note ltx_role_footnote" id="footnotex4"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Core contributors.</span></span></span></sup>, Da Yin, Clark Peng, Cho-Jui Hsieh,
<br class="ltx_break"/><span class="ltx_text ltx_font_bold">Kai-Wei Chang, Nanyun Peng</span>
<br class="ltx_break"/>University of California, Los Angeles
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">{yuzhou, kwchang, violetpeng}@cs.ucla.edu</span>
<br class="ltx_break"/>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">Contact languages like English exhibit rich regional variations in the form of dialects, which are often used by dialect speakers interacting with generative models. However, can multimodal generative models effectively produce content given dialectal textual input? In this work, we study this question by constructing a new large-scale benchmark spanning six common English dialects. We work with dialect speakers to collect and verify over 4,200 unique prompts and evaluate on 17 image and video generative models. Our automatic and human evaluation results show that current state-of-the-art multimodal generative models exhibit 32.26% to 48.17% performance degradation when a single dialect word is used in the prompt. Common mitigation methods such as fine-tuning and prompt rewriting can only improve dialect performance by small margins (&lt; 7%), while potentially incurring significant performance degradation in Standard American English (SAE). To this end, we design a general encoder-based mitigation strategy for multimodal generative models. Our method teaches the model to recognize new dialect features while preserving SAE performance. Experiments on models such as Stable Diffusion 1.5 show that our method is able to simultaneously raise performance on five dialects to be on par with SAE (+34.4%), while incurring near-zero cost to SAE performance. Code and data at:<a class="ltx_ref ltx_href" href="https://dialectgen.github.io" title=""> <span class="ltx_text ltx_font_typewriter ltx_font_bold">dialectgen.github.io</span></a>.</p>
</div>
<figure class="ltx_figure" id="S0.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="326" id="S0.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
<span class="ltx_text ltx_font_bold">Multimodal Generative Model Outputs</span> on semantically identical prompts that differ only in one synonymous lexical feature in <span class="ltx_text ltx_font_bold" style="--ltx-fg-color:#00B0F0;">Standard American English</span> (top) / <span class="ltx_text ltx_font_bold" style="--ltx-fg-color:#A02B93;">a lower-resource English dialect</span> (bottom).
</figcaption>
</figure>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p">Linguists have defined over 160 dialects <cite class="ltx_cite ltx_citemacro_citep">(Aeni et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib1" title="">2021</a>)</cite> within the English language, with three out of four English speakers having a dialect background other than Standard American or British English <cite class="ltx_cite ltx_citemacro_citep">(Crystal, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib12" title="">2003</a>)</cite>. Despite this rich diversity, current pre-training paradigms employ content filters that can exclude data involving lower-resource English dialects other than Standard American and British English <cite class="ltx_cite ltx_citemacro_citep">(Gururangan et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib21" title="">2022</a>)</cite>, reducing the effectiveness of pretrained models on inputs from other dialects <cite class="ltx_cite ltx_citemacro_citep">(Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib30" title="">2023</a>)</cite>. Prior works have shown significant allocational harms toward dialect speakers caused by such dialect performance discrepancies in machine learning applications <cite class="ltx_cite ltx_citemacro_citep">(Hovy &amp; Spruit, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib25" title="">2016</a>; Bender et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib3" title="">2021</a>)</cite>, making the observation of similar performance trends in multimodal generative models an alarming sign.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p">As shown in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S0.F1" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">1</span></a>, while current multimodal generative models can accurately generate high quality image and video content given Standard American English (SAE) prompts (left); they fail in various manners when provided with semantically equivalent prompts containing a single synonymous dialect word (right). Stable Diffusion 3.5 Large <cite class="ltx_cite ltx_citemacro_citep">(Esser et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib16" title="">2024</a>)</cite> fails to generate "ang pow", which is commonly used in Singaporean English to mean "red packet", and FLUX.1 [dev] <cite class="ltx_cite ltx_citemacro_citep">(Black Forest Labs, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib6" title="">2024</a>)</cite> fails to generate "brinjal", which is synonymous with "eggplant" in Indian English. Furthermore, when the dialect lexeme is polysemous, <span class="ltx_text ltx_font_italic">i.e.</span>, has an alternative meaning in SAE, models tend to always generate content that align with the SAE meaning, even when the context makes such interpretation highly improbable. For example, DALL-E Mini <cite class="ltx_cite ltx_citemacro_citep">(Dayma et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib15" title="">2021</a>)</cite> generations of "A man driving his whip" fail to capture the correct meaning of "whip" as "car" in African American English, given clear context indications.
Similar failure modes are observed in text-to-video generative models: Wan 2.1 <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib46" title="">2025</a>)</cite> fails to correctly render "carnal", which refers to "brother" in Chicano English.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p">In this work, we construct <span class="ltx_text ltx_font_bold">DialectGen</span>, a new large-scale benchmark evaluating dialect robustness in image and video generation. Our benchmark dataset spans six common English dialects, including Standard American English (SAE), British English (BrE), Chicano English (ChE), Indian English (InE), and Singaporean English (SgE). For each dialect other than SAE, we create SAE Prompt / Dialect Prompt pairs that are semantically identical besides switching a single SAE lexeme for a synonymous dialect lexeme. We work with dialect speaker annotators to create a rigorous feature selection and prompt filtering pipeline that ensures the final dialect prompts are (1) exactly synonymous with the SAE prompt; (2) valid in the dialect context; and (3) non-ambiguous (for polysemous lexemes). These strictly enforced quality guarantees facilitate the development of simple yet effective automatic and human evaluation metrics for evaluating generative model performance. We experiment with 17 widely used image and video generative models on <span class="ltx_text ltx_font_bold">DialectGen</span>, demonstrating up to 38.63% and 48.17% performance drops for SOTA open-weights image and video generative models, respectively.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p">To alleviate such significant dialect performance drops observed in current multimodal generative models, we design a general encoder-based learning strategy that enhances dialect robustness for diffusion-based multimodal generative models. Our method teaches the model’s text encoder to recognize dialect lexemes while retaining its knowledge of SAE polysemous lexemes. We also include an encoder-based KL regularization loss based on image-SAE caption datasets to regulate output distribution shifts. Experiments on five dialects show that our method is able to simultaneously improve Stable Diffusion 1.5 <cite class="ltx_cite ltx_citemacro_citep">(Rombach et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib41" title="">2022</a>)</cite> and SDXL <cite class="ltx_cite ltx_citemacro_citep">(Podell et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib37" title="">2023</a>)</cite> performance on five dialects to be on par with SAE performance. At the same time, we observe near zero (&lt; 1%) SAE performance drop on the general MSCOCO <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib31" title="">2014</a>)</cite> validation set for both models.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p">Our key contributions include:</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">DialectGen</span>, a new large-scale multi-dialectal benchmark for evaluating dialect robustness in text-to-image and text-to-video generation.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p">Comprehensive evaluation and analysis of 17 multimodal generative models and five baseline mitigation methods on <span class="ltx_text ltx_font_bold">DialectGen</span>.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i3.p1">
<p class="ltx_p">A high-performing method for improving dialect robustness in multimodal generation while maintaining strong SAE performance.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>
<figure class="ltx_table" id="S2.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Example paired textual data entries from the <span class="ltx_text ltx_font_bold">DialectGen</span> dataset, including <span class="ltx_text ltx_font_bold">Lexeme</span>, <span class="ltx_text ltx_font_bold">Concise Prompt</span>, and <span class="ltx_text ltx_font_bold">Detailed Prompt</span>. Dialect name abbreviations: <span class="ltx_text" style="--ltx-fg-color:#00B0F0;">SAE</span> (Standard American English), <span class="ltx_text" style="--ltx-fg-color:#A02B93;">AAE</span> (African American English), <span class="ltx_text" style="--ltx-fg-color:#A02B93;">BrE</span> (British English), <span class="ltx_text" style="--ltx-fg-color:#A02B93;">SgE</span> (Singaporean English).</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text ltx_font_bold">Lexeme</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt"><span class="ltx_text ltx_font_bold">Concise Prompt</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_tt">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:202.0pt;"><span class="ltx_text ltx_font_bold">Detailed Prompt</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="--ltx-fg-color:#00B0F0;">SAE</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="--ltx-fg-color:#00B0F0;">sneakers</span></td>
<td class="ltx_td ltx_align_left ltx_border_t">brand new <span class="ltx_text" style="--ltx-fg-color:#00B0F0;">sneakers</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:202.0pt;">a little girl wearing a pair of stylish white <span class="ltx_text" style="--ltx-fg-color:#00B0F0;">sneakers</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="--ltx-fg-color:#A02B93;">AAE</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="--ltx-fg-color:#A02B93;">kicks</span></td>
<td class="ltx_td ltx_align_left">brand new <span class="ltx_text" style="--ltx-fg-color:#A02B93;">kicks</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:202.0pt;">a little girl wearing a pair of stylish white <span class="ltx_text" style="--ltx-fg-color:#A02B93;">kicks</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="--ltx-fg-color:#00B0F0;">SAE</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="--ltx-fg-color:#00B0F0;">bathroom</span></td>
<td class="ltx_td ltx_align_left ltx_border_t">a spacious <span class="ltx_text" style="--ltx-fg-color:#00B0F0;">bathroom</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:202.0pt;">a clean and tidy <span class="ltx_text" style="--ltx-fg-color:#00B0F0;">bathroom</span> with shiny blue wall tiles</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="--ltx-fg-color:#A02B93;">BrE</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="--ltx-fg-color:#A02B93;">loo</span></td>
<td class="ltx_td ltx_align_left">a spacious <span class="ltx_text" style="--ltx-fg-color:#A02B93;">loo</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:202.0pt;">a clean and tidy <span class="ltx_text" style="--ltx-fg-color:#A02B93;">loo</span> with shiny blue wall tiles</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="--ltx-fg-color:#00B0F0;">SAE</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="--ltx-fg-color:#00B0F0;">squid</span></td>
<td class="ltx_td ltx_align_left ltx_border_t">a <span class="ltx_text" style="--ltx-fg-color:#00B0F0;">squid</span> on a counter</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:202.0pt;">a large <span class="ltx_text" style="--ltx-fg-color:#00B0F0;">squid</span> in an aquarium with colorful coral</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text" style="--ltx-fg-color:#A02B93;">SgE</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text" style="--ltx-fg-color:#A02B93;">sotong</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb">a <span class="ltx_text" style="--ltx-fg-color:#A02B93;">sotong</span> on a counter</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:202.0pt;">a large <span class="ltx_text" style="--ltx-fg-color:#A02B93;">sotong</span> in an aquarium with colorful coral</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p">Linguists define dialects as regional variations of a language distinguished by unique features in lexicon, phonology, and grammar from each other, together constituting a single language <cite class="ltx_cite ltx_citemacro_citep">(Hudson, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib26" title="">1996</a>; Chambers &amp; Trudgill, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib9" title="">1998</a>; Fromkin et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib18" title="">1998</a>; Nerbonne, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib33" title="">2009</a>; Wardhaugh &amp; Fuller, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib48" title="">2021</a>)</cite>. English, like any other language, is subject to such variations. However, most dataset resources and pre-training paradigms focus only on Standard American and British English <cite class="ltx_cite ltx_citemacro_citep">(Gururangan et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib21" title="">2022</a>)</cite>, leading to dialect robustness issues and performance gaps in downstream machine learning applications. Previous works have analyzed and explored such dialectal performance gaps in NLP tasks like QA <cite class="ltx_cite ltx_citemacro_citep">(Ziems et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib55" title="">2023</a>)</cite>, NLI <cite class="ltx_cite ltx_citemacro_citep">(Ziems et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib54" title="">2022</a>)</cite>, dependency
parsing, and POS tagging <cite class="ltx_cite ltx_citemacro_citep">(Blodgett et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib7" title="">2018</a>; Jørgensen et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib28" title="">2015</a>)</cite>. Recent works have also noticed the impact of dialect variations on text-to-image generation <cite class="ltx_cite ltx_citemacro_citep">(Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib30" title="">2023</a>; Wan et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib45" title="">2024</a>)</cite>. Along this line of research, we create the first large-scale benchmark of dialect robustness in multimodal generation, evaluating both text-to-image and text-to-video generative models on inputs across six different dialects.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p">Moreover, while lexicon, phonology, and grammar are the three key aspects that distinguish each dialect from others, existing works in Dialectal NLP have so far mainly focused on the grammar variations of dialects <cite class="ltx_cite ltx_citemacro_citep">(Ziems et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib54" title="">2022</a>; <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib55" title="">2023</a>; Blodgett et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib7" title="">2018</a>; Jørgensen et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib28" title="">2015</a>)</cite>. In this work, we provide the first large-scale dataset of dialectal lexical variations, bridging the gap towards holistic dialectal variation evaluation and building dialect-robust machine learning models.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span class="ltx_text ltx_font_bold">DialectGen</span> Benchmark</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Dataset Construction</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p">To select dialect features for our benchmark dataset, we first gather dialect lexemes along with their dictionary definitions and example usages from publicly available regional English dictionaries including The Oxford Regional English Dictionary <cite class="ltx_cite ltx_citemacro_citep">(Gates et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib19" title="">2023</a>)</cite>, Dictionary of American regional english <cite class="ltx_cite ltx_citemacro_citep">(Cassidy et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib8" title="">1985</a>)</cite>, A dictionary of Singlish and Singapore English <cite class="ltx_cite ltx_citemacro_citep">(Lee, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib29" title="">2004</a>)</cite>, Dictionary of Indian English <cite class="ltx_cite ltx_citemacro_citep">(Subhash, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib43" title="">2020</a>)</cite>, and The Oxford Dictionary of African American English <cite class="ltx_cite ltx_citemacro_citep">(Heinmiller, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib23" title="">2023</a>)</cite>. We collect a total of 1126 dialect lexemes for initial processing.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p">Based on the dictionary definitions of the selected lexemes, we manually filter out: (1) potentially derogatory lexemes; (2) culture-unique lexemes without Standard American English (SAE) equivalents.
We then carefully read the dictionary definitions of each remaining dialect lexeme and assign it a SAE equivalent lexeme with the same meaning, creating a list of pair-wise corresponding lexical features for each dialect. Examples of selected pairs can be seen in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S2.T1" title="In 2 Related Works ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S0.F1" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p">Next, we use GPT4o <cite class="ltx_cite ltx_citemacro_citep">(Hurst et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib27" title="">2024</a>)</cite> to generate prompts for each SAE word in our paired lexical feature set. We specifically instruct the model to generate prompts describing a visual scene with the lexeme playing a central role, which can be one of the following depending on the semantic role of the lexeme: (1) The central object in the scene; (2) The main action of the central object; (3) A prominent descriptive feature of the central object.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p">We also ask the model to create two different sets of <span class="ltx_text ltx_font_bold">Concise</span> and <span class="ltx_text ltx_font_bold">Detailed</span> prompts for each SAE lexeme. Then we simply replace the SAE lexeme in the prompts with the dialect lexeme (<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S2.T1" title="In 2 Related Works ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">1</span></a>) to create our two dialect evaluation settings:</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Concise</span> prompts generally consist of <math alttext="\leq" class="ltx_Math" display="inline" id="S3.I1.i1.p1.m1" intent=":literal"><semantics><mo>≤</mo><annotation encoding="application/x-tex">\leq</annotation></semantics></math> 6 words, with the goal of providing a more challenging evaluation setting where the multimodal generative model is not given too many contextual hints about the lexeme’s meaning.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S3.I1.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Detailed</span> prompts generally consist of <math alttext="\geq" class="ltx_Math" display="inline" id="S3.I1.i2.p1.m1" intent=":literal"><semantics><mo>≥</mo><annotation encoding="application/x-tex">\geq</annotation></semantics></math> 9 words, with the goal of providing a more relaxed evaluation setting where the multimodal generative model can use more contextual hints to infer the lexeme’s meaning.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<p class="ltx_p">These two evaluation settings also intuitively represent two common user input styles for multimodal generative models, where casual users may tend to provide concise prompts and professional users may be more inclined to write detailed prompts. Across <span class="ltx_text ltx_font_bold">Concise</span> and <span class="ltx_text ltx_font_bold">Detailed</span> evaluation settings, we generate a total of 6552 prompts.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p6">
<p class="ltx_p">For specific Dialect Prompt / SAE Prompt pairs where the dialect lexeme has an additional polysemous meaning recorded in an SAE dictionary <cite class="ltx_cite ltx_citemacro_citep">(Webster, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib49" title="">1869</a>)</cite>, we generate an additional SAE Polysemy Prompt, where the lexeme is used unambiguously in its SAE meaning. This data can be used for regulating model behavior in training scenarios.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Dialect Speaker Validation and Filtering</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p">Before admitting the generated prompts to our final evaluation benchmark, we carefully verify their quality and correctness with dialect speaker human annotators. We created a specialized Amazon MTurk interface (<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A5.F4" title="In Appendix E Human Annotation Details ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">4</span></a>) for prompt annotation and matching potential dialect speaker annotators to their spoken dialect: each human annotator must first self-identify their dialect background and then complete a dialect speaker assessment quiz <cite class="ltx_cite ltx_citemacro_citep">(Ziems et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib55" title="">2023</a>)</cite> that matches each annotator to at most one dialect (<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A5.F5" title="In Appendix E Human Annotation Details ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">5</span></a>). Annotators are only selected if both their self-identified dialect background and their quiz assessment result match to the same dialect. More details on human annotation are available in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A5" title="Appendix E Human Annotation Details ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Appendix</span>˜<span class="ltx_text ltx_ref_tag">E</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p">After each dialect speaker is selected, they will be presented with Dialect Prompt / SAE Prompt pairs where the only difference is the dialect lexeme being swapped with its SAE equivalent word. For each pair of prompts, the dialect speaker must answer two questions:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<ol class="ltx_enumerate" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p">Does the given Dialect Prompt make sense in said Dialect and correspond exactly in meaning to the given SAE prompt in Standard American English? (Yes / No / I don’t know)</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para ltx_noindent" id="S3.I2.i2.p1">
<p class="ltx_p">Is the given Dialect Prompt ambiguous? <span class="ltx_text ltx_font_italic">i.e.</span>, Does it have a reasonable alternative interpretation in the Standard American English (SAE) context? (Yes / No / I don’t know)</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p">Each Dialect Prompt / SAE Prompt pair is presented to two independent dialect speaker annotators. A pair is included in the final dataset only if both human annotators answer “Yes” to the first question and “No” to the second question. Consistent responses ensure the dialect prompt is: (1) exactly synonymous with the SAE prompt. (2) valid in the dialectal context. (3) non-ambiguous (for polysemous lexemes).</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p">In total, dialect speaker filtering further removes 35.9% of all generated prompts, resulting in a final dataset containing 4,200 validated prompts.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span><span class="ltx_text ltx_font_bold">DialectGen</span> benchmark results for popular text-to-image and text-to-video generative models, including <span class="ltx_text ltx_font_bold">Dialect-wise Performance Drop</span> measured by VQAScore <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib32" title="">2024</a>)</cite>; and <span class="ltx_text ltx_font_bold">Overall Performance Drop</span> measured by human eval, VQAScore, and CLIPScore <cite class="ltx_cite ltx_citemacro_citep">(Hessel et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib24" title="">2021</a>)</cite>. Cells are highlighted based on numerical value normalized across the entire table, with darker red indicating a higher performance drop in the given metric.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:397.5pt;height:320.3pt;vertical-align:-158.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-86.2pt,69.5pt) scale(0.697438194189873,0.697438194189873) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" colspan="2"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span class="ltx_text ltx_font_bold">Model</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3"><span class="ltx_text ltx_font_bold">Overall Performance Drop (%) <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T2.m1" intent=":literal"><semantics><mo stretchy="false">↓</mo><annotation encoding="application/x-tex">\downarrow</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5"><span class="ltx_text ltx_font_bold">Dialect-wise Performance Drop (%) <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T2.m2" intent=":literal"><semantics><mo stretchy="false">↓</mo><annotation encoding="application/x-tex">\downarrow</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row" colspan="2"></th>
<td class="ltx_td ltx_align_center">Human</td>
<td class="ltx_td ltx_align_center">VQAScore</td>
<td class="ltx_td ltx_align_center ltx_border_r">CLIPScore</td>
<td class="ltx_td ltx_align_center">AAE</td>
<td class="ltx_td ltx_align_center">BrE</td>
<td class="ltx_td ltx_align_center">ChE</td>
<td class="ltx_td ltx_align_center">InE</td>
<td class="ltx_td ltx_align_center">SgE</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" rowspan="18">
<div class="ltx_inline-block ltx_transformed_outer" style="width:8.9pt;height:85.8pt;vertical-align:-40.4pt;"><span class="ltx_transformed_inner" style="width:85.7pt;transform:translate(-38.4pt,-38.4pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Concise Prompts</span></p>
</span></div>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" rowspan="13">
<div class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:49.6pt;vertical-align:-21.3pt;"><span class="ltx_transformed_inner" style="width:49.6pt;transform:translate(-21.3pt,-21.3pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">T2I Models</span></p>
</span></div>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Stable Diffusion 1.4</th>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FF9E9E;"><span class="ltx_text" style="--ltx-bg-color:#FF9E9E;">28.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFA3A3;"><span class="ltx_text" style="--ltx-bg-color:#FFA3A3;">26.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#FFE3E3;"><span class="ltx_text" style="--ltx-bg-color:#FFE3E3;">10.35</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFBABA;"><span class="ltx_text" style="--ltx-bg-color:#FFBABA;">20.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFE6E6;"><span class="ltx_text" style="--ltx-bg-color:#FFE6E6;">9.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FF8282;"><span class="ltx_text" style="--ltx-bg-color:#FF8282;">34.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FF6B6B;"><span class="ltx_text" style="--ltx-bg-color:#FF6B6B;">41.27</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFA1A1;"><span class="ltx_text" style="--ltx-bg-color:#FFA1A1;">26.96</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Stable Diffusion 1.5</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9696;"><span class="ltx_text" style="--ltx-bg-color:#FF9696;">29.77</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA1A1;"><span class="ltx_text" style="--ltx-bg-color:#FFA1A1;">27.06</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFE3E3;"><span class="ltx_text" style="--ltx-bg-color:#FFE3E3;">10.32</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFBFBF;"><span class="ltx_text" style="--ltx-bg-color:#FFBFBF;">19.51</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE8E8;"><span class="ltx_text" style="--ltx-bg-color:#FFE8E8;">8.66</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF7D7D;"><span class="ltx_text" style="--ltx-bg-color:#FF7D7D;">36.5</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6666;"><span class="ltx_text" style="--ltx-bg-color:#FF6666;">42.15</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9C9C;"><span class="ltx_text" style="--ltx-bg-color:#FF9C9C;">28.48</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Stable Diffusion 2.1</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9191;"><span class="ltx_text" style="--ltx-bg-color:#FF9191;">31.46</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9C9C;"><span class="ltx_text" style="--ltx-bg-color:#FF9C9C;">28.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFDEDE;"><span class="ltx_text" style="--ltx-bg-color:#FFDEDE;">11.7</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFABAB;"><span class="ltx_text" style="--ltx-bg-color:#FFABAB;">24.35</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE6E6;"><span class="ltx_text" style="--ltx-bg-color:#FFE6E6;">9.31</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF5C5C;"><span class="ltx_text" style="--ltx-bg-color:#FF5C5C;">44.82</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6B6B;"><span class="ltx_text" style="--ltx-bg-color:#FF6B6B;">41.12</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9C9C;"><span class="ltx_text" style="--ltx-bg-color:#FF9C9C;">28.89</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Stable Diffusion XL</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9696;"><span class="ltx_text" style="--ltx-bg-color:#FF9696;">29.8</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA3A3;"><span class="ltx_text" style="--ltx-bg-color:#FFA3A3;">26.69</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFE0E0;"><span class="ltx_text" style="--ltx-bg-color:#FFE0E0;">10.88</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFB0B0;"><span class="ltx_text" style="--ltx-bg-color:#FFB0B0;">23.37</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFEBEB;"><span class="ltx_text" style="--ltx-bg-color:#FFEBEB;">7.95</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6B6B;"><span class="ltx_text" style="--ltx-bg-color:#FF6B6B;">41.22</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF7373;"><span class="ltx_text" style="--ltx-bg-color:#FF7373;">38.74</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFB5B5;"><span class="ltx_text" style="--ltx-bg-color:#FFB5B5;">22.17</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Stable Diffusion 3</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8F8F;"><span class="ltx_text" style="--ltx-bg-color:#FF8F8F;">31.89</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9999;"><span class="ltx_text" style="--ltx-bg-color:#FF9999;">29.01</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFE0E0;"><span class="ltx_text" style="--ltx-bg-color:#FFE0E0;">10.81</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9E9E;"><span class="ltx_text" style="--ltx-bg-color:#FF9E9E;">27.89</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE8E8;"><span class="ltx_text" style="--ltx-bg-color:#FFE8E8;">8.64</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6666;"><span class="ltx_text" style="--ltx-bg-color:#FF6666;">42.67</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6E6E;"><span class="ltx_text" style="--ltx-bg-color:#FF6E6E;">40.69</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA8A8;"><span class="ltx_text" style="--ltx-bg-color:#FFA8A8;">25.12</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Stable Diffusion 3.5 Large</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8C8C;"><span class="ltx_text" style="--ltx-bg-color:#FF8C8C;">32.31</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9999;"><span class="ltx_text" style="--ltx-bg-color:#FF9999;">29.43</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFDEDE;"><span class="ltx_text" style="--ltx-bg-color:#FFDEDE;">11.37</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9C9C;"><span class="ltx_text" style="--ltx-bg-color:#FF9C9C;">28.3</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE6E6;"><span class="ltx_text" style="--ltx-bg-color:#FFE6E6;">9.74</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6666;"><span class="ltx_text" style="--ltx-bg-color:#FF6666;">42.66</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6969;"><span class="ltx_text" style="--ltx-bg-color:#FF6969;">41.9</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFABAB;"><span class="ltx_text" style="--ltx-bg-color:#FFABAB;">24.56</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Stable Diffusion 3.5 Large Turbo</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8A8A;"><span class="ltx_text" style="--ltx-bg-color:#FF8A8A;">32.92</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9494;"><span class="ltx_text" style="--ltx-bg-color:#FF9494;">30.28</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFDEDE;"><span class="ltx_text" style="--ltx-bg-color:#FFDEDE;">11.34</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9494;"><span class="ltx_text" style="--ltx-bg-color:#FF9494;">30.33</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE6E6;"><span class="ltx_text" style="--ltx-bg-color:#FFE6E6;">9.27</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6161;"><span class="ltx_text" style="--ltx-bg-color:#FF6161;">43.6</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6666;"><span class="ltx_text" style="--ltx-bg-color:#FF6666;">42.49</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA6A6;"><span class="ltx_text" style="--ltx-bg-color:#FFA6A6;">25.72</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Flux.1 [dev]</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF7D7D;"><span class="ltx_text" style="--ltx-bg-color:#FF7D7D;">36.43</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8C8C;"><span class="ltx_text" style="--ltx-bg-color:#FF8C8C;">32.26</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFE0E0;"><span class="ltx_text" style="--ltx-bg-color:#FFE0E0;">10.88</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9494;"><span class="ltx_text" style="--ltx-bg-color:#FF9494;">30.61</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE0E0;"><span class="ltx_text" style="--ltx-bg-color:#FFE0E0;">10.83</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF5E5E;"><span class="ltx_text" style="--ltx-bg-color:#FF5E5E;">44.64</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6666;"><span class="ltx_text" style="--ltx-bg-color:#FF6666;">42.59</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8C8C;"><span class="ltx_text" style="--ltx-bg-color:#FF8C8C;">32.62</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DALL-E Mini</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8585;"><span class="ltx_text" style="--ltx-bg-color:#FF8585;">34.29</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8F8F;"><span class="ltx_text" style="--ltx-bg-color:#FF8F8F;">31.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFDEDE;"><span class="ltx_text" style="--ltx-bg-color:#FFDEDE;">11.71</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8787;"><span class="ltx_text" style="--ltx-bg-color:#FF8787;">33.91</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFEBEB;"><span class="ltx_text" style="--ltx-bg-color:#FFEBEB;">8.18</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF5454;"><span class="ltx_text" style="--ltx-bg-color:#FF5454;">47.11</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6363;"><span class="ltx_text" style="--ltx-bg-color:#FF6363;">42.85</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA8A8;"><span class="ltx_text" style="--ltx-bg-color:#FFA8A8;">25.51</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DALL-E 2</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF7575;"><span class="ltx_text" style="--ltx-bg-color:#FF7575;">38.63</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8C8C;"><span class="ltx_text" style="--ltx-bg-color:#FF8C8C;">32.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFE3E3;"><span class="ltx_text" style="--ltx-bg-color:#FFE3E3;">9.97</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8080;"><span class="ltx_text" style="--ltx-bg-color:#FF8080;">35.87</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFEBEB;"><span class="ltx_text" style="--ltx-bg-color:#FFEBEB;">7.95</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF4D4D;"><span class="ltx_text" style="--ltx-bg-color:#FF4D4D;">48.78</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF5454;"><span class="ltx_text" style="--ltx-bg-color:#FF5454;">47.21</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFADAD;"><span class="ltx_text" style="--ltx-bg-color:#FFADAD;">24.14</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DALL-E 3</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA3A3;"><span class="ltx_text" style="--ltx-bg-color:#FFA3A3;">26.55</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFABAB;"><span class="ltx_text" style="--ltx-bg-color:#FFABAB;">24.39</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFE6E6;"><span class="ltx_text" style="--ltx-bg-color:#FFE6E6;">9.32</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC2C2;"><span class="ltx_text" style="--ltx-bg-color:#FFC2C2;">18.97</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFFCFC;"><span class="ltx_text" style="--ltx-bg-color:#FFFCFC;">3.58</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6969;"><span class="ltx_text" style="--ltx-bg-color:#FF6969;">41.95</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8F8F;"><span class="ltx_text" style="--ltx-bg-color:#FF8F8F;">31.9</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA8A8;"><span class="ltx_text" style="--ltx-bg-color:#FFA8A8;">25.56</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DALL-E 3 (w/ Prompt Rewrite)</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFBDBD;"><span class="ltx_text" style="--ltx-bg-color:#FFBDBD;">20.19</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC4C4;"><span class="ltx_text" style="--ltx-bg-color:#FFC4C4;">18.25</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFF0F0;"><span class="ltx_text" style="--ltx-bg-color:#FFF0F0;">6.69</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFB5B5;"><span class="ltx_text" style="--ltx-bg-color:#FFB5B5;">22.11</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFF2F2;"><span class="ltx_text" style="--ltx-bg-color:#FFF2F2;">6.48</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA3A3;"><span class="ltx_text" style="--ltx-bg-color:#FFA3A3;">26.86</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFB0B0;"><span class="ltx_text" style="--ltx-bg-color:#FFB0B0;">23.05</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFD9D9;"><span class="ltx_text" style="--ltx-bg-color:#FFD9D9;">12.74</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">gpt-image-1 (4o Image Gen)</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFB5B5;"><span class="ltx_text" style="--ltx-bg-color:#FFB5B5;">22.18</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFBFBF;"><span class="ltx_text" style="--ltx-bg-color:#FFBFBF;">19.18</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFEDED;"><span class="ltx_text" style="--ltx-bg-color:#FFEDED;">7.65</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA6A6;"><span class="ltx_text" style="--ltx-bg-color:#FFA6A6;">26.12</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFF7F7;"><span class="ltx_text" style="--ltx-bg-color:#FFF7F7;">5.2</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA6A6;"><span class="ltx_text" style="--ltx-bg-color:#FFA6A6;">26.09</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA3A3;"><span class="ltx_text" style="--ltx-bg-color:#FFA3A3;">26.51</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFDBDB;"><span class="ltx_text" style="--ltx-bg-color:#FFDBDB;">11.99</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" rowspan="5">
<div class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:53.2pt;vertical-align:-23.1pt;"><span class="ltx_transformed_inner" style="width:53.2pt;transform:translate(-23.1pt,-23.1pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">T2V Models</span></p>
</span></div>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Cosmos-1</th>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFA8A8;"><span class="ltx_text" style="--ltx-bg-color:#FFA8A8;">25.41</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFBABA;"><span class="ltx_text" style="--ltx-bg-color:#FFBABA;">20.49</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#FFF0F0;"><span class="ltx_text" style="--ltx-bg-color:#FFF0F0;">6.66</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFB5B5;"><span class="ltx_text" style="--ltx-bg-color:#FFB5B5;">22.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFE6E6;"><span class="ltx_text" style="--ltx-bg-color:#FFE6E6;">9.69</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFA6A6;"><span class="ltx_text" style="--ltx-bg-color:#FFA6A6;">26.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFA1A1;"><span class="ltx_text" style="--ltx-bg-color:#FFA1A1;">27.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFC7C7;"><span class="ltx_text" style="--ltx-bg-color:#FFC7C7;">17.09</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Open-Sora</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9696;"><span class="ltx_text" style="--ltx-bg-color:#FF9696;">29.98</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA3A3;"><span class="ltx_text" style="--ltx-bg-color:#FFA3A3;">26.63</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFE8E8;"><span class="ltx_text" style="--ltx-bg-color:#FFE8E8;">8.93</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFB3B3;"><span class="ltx_text" style="--ltx-bg-color:#FFB3B3;">22.59</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE8E8;"><span class="ltx_text" style="--ltx-bg-color:#FFE8E8;">9.19</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6363;"><span class="ltx_text" style="--ltx-bg-color:#FF6363;">43.09</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8F8F;"><span class="ltx_text" style="--ltx-bg-color:#FF8F8F;">31.74</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA3A3;"><span class="ltx_text" style="--ltx-bg-color:#FFA3A3;">26.53</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">VideoCrafter-2</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8C8C;"><span class="ltx_text" style="--ltx-bg-color:#FF8C8C;">32.5</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9494;"><span class="ltx_text" style="--ltx-bg-color:#FF9494;">30.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFE3E3;"><span class="ltx_text" style="--ltx-bg-color:#FFE3E3;">10.51</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA8A8;"><span class="ltx_text" style="--ltx-bg-color:#FFA8A8;">25.36</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE6E6;"><span class="ltx_text" style="--ltx-bg-color:#FFE6E6;">9.43</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF4747;"><span class="ltx_text" style="--ltx-bg-color:#FF4747;">50.36</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF7070;"><span class="ltx_text" style="--ltx-bg-color:#FF7070;">39.95</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA6A6;"><span class="ltx_text" style="--ltx-bg-color:#FFA6A6;">26.08</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CogVideoX</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6E6E;"><span class="ltx_text" style="--ltx-bg-color:#FF6E6E;">40.06</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6666;"><span class="ltx_text" style="--ltx-bg-color:#FF6666;">42.55</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFE0E0;"><span class="ltx_text" style="--ltx-bg-color:#FFE0E0;">11.04</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF7575;"><span class="ltx_text" style="--ltx-bg-color:#FF7575;">38.33</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFADAD;"><span class="ltx_text" style="--ltx-bg-color:#FFADAD;">23.75</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF3333;"><span class="ltx_text" style="--ltx-bg-color:#FF3333;">55.18</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA6A6;"><span class="ltx_text" style="--ltx-bg-color:#FFA6A6;">26.1</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA1A1;"><span class="ltx_text" style="--ltx-bg-color:#FFA1A1;">27.44</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Wan 2.1</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF4F4F;"><span class="ltx_text" style="--ltx-bg-color:#FF4F4F;">48.17</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF5252;"><span class="ltx_text" style="--ltx-bg-color:#FF5252;">47.33</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFD9D9;"><span class="ltx_text" style="--ltx-bg-color:#FFD9D9;">13.1</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF3D3D;"><span class="ltx_text" style="--ltx-bg-color:#FF3D3D;">52.68</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9191;"><span class="ltx_text" style="--ltx-bg-color:#FF9191;">31.27</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6161;"><span class="ltx_text" style="--ltx-bg-color:#FF6161;">43.83</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF3B3B;"><span class="ltx_text" style="--ltx-bg-color:#FF3B3B;">53.38</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF3333;"><span class="ltx_text" style="--ltx-bg-color:#FF3333;">55.47</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" rowspan="18">
<div class="ltx_inline-block ltx_transformed_outer" style="width:8.9pt;height:89.4pt;vertical-align:-42.2pt;"><span class="ltx_transformed_inner" style="width:89.4pt;transform:translate(-40.2pt,-40.2pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Detailed Prompts</span></p>
</span></div>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" rowspan="13">
<div class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:49.6pt;vertical-align:-21.3pt;"><span class="ltx_transformed_inner" style="width:49.6pt;transform:translate(-21.3pt,-21.3pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">T2I Models</span></p>
</span></div>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Stable Diffusion 1.4</th>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFD4D4;"><span class="ltx_text" style="--ltx-bg-color:#FFD4D4;">14.33</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFCCCC;"><span class="ltx_text" style="--ltx-bg-color:#FFCCCC;">15.93</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#FFF7F7;"><span class="ltx_text" style="--ltx-bg-color:#FFF7F7;">5.16</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFDEDE;"><span class="ltx_text" style="--ltx-bg-color:#FFDEDE;">11.65</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFFAFA;"><span class="ltx_text" style="--ltx-bg-color:#FFFAFA;">4.37</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFC7C7;"><span class="ltx_text" style="--ltx-bg-color:#FFC7C7;">17.35</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FF9999;"><span class="ltx_text" style="--ltx-bg-color:#FF9999;">29.23</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFC9C9;"><span class="ltx_text" style="--ltx-bg-color:#FFC9C9;">17.03</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Stable Diffusion 1.5</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC9C9;"><span class="ltx_text" style="--ltx-bg-color:#FFC9C9;">16.56</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFCCCC;"><span class="ltx_text" style="--ltx-bg-color:#FFCCCC;">16.17</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFF5F5;"><span class="ltx_text" style="--ltx-bg-color:#FFF5F5;">5.51</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFDEDE;"><span class="ltx_text" style="--ltx-bg-color:#FFDEDE;">11.18</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFF5F5;"><span class="ltx_text" style="--ltx-bg-color:#FFF5F5;">5.39</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC7C7;"><span class="ltx_text" style="--ltx-bg-color:#FFC7C7;">17.34</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9C9C;"><span class="ltx_text" style="--ltx-bg-color:#FF9C9C;">28.7</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC4C4;"><span class="ltx_text" style="--ltx-bg-color:#FFC4C4;">18.22</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Stable Diffusion 2.1</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC7C7;"><span class="ltx_text" style="--ltx-bg-color:#FFC7C7;">17.39</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC2C2;"><span class="ltx_text" style="--ltx-bg-color:#FFC2C2;">18.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFF5F5;"><span class="ltx_text" style="--ltx-bg-color:#FFF5F5;">5.78</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFD1D1;"><span class="ltx_text" style="--ltx-bg-color:#FFD1D1;">15.06</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFF5F5;"><span class="ltx_text" style="--ltx-bg-color:#FFF5F5;">5.51</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFB0B0;"><span class="ltx_text" style="--ltx-bg-color:#FFB0B0;">23.03</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9999;"><span class="ltx_text" style="--ltx-bg-color:#FF9999;">29.36</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFBFBF;"><span class="ltx_text" style="--ltx-bg-color:#FFBFBF;">19.06</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Stable Diffusion XL</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC7C7;"><span class="ltx_text" style="--ltx-bg-color:#FFC7C7;">17.12</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC7C7;"><span class="ltx_text" style="--ltx-bg-color:#FFC7C7;">17.09</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFF5F5;"><span class="ltx_text" style="--ltx-bg-color:#FFF5F5;">5.83</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFD4D4;"><span class="ltx_text" style="--ltx-bg-color:#FFD4D4;">14.09</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFF5F5;"><span class="ltx_text" style="--ltx-bg-color:#FFF5F5;">5.56</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFBABA;"><span class="ltx_text" style="--ltx-bg-color:#FFBABA;">20.57</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9696;"><span class="ltx_text" style="--ltx-bg-color:#FF9696;">30.12</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFD1D1;"><span class="ltx_text" style="--ltx-bg-color:#FFD1D1;">15.1</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Stable Diffusion 3</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC7C7;"><span class="ltx_text" style="--ltx-bg-color:#FFC7C7;">17.15</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC2C2;"><span class="ltx_text" style="--ltx-bg-color:#FFC2C2;">18.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFF5F5;"><span class="ltx_text" style="--ltx-bg-color:#FFF5F5;">5.86</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFD1D1;"><span class="ltx_text" style="--ltx-bg-color:#FFD1D1;">14.74</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFF0F0;"><span class="ltx_text" style="--ltx-bg-color:#FFF0F0;">6.67</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFADAD;"><span class="ltx_text" style="--ltx-bg-color:#FFADAD;">23.85</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9999;"><span class="ltx_text" style="--ltx-bg-color:#FF9999;">28.94</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC2C2;"><span class="ltx_text" style="--ltx-bg-color:#FFC2C2;">19.02</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Stable Diffusion 3.5 Large</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC2C2;"><span class="ltx_text" style="--ltx-bg-color:#FFC2C2;">18.42</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFBFBF;"><span class="ltx_text" style="--ltx-bg-color:#FFBFBF;">19.54</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFF2F2;"><span class="ltx_text" style="--ltx-bg-color:#FFF2F2;">6.12</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFCFCF;"><span class="ltx_text" style="--ltx-bg-color:#FFCFCF;">15.7</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFF0F0;"><span class="ltx_text" style="--ltx-bg-color:#FFF0F0;">6.99</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFB0B0;"><span class="ltx_text" style="--ltx-bg-color:#FFB0B0;">23.46</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8F8F;"><span class="ltx_text" style="--ltx-bg-color:#FF8F8F;">31.83</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFBDBD;"><span class="ltx_text" style="--ltx-bg-color:#FFBDBD;">19.72</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Stable Diffusion 3.5 Large Turbo</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFBDBD;"><span class="ltx_text" style="--ltx-bg-color:#FFBDBD;">19.9</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFBABA;"><span class="ltx_text" style="--ltx-bg-color:#FFBABA;">20.63</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFF2F2;"><span class="ltx_text" style="--ltx-bg-color:#FFF2F2;">6.09</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFD1D1;"><span class="ltx_text" style="--ltx-bg-color:#FFD1D1;">15.06</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFEBEB;"><span class="ltx_text" style="--ltx-bg-color:#FFEBEB;">8.13</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFABAB;"><span class="ltx_text" style="--ltx-bg-color:#FFABAB;">24.94</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8A8A;"><span class="ltx_text" style="--ltx-bg-color:#FF8A8A;">33.42</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFB8B8;"><span class="ltx_text" style="--ltx-bg-color:#FFB8B8;">21.61</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Flux.1 [dev]</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFB0B0;"><span class="ltx_text" style="--ltx-bg-color:#FFB0B0;">23.29</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFB8B8;"><span class="ltx_text" style="--ltx-bg-color:#FFB8B8;">21.25</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFF5F5;"><span class="ltx_text" style="--ltx-bg-color:#FFF5F5;">5.46</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFD1D1;"><span class="ltx_text" style="--ltx-bg-color:#FFD1D1;">14.84</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE8E8;"><span class="ltx_text" style="--ltx-bg-color:#FFE8E8;">9.11</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA6A6;"><span class="ltx_text" style="--ltx-bg-color:#FFA6A6;">25.69</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9191;"><span class="ltx_text" style="--ltx-bg-color:#FF9191;">31.4</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA8A8;"><span class="ltx_text" style="--ltx-bg-color:#FFA8A8;">25.23</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DALL-E Mini</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFABAB;"><span class="ltx_text" style="--ltx-bg-color:#FFABAB;">24.71</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFB8B8;"><span class="ltx_text" style="--ltx-bg-color:#FFB8B8;">21.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFF0F0;"><span class="ltx_text" style="--ltx-bg-color:#FFF0F0;">7.05</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA1A1;"><span class="ltx_text" style="--ltx-bg-color:#FFA1A1;">27.56</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFF5F5;"><span class="ltx_text" style="--ltx-bg-color:#FFF5F5;">5.29</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA1A1;"><span class="ltx_text" style="--ltx-bg-color:#FFA1A1;">27.35</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9191;"><span class="ltx_text" style="--ltx-bg-color:#FF9191;">31.47</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFCFCF;"><span class="ltx_text" style="--ltx-bg-color:#FFCFCF;">15.53</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DALL-E 2</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC7C7;"><span class="ltx_text" style="--ltx-bg-color:#FFC7C7;">17.73</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFBDBD;"><span class="ltx_text" style="--ltx-bg-color:#FFBDBD;">20.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFF2F2;"><span class="ltx_text" style="--ltx-bg-color:#FFF2F2;">5.98</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC2C2;"><span class="ltx_text" style="--ltx-bg-color:#FFC2C2;">18.43</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFF2F2;"><span class="ltx_text" style="--ltx-bg-color:#FFF2F2;">6.52</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFA8A8;"><span class="ltx_text" style="--ltx-bg-color:#FFA8A8;">25.5</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8C8C;"><span class="ltx_text" style="--ltx-bg-color:#FF8C8C;">32.8</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC4C4;"><span class="ltx_text" style="--ltx-bg-color:#FFC4C4;">17.76</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DALL-E 3</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFDBDB;"><span class="ltx_text" style="--ltx-bg-color:#FFDBDB;">12.18</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFD6D6;"><span class="ltx_text" style="--ltx-bg-color:#FFD6D6;">13.27</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFFAFA;"><span class="ltx_text" style="--ltx-bg-color:#FFFAFA;">4.29</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE8E8;"><span class="ltx_text" style="--ltx-bg-color:#FFE8E8;">8.85</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFF7F7;"><span class="ltx_text" style="--ltx-bg-color:#FFF7F7;">4.74</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFBABA;"><span class="ltx_text" style="--ltx-bg-color:#FFBABA;">20.98</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC2C2;"><span class="ltx_text" style="--ltx-bg-color:#FFC2C2;">18.91</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFD9D9;"><span class="ltx_text" style="--ltx-bg-color:#FFD9D9;">12.85</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DALL-E 3 (w/ Prompt Rewrite)</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFF2F2;"><span class="ltx_text" style="--ltx-bg-color:#FFF2F2;">6.55</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE0E0;"><span class="ltx_text" style="--ltx-bg-color:#FFE0E0;">10.77</span></td>
<td class="ltx_td ltx_align_center ltx_border_r">2.97</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFDBDB;"><span class="ltx_text" style="--ltx-bg-color:#FFDBDB;">11.93</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFF5F5;"><span class="ltx_text" style="--ltx-bg-color:#FFF5F5;">5.28</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE0E0;"><span class="ltx_text" style="--ltx-bg-color:#FFE0E0;">10.62</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC7C7;"><span class="ltx_text" style="--ltx-bg-color:#FFC7C7;">17.09</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE8E8;"><span class="ltx_text" style="--ltx-bg-color:#FFE8E8;">8.94</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">gpt-image-1 (4o Image Gen)</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE8E8;"><span class="ltx_text" style="--ltx-bg-color:#FFE8E8;">8.98</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE0E0;"><span class="ltx_text" style="--ltx-bg-color:#FFE0E0;">10.97</span></td>
<td class="ltx_td ltx_align_center ltx_border_r">3.24</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFD6D6;"><span class="ltx_text" style="--ltx-bg-color:#FFD6D6;">13.72</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFFAFA;"><span class="ltx_text" style="--ltx-bg-color:#FFFAFA;">4.46</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE0E0;"><span class="ltx_text" style="--ltx-bg-color:#FFE0E0;">10.56</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFCCCC;"><span class="ltx_text" style="--ltx-bg-color:#FFCCCC;">15.96</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFE3E3;"><span class="ltx_text" style="--ltx-bg-color:#FFE3E3;">10.17</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" rowspan="5">
<div class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:53.2pt;vertical-align:-23.1pt;"><span class="ltx_transformed_inner" style="width:53.2pt;transform:translate(-23.1pt,-23.1pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">T2V Models</span></p>
</span></div>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Cosmos-1</th>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFC4C4;"><span class="ltx_text" style="--ltx-bg-color:#FFC4C4;">18.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFD4D4;"><span class="ltx_text" style="--ltx-bg-color:#FFD4D4;">14.28</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#FFFAFA;"><span class="ltx_text" style="--ltx-bg-color:#FFFAFA;">4.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFE0E0;"><span class="ltx_text" style="--ltx-bg-color:#FFE0E0;">11.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFE6E6;"><span class="ltx_text" style="--ltx-bg-color:#FFE6E6;">9.25</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFD4D4;"><span class="ltx_text" style="--ltx-bg-color:#FFD4D4;">14.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFB3B3;"><span class="ltx_text" style="--ltx-bg-color:#FFB3B3;">22.49</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#FFD1D1;"><span class="ltx_text" style="--ltx-bg-color:#FFD1D1;">14.58</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Open-Sora</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC7C7;"><span class="ltx_text" style="--ltx-bg-color:#FFC7C7;">17.16</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFD4D4;"><span class="ltx_text" style="--ltx-bg-color:#FFD4D4;">14.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFFAFA;"><span class="ltx_text" style="--ltx-bg-color:#FFFAFA;">4.57</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFD6D6;"><span class="ltx_text" style="--ltx-bg-color:#FFD6D6;">13.49</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFF7F7;"><span class="ltx_text" style="--ltx-bg-color:#FFF7F7;">5.13</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFBFBF;"><span class="ltx_text" style="--ltx-bg-color:#FFBFBF;">19.4</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFBDBD;"><span class="ltx_text" style="--ltx-bg-color:#FFBDBD;">19.8</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFD9D9;"><span class="ltx_text" style="--ltx-bg-color:#FFD9D9;">12.69</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">VideoCrafter-2</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFB3B3;"><span class="ltx_text" style="--ltx-bg-color:#FFB3B3;">22.59</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC4C4;"><span class="ltx_text" style="--ltx-bg-color:#FFC4C4;">18.31</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFF5F5;"><span class="ltx_text" style="--ltx-bg-color:#FFF5F5;">5.91</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC9C9;"><span class="ltx_text" style="--ltx-bg-color:#FFC9C9;">16.97</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFFAFA;"><span class="ltx_text" style="--ltx-bg-color:#FFFAFA;">4.18</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFADAD;"><span class="ltx_text" style="--ltx-bg-color:#FFADAD;">24.16</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9E9E;"><span class="ltx_text" style="--ltx-bg-color:#FF9E9E;">27.63</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFC2C2;"><span class="ltx_text" style="--ltx-bg-color:#FFC2C2;">18.61</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CogVideoX</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8F8F;"><span class="ltx_text" style="--ltx-bg-color:#FF8F8F;">31.87</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF9696;"><span class="ltx_text" style="--ltx-bg-color:#FF9696;">29.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FFEBEB;"><span class="ltx_text" style="--ltx-bg-color:#FFEBEB;">8.08</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFB8B8;"><span class="ltx_text" style="--ltx-bg-color:#FFB8B8;">21.33</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFD1D1;"><span class="ltx_text" style="--ltx-bg-color:#FFD1D1;">14.63</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF8C8C;"><span class="ltx_text" style="--ltx-bg-color:#FF8C8C;">32.74</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF6363;"><span class="ltx_text" style="--ltx-bg-color:#FF6363;">42.88</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FF7D7D;"><span class="ltx_text" style="--ltx-bg-color:#FF7D7D;">36.4</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Wan 2.1</th>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#FF8C8C;"><span class="ltx_text" style="--ltx-bg-color:#FF8C8C;">32.69</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#FF8F8F;"><span class="ltx_text" style="--ltx-bg-color:#FF8F8F;">31.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#FFE8E8;"><span class="ltx_text" style="--ltx-bg-color:#FFE8E8;">8.59</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#FF9494;"><span class="ltx_text" style="--ltx-bg-color:#FF9494;">30.23</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#FFD1D1;"><span class="ltx_text" style="--ltx-bg-color:#FFD1D1;">14.97</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#FF6666;"><span class="ltx_text" style="--ltx-bg-color:#FF6666;">42.58</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#FF7D7D;"><span class="ltx_text" style="--ltx-bg-color:#FF7D7D;">36.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#FF8080;"><span class="ltx_text" style="--ltx-bg-color:#FF8080;">35.71</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Evaluation Metrics</h3>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Automatic Evaluation</h5>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p">To automatically evaluate any multimodal generative model <math alttext="\mathcal{G}(\cdot)" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.m1" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{G}(\cdot)</annotation></semantics></math> on our benchmark, we design scoring functions based on reference-free image-text alignment metrics, including VQAScore <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib32" title="">2024</a>)</cite> and CLIPScore <cite class="ltx_cite ltx_citemacro_citep">(Hessel et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib24" title="">2021</a>)</cite>. For simplicity, we denote any such alignment metric below as <math alttext="\mathcal{A}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒜</mi><annotation encoding="application/x-tex">\mathcal{A}</annotation></semantics></math>. We further denote the <span class="ltx_text ltx_font_bold">DialectGen</span> prompt subset for any dialect as <math alttext="\mathcal{P}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.m3" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒫</mi><annotation encoding="application/x-tex">\mathcal{P}</annotation></semantics></math>, which contains many SAE Prompt / Dialect Prompt pairs <math alttext="p=(p^{s},\ p^{d})" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.m4" intent=":literal"><semantics><mrow><mi>p</mi><mo>=</mo><mrow><mo stretchy="false">(</mo><msup><mi>p</mi><mi>s</mi></msup><mo rspace="0.667em">,</mo><msup><mi>p</mi><mi>d</mi></msup><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">p=(p^{s},\ p^{d})</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p2">
<p class="ltx_p">For each individual text prompt <math alttext="p^{s}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p2.m1" intent=":literal"><semantics><msup><mi>p</mi><mi>s</mi></msup><annotation encoding="application/x-tex">p^{s}</annotation></semantics></math> or <math alttext="p^{d}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p2.m2" intent=":literal"><semantics><msup><mi>p</mi><mi>d</mi></msup><annotation encoding="application/x-tex">p^{d}</annotation></semantics></math>, we generate <math alttext="n" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p2.m3" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> images under different random seeds for text-to-image generative models, or uniformly sample <math alttext="n" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p2.m4" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> frames in a video for text-to-video generative models. Therefore, for each SAE Prompt / Dialect Prompt pair <math alttext="p=(p^{s},\ p^{d})\in\mathcal{P}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p2.m5" intent=":literal"><semantics><mrow><mi>p</mi><mo>=</mo><mrow><mo stretchy="false">(</mo><msup><mi>p</mi><mi>s</mi></msup><mo rspace="0.667em">,</mo><msup><mi>p</mi><mi>d</mi></msup><mo stretchy="false">)</mo></mrow><mo>∈</mo><mi class="ltx_font_mathcaligraphic">𝒫</mi></mrow><annotation encoding="application/x-tex">p=(p^{s},\ p^{d})\in\mathcal{P}</annotation></semantics></math>, we can calculate its SAE and Dialect performance as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p3">
<table class="ltx_equation ltx_eqn_table" id="S4.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="SAE(p,\ \mathcal{G})=\frac{1}{n}\sum_{i=1}^{n}\mathcal{A}(p^{s},\ \mathcal{G}(p^{s})_{i})" class="ltx_Math" display="block" id="S4.E1.m1" intent=":literal"><semantics><mrow><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mi>A</mi><mo lspace="0em" rspace="0em">​</mo><mi>E</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>p</mi><mo rspace="0.667em">,</mo><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo lspace="0em" rspace="0em">​</mo><mrow><munderover><mo movablelimits="false">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mi class="ltx_font_mathcaligraphic">𝒜</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msup><mi>p</mi><mi>s</mi></msup><mo rspace="0.667em">,</mo><mrow><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo lspace="0em" rspace="0em">​</mo><msub><mrow><mo stretchy="false">(</mo><msup><mi>p</mi><mi>s</mi></msup><mo stretchy="false">)</mo></mrow><mi>i</mi></msub></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">SAE(p,\ \mathcal{G})=\frac{1}{n}\sum_{i=1}^{n}\mathcal{A}(p^{s},\ \mathcal{G}(p^{s})_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p4">
<table class="ltx_equation ltx_eqn_table" id="S4.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Dialect(p,\ \mathcal{G})=\frac{1}{n}\sum_{i=1}^{n}\mathcal{A}(p^{s},\ \mathcal{G}(p^{d})_{i})" class="ltx_Math" display="block" id="S4.E2.m1" intent=":literal"><semantics><mrow><mrow><mi>D</mi><mo lspace="0em" rspace="0em">​</mo><mi>i</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>l</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>c</mi><mo lspace="0em" rspace="0em">​</mo><mi>t</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>p</mi><mo rspace="0.667em">,</mo><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo lspace="0em" rspace="0em">​</mo><mrow><munderover><mo movablelimits="false">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mi class="ltx_font_mathcaligraphic">𝒜</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msup><mi>p</mi><mi>s</mi></msup><mo rspace="0.667em">,</mo><mrow><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo lspace="0em" rspace="0em">​</mo><msub><mrow><mo stretchy="false">(</mo><msup><mi>p</mi><mi>d</mi></msup><mo stretchy="false">)</mo></mrow><mi>i</mi></msub></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">Dialect(p,\ \mathcal{G})=\frac{1}{n}\sum_{i=1}^{n}\mathcal{A}(p^{s},\ \mathcal{G}(p^{d})_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p5">
<p class="ltx_p">Note that when calculating dialect performance, we align the SAE Prompt <math alttext="p^{s}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p5.m1" intent=":literal"><semantics><msup><mi>p</mi><mi>s</mi></msup><annotation encoding="application/x-tex">p^{s}</annotation></semantics></math> with multimodal output generated from the corresponding Dialect Prompt, <span class="ltx_text ltx_font_italic">i.e.</span>, <math alttext="\mathcal{G}(p^{d})" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p5.m2" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msup><mi>p</mi><mi>d</mi></msup><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{G}(p^{d})</annotation></semantics></math>. This is feasible given that the paired prompts are synonymous, as verified by dialect speaker annotators in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S3.SS2" title="3.2 Dialect Speaker Validation and Filtering ‣ 3 DialectGen Benchmark ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Section</span>˜<span class="ltx_text ltx_ref_tag">3.2</span></a>. Based on this, we can compute the dialect-induced performance drop of <math alttext="\mathcal{G}(\cdot)" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p5.m3" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{G}(\cdot)</annotation></semantics></math> for each prompt pair <math alttext="p" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p5.m4" intent=":literal"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Drop(p,\ \mathcal{G})=\frac{SAE(p,\ \mathcal{G})-Dialect(p,\ \mathcal{G})}{SAE(p,\ \mathcal{G})}=\sum_{i=1}^{n}\frac{\mathcal{A}(\mathcal{G}(p^{s})_{i},\ p^{s})-\mathcal{A}(\mathcal{G}(p^{d})_{i},\ p^{s})}{\mathcal{A}(\mathcal{G}(p^{s})_{i},\ p^{s})}" class="ltx_Math" display="block" id="S4.E3.m1" intent=":literal"><semantics><mrow><mrow><mi>D</mi><mo lspace="0em" rspace="0em">​</mo><mi>r</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>p</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>p</mi><mo rspace="0.667em">,</mo><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mfrac><mrow><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mi>A</mi><mo lspace="0em" rspace="0em">​</mo><mi>E</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>p</mi><mo rspace="0.667em">,</mo><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo stretchy="false">)</mo></mrow></mrow><mo>−</mo><mrow><mi>D</mi><mo lspace="0em" rspace="0em">​</mo><mi>i</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>l</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>c</mi><mo lspace="0em" rspace="0em">​</mo><mi>t</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>p</mi><mo rspace="0.667em">,</mo><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mi>A</mi><mo lspace="0em" rspace="0em">​</mo><mi>E</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>p</mi><mo rspace="0.667em">,</mo><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo stretchy="false">)</mo></mrow></mrow></mfrac><mo rspace="0.111em">=</mo><mrow><munderover><mo movablelimits="false">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mfrac><mrow><mrow><mi class="ltx_font_mathcaligraphic">𝒜</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo lspace="0em" rspace="0em">​</mo><msub><mrow><mo stretchy="false">(</mo><msup><mi>p</mi><mi>s</mi></msup><mo stretchy="false">)</mo></mrow><mi>i</mi></msub></mrow><mo rspace="0.667em">,</mo><msup><mi>p</mi><mi>s</mi></msup><mo stretchy="false">)</mo></mrow></mrow><mo>−</mo><mrow><mi class="ltx_font_mathcaligraphic">𝒜</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo lspace="0em" rspace="0em">​</mo><msub><mrow><mo stretchy="false">(</mo><msup><mi>p</mi><mi>d</mi></msup><mo stretchy="false">)</mo></mrow><mi>i</mi></msub></mrow><mo rspace="0.667em">,</mo><msup><mi>p</mi><mi>s</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mi class="ltx_font_mathcaligraphic">𝒜</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo lspace="0em" rspace="0em">​</mo><msub><mrow><mo stretchy="false">(</mo><msup><mi>p</mi><mi>s</mi></msup><mo stretchy="false">)</mo></mrow><mi>i</mi></msub></mrow><mo rspace="0.667em">,</mo><msup><mi>p</mi><mi>s</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mfrac></mrow></mrow><annotation encoding="application/x-tex">Drop(p,\ \mathcal{G})=\frac{SAE(p,\ \mathcal{G})-Dialect(p,\ \mathcal{G})}{SAE(p,\ \mathcal{G})}=\sum_{i=1}^{n}\frac{\mathcal{A}(\mathcal{G}(p^{s})_{i},\ p^{s})-\mathcal{A}(\mathcal{G}(p^{d})_{i},\ p^{s})}{\mathcal{A}(\mathcal{G}(p^{s})_{i},\ p^{s})}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">To obtain the average model performance drop for a specific dialect, <span class="ltx_text ltx_font_italic">i.e.</span>, <math alttext="Drop(\mathcal{P},\ \mathcal{G})" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p5.m5" intent=":literal"><semantics><mrow><mi>D</mi><mo lspace="0em" rspace="0em">​</mo><mi>r</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>p</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">𝒫</mi><mo rspace="0.667em">,</mo><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">Drop(\mathcal{P},\ \mathcal{G})</annotation></semantics></math>, we simply average <math alttext="Drop(p,\ \mathcal{G})" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p5.m6" intent=":literal"><semantics><mrow><mi>D</mi><mo lspace="0em" rspace="0em">​</mo><mi>r</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>p</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>p</mi><mo rspace="0.667em">,</mo><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">Drop(p,\ \mathcal{G})</annotation></semantics></math> for all <math alttext="p" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p5.m7" intent=":literal"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math> in <math alttext="\mathcal{P}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p5.m8" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒫</mi><annotation encoding="application/x-tex">\mathcal{P}</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Human Evaluation</h5>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p">We further design a human evaluation pipeline to check the empirical alignment between our automatic evaluation metrics and human judgment. For 5% of the model outputs in our benchmark, we ask three independent external human annotators to evaluate: to what extent does the multimodal generations conditioned on the SAE Prompt <math alttext="\mathcal{G}(p^{s})" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px2.p1.m1" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msup><mi>p</mi><mi>s</mi></msup><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{G}(p^{s})</annotation></semantics></math> or Dialect Prompt <math alttext="\mathcal{G}(p^{d})" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px2.p1.m2" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msup><mi>p</mi><mi>d</mi></msup><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{G}(p^{d})</annotation></semantics></math> match with the scene described by SAE prompt <math alttext="p^{s}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px2.p1.m3" intent=":literal"><semantics><msup><mi>p</mi><mi>s</mi></msup><annotation encoding="application/x-tex">p^{s}</annotation></semantics></math>. Annotators are asked to rate the alignment between each (image/video, caption) pair with a numerical score between 0 and 10.
The numerical scores are scaled by 0.1 to match the scoring range of VQAScore and CLIPScore before calculating SAE and Dialect performance.
Finally, we use the same formula to calculate the dialect-induced performance drop <math alttext="Drop(p,\ \mathcal{G})" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px2.p1.m4" intent=":literal"><semantics><mrow><mi>D</mi><mo lspace="0em" rspace="0em">​</mo><mi>r</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>p</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>p</mi><mo rspace="0.667em">,</mo><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">Drop(p,\ \mathcal{G})</annotation></semantics></math>. Since we only evaluate the alignment between image/video and the SAE prompt, this task does not require dialect speaker human annotators.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Benchmark Experiments</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p">Applying the automatic and human evaluation metrics described in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4.SS1" title="4.1 Evaluation Metrics ‣ 4 Experiments ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Section</span>˜<span class="ltx_text ltx_ref_tag">4.1</span></a>, we evaluate popular open-weights and proprietary multimodal generative models on <span class="ltx_text ltx_font_bold">DialectGen</span>. Model performances are separately aggregated for <span class="ltx_text ltx_font_bold">Concise Prompts</span> and <span class="ltx_text ltx_font_bold">Detailed Prompts</span> settings in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4.T2" title="In 4 Experiments ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Overall Performances</h5>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px1.p1">
<p class="ltx_p">For each model, we record overall dialect-induced performance drop on <span class="ltx_text ltx_font_bold">DialectGen</span> using three different metrics: Human Eval, VQAScore, and CLIPScore. We calculate Pearson correlation coefficients <cite class="ltx_cite ltx_citemacro_citep">(Pearson, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib36" title="">1895</a>)</cite> <math alttext="r" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p1.m1" intent=":literal"><semantics><mi>r</mi><annotation encoding="application/x-tex">r</annotation></semantics></math> between each of the two metrics and observe <math alttext="r" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p1.m2" intent=":literal"><semantics><mi>r</mi><annotation encoding="application/x-tex">r</annotation></semantics></math>(Human, VQAScore) = 0.968, <math alttext="r" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p1.m3" intent=":literal"><semantics><mi>r</mi><annotation encoding="application/x-tex">r</annotation></semantics></math>(Human, CLIPScore) = 0.924, and <math alttext="r" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p1.m4" intent=":literal"><semantics><mi>r</mi><annotation encoding="application/x-tex">r</annotation></semantics></math>(VQAScore, CLIPScore) = 0.907. This shows that while both automatic scoring metrics have high correlations to human judgement (the gold standard), VQAScore is a better-aligned scoring metric for measuring dialect-induced performance drop.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px1.p2">
<p class="ltx_p">Contrasting the model performance drops across the two evaluation settings <span class="ltx_text ltx_font_bold">Concise Prompts</span> and <span class="ltx_text ltx_font_bold">Detailed Prompts</span>, we can clearly see that all models exhibit significantly larger performance drops for concise prompts compared to detailed prompts. This is in line with our assumption that models can more easily infer the meanings of unknown dialect lexemes from richer prompt contexts, highlighting the need for challenging evaluation via concise prompts to reveal model robustness issues.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px1.p3">
<p class="ltx_p">Looking at individual model performances, we observe that among text-to-video generative models: Wan 2.1 <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib46" title="">2025</a>)</cite> and CogVideoX <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib50" title="">2024</a>)</cite>
exhibit the largest overall performance drops while Cosmos-1 <cite class="ltx_cite ltx_citemacro_citep">(Agarwal et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib2" title="">2025</a>)</cite> is the most robust. While for text-to-image generative models, DALL-E 2 <cite class="ltx_cite ltx_citemacro_citep">(Ramesh et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib40" title="">2022</a>)</cite> and Flux.1 [dev] <cite class="ltx_cite ltx_citemacro_citep">(Black Forest Labs, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib6" title="">2024</a>)</cite> exhibit the largest overall performance drops while DALL-E 3 <cite class="ltx_cite ltx_citemacro_citep">(Betker et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib4" title="">2023</a>)</cite> (w/ Prompt Rewrite) and gpt-image-1 (4o Image Generation) <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib34" title="">2025</a>)</cite> are the most robust.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Dialect-wise Performance Drop</h5>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px2.p1">
<p class="ltx_p">In addition to overall performance, we record each model’s performance drop on each dialect, measured by VQAScore. Based on the color heatmap in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4.T2" title="In 4 Experiments ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">2</span></a>, we can clearly see that the most severe performance drops occur for ChE and InE for most models, while AAE and SgE also suffer significant performance decreases. On the other hand, models generally do not see a very significant performance drop for BrE, which is expected given the relatively higher-resource nature of the dialect.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Mitigation Methods</h2>
<figure class="ltx_figure" id="S5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="326" id="S5.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>
Losses used in our mitigation. Text prompts for <span class="ltx_text ltx_font_bold">Dialect Learning</span> and <span class="ltx_text ltx_font_bold">Polysemy Control</span> come from the <span class="ltx_text ltx_font_bold">DialectGen</span> training set, while image-caption pairs for <span class="ltx_text ltx_font_bold">KL Regularization</span> come from the MSCOCO validation set.
</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p">The significant dialect performance drops of current multimodal generative models shown in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4.SS2" title="4.2 Benchmark Experiments ‣ 4 Experiments ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Section</span>˜<span class="ltx_text ltx_ref_tag">4.2</span></a> highlight the need for effective mitigation strategies to improve dialect robustness. Here, the goal is to develop a method that enhances robustness across multiple dialects while preserving performance on standard SAE prompts.
To this end, we first investigate intuitive baseline approaches, including (1) UNet Finetuning; (2) Prompt Revision, and then introduce our new mitigation strategy.
</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Baseline Methods</h3>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">UNet Finetuning</h5>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px1.p1">
<p class="ltx_p">The vast majority of current text-to-image and text-to-video generative models comprise two main components: a text encoder and a diffusion-based image/video decoder. In current post-training paradigms, typically the text encoder is kept frozen while the diffusion UNet is fine-tuned <cite class="ltx_cite ltx_citemacro_citep">(Podell et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib37" title="">2023</a>; Rombach et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib41" title="">2022</a>; Betker et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib4" title="">2023</a>; Dai et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib13" title="">2023</a>)</cite>. Existing works in aligning, enhancing, and customizing multimodal generative models also focus heavily on developing reward-based fine-tuning methods for the diffusion UNet while freezing the text encoder <cite class="ltx_cite ltx_citemacro_citep">(Segalis et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib42" title="">2023</a>; Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib11" title="">2023</a>; Prabhudesai et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib38" title="">2023</a>; Black et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib5" title="">2023</a>; Fan et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib17" title="">2023</a>; Wallace et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib44" title="">2024</a>; Dang et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib14" title="">2025</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px1.p2">
<p class="ltx_p">Based on existing works, we apply prominent multimodal generation enhancement methods towards improving dialect robustness, including:</p>
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Diffusion Fine-tune</span> <cite class="ltx_cite ltx_citemacro_citep">(Rombach et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib41" title="">2022</a>)</cite> given a pair of synonymous Dialect / SAE Prompts, we fine-tune the diffusion UNet with the Dialect Prompt as input, and images generated using the SAE Prompt as target output.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S5.I1.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Diffusion DPO</span> <cite class="ltx_cite ltx_citemacro_citep">(Wallace et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib44" title="">2024</a>)</cite> We similarly use the Dialect Prompt as input, and use images generated with the SAE Prompt / Dialect Prompt as Win / Lose pairs for DPO.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Prompt Revision</h5>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px2.p1">
<p class="ltx_p">Beyond UNet fine-tuning, another popular family of methods for aligning and enhancing multimodal generative models is prompt revision <cite class="ltx_cite ltx_citemacro_citep">(Hao et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib22" title="">2023</a>; Betker et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib4" title="">2023</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib47" title="">2024</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib10" title="">2024</a>)</cite>. In our experiments, we include both a general prompt rewriting method and targeted prompt translation methods using general-purpose LLMs:</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px2.p2">
<ul class="ltx_itemize" id="S5.I2">
<li class="ltx_item" id="S5.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Prompt Rewrite</span> We apply the general prompt rewriting pipeline in <cite class="ltx_cite ltx_citemacro_citet">Betker et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib4" title="">2023</a>)</cite> to all test prompts before passing them to the generative model.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S5.I2.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Prompt Translate</span> We use general-purpose LLMs <cite class="ltx_cite ltx_citemacro_citep">(Grattafiori et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib20" title="">2024</a>; OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib35" title="">2025</a>)</cite> to translate all prompts to SAE before passing them to the generative model.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Our Method</h3>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p">Unlike prior approaches, we propose a new mitigation strategy that focuses on updating the text encoder(s). A natural first step toward improving dialectal robustness is to align the semantic representation of a dialect expression with that of its corresponding SAE counterpart.</p>
</div>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Dialect Learning</h5>
<div class="ltx_para ltx_noindent" id="S5.SS2.SSS0.Px1.p1">
<p class="ltx_p">To operationalize this idea, we introduce a Dialect Learning loss that encourages the target text encoder to recognize dialectal lexemes by minimizing the cosine distance between the target encoder’s embedding of a dialect prompt and the frozen encoder’s embedding of its synonymous SAE prompt:</p>
<table class="ltx_equationgroup ltx_eqn_table" id="S5.E4">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S5.E4X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{DL}}=\frac{1}{N}\sum_{i=1}^{N}\left(1-\langle\pi(p^{d}_{i}),\ \pi_{0}(p^{s}_{i})\rangle\right)." class="ltx_Math" display="inline" id="S5.E4X.m2" intent=":literal"><semantics><mrow><mrow><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mtext>DL</mtext></msub><mo>=</mo><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><mi>N</mi></mfrac></mstyle><mo lspace="0em" rspace="0em">​</mo><mrow><mstyle displaystyle="true"><munderover><mo movablelimits="false">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover></mstyle><mrow><mo>(</mo><mrow><mn>1</mn><mo>−</mo><mrow><mo stretchy="false">⟨</mo><mrow><mi>π</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>p</mi><mi>i</mi><mi>d</mi></msubsup><mo stretchy="false">)</mo></mrow></mrow><mo rspace="0.667em">,</mo><mrow><msub><mi>π</mi><mn>0</mn></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>p</mi><mi>i</mi><mi>s</mi></msubsup><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">⟩</mo></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\displaystyle\mathcal{L}_{\text{DL}}=\frac{1}{N}\sum_{i=1}^{N}\left(1-\langle\pi(p^{d}_{i}),\ \pi_{0}(p^{s}_{i})\rangle\right).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(4)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p">Here, <math alttext="\langle\cdot,\ \cdot\rangle" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px1.p1.m1" intent=":literal"><semantics><mrow><mo stretchy="false">⟨</mo><mo lspace="0em" rspace="0em">⋅</mo><mo rspace="0.333em">,</mo><mo rspace="0em">⋅</mo><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle\cdot,\ \cdot\rangle</annotation></semantics></math> denotes cosine similarity; <math alttext="\pi(\cdot)" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px1.p1.m2" intent=":literal"><semantics><mrow><mi>π</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi(\cdot)</annotation></semantics></math> and <math alttext="\pi_{0}(\cdot)" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px1.p1.m3" intent=":literal"><semantics><mrow><msub><mi>π</mi><mn>0</mn></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi_{0}(\cdot)</annotation></semantics></math> represent the trainable target text encoder and the frozen reference encoder, respectively; and <math alttext="p^{d}_{i}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px1.p1.m4" intent=":literal"><semantics><msubsup><mi>p</mi><mi>i</mi><mi>d</mi></msubsup><annotation encoding="application/x-tex">p^{d}_{i}</annotation></semantics></math> and <math alttext="p^{s}_{i}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px1.p1.m5" intent=":literal"><semantics><msubsup><mi>p</mi><mi>i</mi><mi>s</mi></msubsup><annotation encoding="application/x-tex">p^{s}_{i}</annotation></semantics></math> denote the <math alttext="i" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px1.p1.m6" intent=":literal"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>-th pair of synonymous prompts in dialect and standard English, respectively.
Although this may improve dialectal robustness, relying on this loss alone may compromise the model’s ability to handle dialect lexemes that exhibit polysemy in SAE contexts.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Polysemy Control</h5>
<div class="ltx_para ltx_noindent" id="S5.SS2.SSS0.Px2.p1">
<p class="ltx_p">In order to retain the model’s ability to correctly recognize polysemous lexemes within SAE contexts, we introduce a Polysemy Control loss that minimizes the cosine distance between embeddings of the same SAE polysemous prompt generated by the target and frozen encoders:</p>
<table class="ltx_equationgroup ltx_eqn_table" id="S5.E5">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S5.E5X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{PC}}=\frac{1}{N}\sum_{i=1}^{N}\left(1-\langle\pi(p^{m}_{i}),\ \pi_{0}(p^{m}_{i})\rangle\right)," class="ltx_Math" display="inline" id="S5.E5X.m2" intent=":literal"><semantics><mrow><mrow><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mtext>PC</mtext></msub><mo>=</mo><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><mi>N</mi></mfrac></mstyle><mo lspace="0em" rspace="0em">​</mo><mrow><mstyle displaystyle="true"><munderover><mo movablelimits="false">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover></mstyle><mrow><mo>(</mo><mrow><mn>1</mn><mo>−</mo><mrow><mo stretchy="false">⟨</mo><mrow><mi>π</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>p</mi><mi>i</mi><mi>m</mi></msubsup><mo stretchy="false">)</mo></mrow></mrow><mo rspace="0.667em">,</mo><mrow><msub><mi>π</mi><mn>0</mn></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>p</mi><mi>i</mi><mi>m</mi></msubsup><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">⟩</mo></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\displaystyle\mathcal{L}_{\text{PC}}=\frac{1}{N}\sum_{i=1}^{N}\left(1-\langle\pi(p^{m}_{i}),\ \pi_{0}(p^{m}_{i})\rangle\right),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(5)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p">where each <math alttext="p^{m}_{i}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px2.p1.m1" intent=":literal"><semantics><msubsup><mi>p</mi><mi>i</mi><mi>m</mi></msubsup><annotation encoding="application/x-tex">p^{m}_{i}</annotation></semantics></math> is a polysemous SAE prompt sampled from the dataset. This loss is applied only to examples containing SAE polysemous lexemes.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>
<span class="ltx_text ltx_font_bold">Mitigation results</span> for all baseline methods and our best performing method, including <span class="ltx_text ltx_font_bold">Overall Performances</span> on SAE MSCOCO, SAE Polysemy, average Dialect performance, and <span class="ltx_text ltx_font_bold">Dialect Performance</span> for each dialect, all measured using VQAScore <cite class="ltx_cite ltx_citemacro_cite">Lin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib32" title="">2024</a>)</cite>. Cell colors reflect column-normalized performance values, with darker green indicating higher VQAScore performance.
</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:397.5pt;height:171.7pt;vertical-align:-84.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-67.1pt,29.0pt) scale(0.74771136321625,0.74771136321625) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" rowspan="3"><span class="ltx_text ltx_font_bold">Mitigation Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="3"><span class="ltx_text ltx_font_bold">Overall Performances <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T3.m1" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5">
<span class="ltx_text ltx_font_bold">Dialect Performance</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T3.m2" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column">SAE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column">SAE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Dialect</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" rowspan="2">AAE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" rowspan="2">BrE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" rowspan="2">ChE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" rowspan="2">InE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" rowspan="2">SgE</th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column">MSCOCO</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column">Polysemy</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Avg.</th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Base Model (Stable Diffusion 1.5)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">75.49</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">72.84</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">57.80</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="--ltx-bg-color:#EBF8F1;"><span class="ltx_text" style="--ltx-bg-color:#EBF8F1;">60.13</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="--ltx-bg-color:#F9FDFB;"><span class="ltx_text" style="--ltx-bg-color:#F9FDFB;">69.39</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">52.65</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">49.94</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">56.89</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Prompt Revision</span></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_r ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">   DALL-E 3 Prompt Rewrite</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8DD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8DD7B0;">74.25</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#89D6AD;"><span class="ltx_text" style="--ltx-bg-color:#89D6AD;">70.85</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#EBF8F1;"><span class="ltx_text" style="--ltx-bg-color:#EBF8F1;">60.91</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">57.34</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F7FCF9;"><span class="ltx_text" style="--ltx-bg-color:#F7FCF9;">69.51</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EDF9F3;"><span class="ltx_text" style="--ltx-bg-color:#EDF9F3;">56.36</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DFF4E9;"><span class="ltx_text" style="--ltx-bg-color:#DFF4E9;">57.54</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DBF2E6;"><span class="ltx_text" style="--ltx-bg-color:#DBF2E6;">63.81</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">   LLaMA 3 Prompt Translate</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#90D8B2;"><span class="ltx_text" style="--ltx-bg-color:#90D8B2;">74.03</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">71.33</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#FBFDFC;"><span class="ltx_text" style="--ltx-bg-color:#FBFDFC;">58.48</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FCFEFD;"><span class="ltx_text" style="--ltx-bg-color:#FCFEFD;">57.73</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EBF8F1;"><span class="ltx_text" style="--ltx-bg-color:#EBF8F1;">70.4</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F9FDFB;"><span class="ltx_text" style="--ltx-bg-color:#F9FDFB;">53.98</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FDFEFE;"><span class="ltx_text" style="--ltx-bg-color:#FDFEFE;">50.42</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EFFAF4;"><span class="ltx_text" style="--ltx-bg-color:#EFFAF4;">59.87</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">   GPT4.1 Prompt Translate</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">74.54</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#86D5AB;"><span class="ltx_text" style="--ltx-bg-color:#86D5AB;">71.47</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#D9F2E5;"><span class="ltx_text" style="--ltx-bg-color:#D9F2E5;">63.90</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E6F6EE;"><span class="ltx_text" style="--ltx-bg-color:#E6F6EE;">60.87</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">74.39</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E1F4EA;"><span class="ltx_text" style="--ltx-bg-color:#E1F4EA;">59.05</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D4F0E2;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E2;">60.20</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D5F0E2;"><span class="ltx_text" style="--ltx-bg-color:#D5F0E2;">64.98</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_bold">UNet Fine-tuning</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_border_r"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">   Diffusion Finetune</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F3FBF7;"><span class="ltx_text" style="--ltx-bg-color:#F3FBF7;">65.01</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E3F5EC;"><span class="ltx_text" style="--ltx-bg-color:#E3F5EC;">52.13</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#EBF8F1;"><span class="ltx_text" style="--ltx-bg-color:#EBF8F1;">60.94</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D1EFDF;"><span class="ltx_text" style="--ltx-bg-color:#D1EFDF;">63.85</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EEF9F4;"><span class="ltx_text" style="--ltx-bg-color:#EEF9F4;">70.14</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E9F7F0;"><span class="ltx_text" style="--ltx-bg-color:#E9F7F0;">57.3</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F3FBF7;"><span class="ltx_text" style="--ltx-bg-color:#F3FBF7;">52.84</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ECF8F2;"><span class="ltx_text" style="--ltx-bg-color:#ECF8F2;">60.56</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">   Diffusion DPO</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">63.94</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ECF8F2;"><span class="ltx_text" style="--ltx-bg-color:#ECF8F2;">50.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#DBF3E6;"><span class="ltx_text" style="--ltx-bg-color:#DBF3E6;">63.52</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C0E9D3;"><span class="ltx_text" style="--ltx-bg-color:#C0E9D3;">66.31</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">68.91</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D6F1E3;"><span class="ltx_text" style="--ltx-bg-color:#D6F1E3;">61.22</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E4F6EC;"><span class="ltx_text" style="--ltx-bg-color:#E4F6EC;">56.38</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D6F1E2;"><span class="ltx_text" style="--ltx-bg-color:#D6F1E2;">64.79</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_bold">Our Encoder Tuning Methods</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_border_r"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">   Dialect Learning</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DCF3E6;"><span class="ltx_text" style="--ltx-bg-color:#DCF3E6;">67.14</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">46.30</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">78.02</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#81D3A8;"><span class="ltx_text" style="--ltx-bg-color:#81D3A8;">75.21</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">78.33</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">79.31</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">78.10</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8BD7AF;"><span class="ltx_text" style="--ltx-bg-color:#8BD7AF;">79.15</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">    + Text Cosine Reg.</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DDF3E7;"><span class="ltx_text" style="--ltx-bg-color:#DDF3E7;">67.06</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FEFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FEFFFF;">46.39</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#81D3A8;"><span class="ltx_text" style="--ltx-bg-color:#81D3A8;">77.93</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">75.44</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#86D5AB;"><span class="ltx_text" style="--ltx-bg-color:#86D5AB;">77.84</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">79.31</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">78.22</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">78.86</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">    + Image Cosine Reg.</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D5F0E2;"><span class="ltx_text" style="--ltx-bg-color:#D5F0E2;">67.73</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FEFFFE;"><span class="ltx_text" style="--ltx-bg-color:#FEFFFE;">46.48</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">78.00</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#83D4A9;"><span class="ltx_text" style="--ltx-bg-color:#83D4A9;">74.91</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#81D3A8;"><span class="ltx_text" style="--ltx-bg-color:#81D3A8;">78.20</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">79.45</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#89D6AE;"><span class="ltx_text" style="--ltx-bg-color:#89D6AE;">78.33</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8BD7AF;"><span class="ltx_text" style="--ltx-bg-color:#8BD7AF;">79.11</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">    + Text KL Reg.</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9FDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9FDDBC;">72.68</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E0F4EA;"><span class="ltx_text" style="--ltx-bg-color:#E0F4EA;">52.72</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D3A8;"><span class="ltx_text" style="--ltx-bg-color:#82D3A8;">77.78</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">74.40</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">78.27</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">78.36</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">78.17</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#88D6AC;"><span class="ltx_text" style="--ltx-bg-color:#88D6AC;">79.71</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">    + Image KL Reg.</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#AAE1C4;"><span class="ltx_text" style="--ltx-bg-color:#AAE1C4;">71.69</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DDF3E7;"><span class="ltx_text" style="--ltx-bg-color:#DDF3E7;">53.41</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">78.12</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8BD7AF;"><span class="ltx_text" style="--ltx-bg-color:#8BD7AF;">73.77</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8ED8B1;"><span class="ltx_text" style="--ltx-bg-color:#8ED8B1;">77.23</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#81D3A8;"><span class="ltx_text" style="--ltx-bg-color:#81D3A8;">79.06</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#85D5AB;"><span class="ltx_text" style="--ltx-bg-color:#85D5AB;">79.25</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">81.29</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">    + Text KL Reg. + Polysemy Ctrl.</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">72.71</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8DD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8DD7B0;">70.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D3A8;"><span class="ltx_text" style="--ltx-bg-color:#82D3A8;">77.74</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DAB6;"><span class="ltx_text" style="--ltx-bg-color:#96DAB6;">72.24</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A2DFBF;"><span class="ltx_text" style="--ltx-bg-color:#A2DFBF;">75.76</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#82D3A8;"><span class="ltx_text" style="--ltx-bg-color:#82D3A8;">78.95</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">80.67</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#81D3A8;"><span class="ltx_text" style="--ltx-bg-color:#81D3A8;">81.07</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">    + Image KL Reg. + Polysemy Ctrl.</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">74.80</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">71.17</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">77.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#93DAB5;"><span class="ltx_text" style="--ltx-bg-color:#93DAB5;">72.61</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#95DAB6;"><span class="ltx_text" style="--ltx-bg-color:#95DAB6;">76.74</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#89D6AD;"><span class="ltx_text" style="--ltx-bg-color:#89D6AD;">77.51</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#81D3A8;"><span class="ltx_text" style="--ltx-bg-color:#81D3A8;">80.41</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">81.14</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">KL Regularization</h5>
<div class="ltx_para ltx_noindent" id="S5.SS2.SSS0.Px3.p1">
<p class="ltx_p">In addition to the previous two losses, it is also essential to preserve the model’s performance on general SAE prompts.
To this end, one might consider employing the conventional Kullback-Leibler (KL) divergence loss, which promotes alignment between the output distributions of a trainable target model and a frozen reference model over a predefined discrete logit space. However, this approach is not directly applicable in our setting, as text encoders output continuous embeddings rather than discrete logits. To address this challenge, we approximate the output distribution by computing similarity scores between a given caption embedding and a set of reference image embeddings drawn from a joint image-text embedding space.
Concretely, we begin by sampling <math alttext="M" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.m1" intent=":literal"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> caption-image pairs <math alttext="\left\{(x_{i}^{\text{cap}},\ x_{i}^{\text{img}})\mid i\in[M]\right\}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.m2" intent=":literal"><semantics><mrow><mo>{</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>x</mi><mi>i</mi><mtext>cap</mtext></msubsup><mo rspace="0.667em">,</mo><msubsup><mi>x</mi><mi>i</mi><mtext>img</mtext></msubsup><mo stretchy="false">)</mo></mrow><mo fence="true" lspace="0em" rspace="0em">∣</mo><mrow><mi>i</mi><mo>∈</mo><mrow><mo stretchy="false">[</mo><mi>M</mi><mo stretchy="false">]</mo></mrow></mrow><mo>}</mo></mrow><annotation encoding="application/x-tex">\left\{(x_{i}^{\text{cap}},\ x_{i}^{\text{img}})\mid i\in[M]\right\}</annotation></semantics></math> from a general SAE dataset such as MSCOCO <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib31" title="">2014</a>)</cite>. For each pair, we compute the caption embedding <math alttext="C_{i}=\pi_{0}(x_{i}^{\text{cap}})" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.m3" intent=":literal"><semantics><mrow><msub><mi>C</mi><mi>i</mi></msub><mo>=</mo><mrow><msub><mi>π</mi><mn>0</mn></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>x</mi><mi>i</mi><mtext>cap</mtext></msubsup><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">C_{i}=\pi_{0}(x_{i}^{\text{cap}})</annotation></semantics></math> using a frozen text encoder <math alttext="\pi_{0}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.m4" intent=":literal"><semantics><msub><mi>π</mi><mn>0</mn></msub><annotation encoding="application/x-tex">\pi_{0}</annotation></semantics></math>, and the corresponding image embedding <math alttext="I_{i}=\phi_{0}(x_{i}^{\text{img}})" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.m5" intent=":literal"><semantics><mrow><msub><mi>I</mi><mi>i</mi></msub><mo>=</mo><mrow><msub><mi>ϕ</mi><mn>0</mn></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>x</mi><mi>i</mi><mtext>img</mtext></msubsup><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">I_{i}=\phi_{0}(x_{i}^{\text{img}})</annotation></semantics></math> using a frozen image encoder <math alttext="\phi_{0}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.m6" intent=":literal"><semantics><msub><mi>ϕ</mi><mn>0</mn></msub><annotation encoding="application/x-tex">\phi_{0}</annotation></semantics></math>, with both encoders operating in the same shared text-image embedding space. The resulting image embeddings <math alttext="\left\{I_{i}\mid i\in[M]\right\}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.m7" intent=":literal"><semantics><mrow><mo>{</mo><msub><mi>I</mi><mi>i</mi></msub><mo fence="true" lspace="0em" rspace="0em">∣</mo><mrow><mi>i</mi><mo>∈</mo><mrow><mo stretchy="false">[</mo><mi>M</mi><mo stretchy="false">]</mo></mrow></mrow><mo>}</mo></mrow><annotation encoding="application/x-tex">\left\{I_{i}\mid i\in[M]\right\}</annotation></semantics></math> serve as reference anchors for computing similarity scores with a given caption embedding. These scores act as surrogate logits that approximate the output distributions required for the KL divergence computation. Specifically, for each caption <math alttext="x_{i}^{\text{cap}}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.m8" intent=":literal"><semantics><msubsup><mi>x</mi><mi>i</mi><mtext>cap</mtext></msubsup><annotation encoding="application/x-tex">x_{i}^{\text{cap}}</annotation></semantics></math>, we define the approximated output distributions for the frozen encoder <math alttext="\pi_{0}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.m9" intent=":literal"><semantics><msub><mi>π</mi><mn>0</mn></msub><annotation encoding="application/x-tex">\pi_{0}</annotation></semantics></math> and the trainable target encoder <math alttext="\pi" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.m10" intent=":literal"><semantics><mi>π</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math> as:</p>
<table class="ltx_equationgroup ltx_eqn_table" id="S5.E6">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S5.E6X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathbf{s}^{\pi_{0}}_{i}" class="ltx_Math" display="inline" id="S5.E6X.m2" intent=":literal"><semantics><msubsup><mi>𝐬</mi><mi>i</mi><msub><mi>π</mi><mn>0</mn></msub></msubsup><annotation encoding="application/x-tex">\displaystyle\mathbf{s}^{\pi_{0}}_{i}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\left[\langle I_{1},C_{i}\rangle,\ \dots,\ \langle I_{M},C_{i}\rangle\right]," class="ltx_Math" display="inline" id="S5.E6X.m3" intent=":literal"><semantics><mrow><mrow><mi></mi><mo>=</mo><mrow><mo>[</mo><mrow><mo stretchy="false">⟨</mo><msub><mi>I</mi><mn>1</mn></msub><mo>,</mo><msub><mi>C</mi><mi>i</mi></msub><mo stretchy="false">⟩</mo></mrow><mo rspace="0.667em">,</mo><mi mathvariant="normal">…</mi><mo rspace="0.667em">,</mo><mrow><mo stretchy="false">⟨</mo><msub><mi>I</mi><mi>M</mi></msub><mo>,</mo><msub><mi>C</mi><mi>i</mi></msub><mo stretchy="false">⟩</mo></mrow><mo>]</mo></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\displaystyle=\left[\langle I_{1},C_{i}\rangle,\ \dots,\ \langle I_{M},C_{i}\rangle\right],</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="2"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(6)</span></td>
</tr>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S5.E6Xa">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathbf{s}^{\pi}_{i}" class="ltx_Math" display="inline" id="S5.E6Xa.m2" intent=":literal"><semantics><msubsup><mi>𝐬</mi><mi>i</mi><mi>π</mi></msubsup><annotation encoding="application/x-tex">\displaystyle\mathbf{s}^{\pi}_{i}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\left[\langle I_{1},C^{\prime}_{i}\rangle,\ \dots,\ \langle I_{M},C^{\prime}_{i}\rangle\right]," class="ltx_Math" display="inline" id="S5.E6Xa.m3" intent=":literal"><semantics><mrow><mrow><mi></mi><mo>=</mo><mrow><mo>[</mo><mrow><mo stretchy="false">⟨</mo><msub><mi>I</mi><mn>1</mn></msub><mo>,</mo><msubsup><mi>C</mi><mi>i</mi><mo>′</mo></msubsup><mo stretchy="false">⟩</mo></mrow><mo rspace="0.667em">,</mo><mi mathvariant="normal">…</mi><mo rspace="0.667em">,</mo><mrow><mo stretchy="false">⟨</mo><msub><mi>I</mi><mi>M</mi></msub><mo>,</mo><msubsup><mi>C</mi><mi>i</mi><mo>′</mo></msubsup><mo stretchy="false">⟩</mo></mrow><mo>]</mo></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\displaystyle=\left[\langle I_{1},C^{\prime}_{i}\rangle,\ \dots,\ \langle I_{M},C^{\prime}_{i}\rangle\right],</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p class="ltx_p">where <math alttext="C^{\prime}_{i}=\pi(x_{i}^{\text{cap}})" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.m11" intent=":literal"><semantics><mrow><msubsup><mi>C</mi><mi>i</mi><mo>′</mo></msubsup><mo>=</mo><mrow><mi>π</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>x</mi><mi>i</mi><mtext>cap</mtext></msubsup><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">C^{\prime}_{i}=\pi(x_{i}^{\text{cap}})</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.SSS0.Px3.p2">
<p class="ltx_p">Given these simulated logits, we define the KL divergence loss to encourage the target encoder’s output distribution to remain close to that of the frozen encoder:</p>
<table class="ltx_equationgroup ltx_eqn_table" id="S5.E7">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S5.E7X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{KL}}" class="ltx_Math" display="inline" id="S5.E7X.m2" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mtext>KL</mtext></msub><annotation encoding="application/x-tex">\displaystyle\mathcal{L}_{\text{KL}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{1}{M}\sum_{i=1}^{M}\text{KL}\left(\operatorname{softmax}(\mathbf{s}^{\pi}_{i})\,\|\,\operatorname{softmax}(\mathbf{s}^{\pi_{0}}_{i})\right)." class="ltx_Math" display="inline" id="S5.E7X.m3" intent=":literal"><semantics><mrow><mrow><mi></mi><mo>=</mo><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><mi>M</mi></mfrac></mstyle><mo lspace="0em" rspace="0em">​</mo><mrow><mstyle displaystyle="true"><munderover><mo movablelimits="false">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover></mstyle><mrow><mtext>KL</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><mrow><mrow><mi>softmax</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>𝐬</mi><mi>i</mi><mi>π</mi></msubsup><mo rspace="0.170em" stretchy="false">)</mo></mrow></mrow><mo rspace="0.448em">∥</mo><mrow><mi>softmax</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>𝐬</mi><mi>i</mi><msub><mi>π</mi><mn>0</mn></msub></msubsup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\displaystyle=\frac{1}{M}\sum_{i=1}^{M}\text{KL}\left(\operatorname{softmax}(\mathbf{s}^{\pi}_{i})\,\|\,\operatorname{softmax}(\mathbf{s}^{\pi_{0}}_{i})\right).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(7)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p">This approach is compatible with CLIP-style models <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib39" title="">2021</a>; Zhai et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib51" title="">2023</a>)</cite>, in which image and text embeddings are aligned within a shared representation space. When an image encoder is unavailable, we instead use the frozen caption embeddings <math alttext="\left\{C_{i}\mid i\in[M]\right\}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p2.m1" intent=":literal"><semantics><mrow><mo>{</mo><msub><mi>C</mi><mi>i</mi></msub><mo fence="true" lspace="0em" rspace="0em">∣</mo><mrow><mi>i</mi><mo>∈</mo><mrow><mo stretchy="false">[</mo><mi>M</mi><mo stretchy="false">]</mo></mrow></mrow><mo>}</mo></mrow><annotation encoding="application/x-tex">\left\{C_{i}\mid i\in[M]\right\}</annotation></semantics></math> as proxies for reference anchors. We hereafter refer to the case where image embeddings are used as reference anchors as “Image KL Reg.” and the one using text embeddings as “Text KL Reg.”</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.SSS0.Px3.p3">
<p class="ltx_p">Based on these design choices, the final combined loss function integrates all three components: <math alttext="\mathcal{L}=\mathcal{L}_{\text{DL}}+\mathcal{L}_{\text{PC}}+\mathcal{L}_{\text{KL}}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p3.m1" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ℒ</mi><mo>=</mo><mrow><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mtext>DL</mtext></msub><mo>+</mo><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mtext>PC</mtext></msub><mo>+</mo><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mtext>KL</mtext></msub></mrow></mrow><annotation encoding="application/x-tex">\mathcal{L}=\mathcal{L}_{\text{DL}}+\mathcal{L}_{\text{PC}}+\mathcal{L}_{\text{KL}}</annotation></semantics></math> as illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.F2" title="In 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">2</span></a>.
For more details, please refer to <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A2" title="Appendix B Implementation Details ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Appendix</span>˜<span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Mitigation Results</h3>
<div class="ltx_para ltx_noindent" id="S5.SS3.p1">
<p class="ltx_p">Here, we validate all baselines and our method on SD1.5 and SDXL. Due to space limitations, the results for SDXL are reported in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A6" title="Appendix F Mitigation Results on Stable Diffusion XL ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Appendix</span>˜<span class="ltx_text ltx_ref_tag">F</span></a>.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.1 </span>Comparison with the Baselines</h4>
<div class="ltx_para ltx_noindent" id="S5.SS3.SSS1.p1">
<p class="ltx_p">As shown in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.T3" title="In Polysemy Control ‣ 5.2 Our Method ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">3</span></a>, prompt rewriting methods that operate solely at the input level do not degrade SAE MSCOCO or polysemy performance, but yield only slight improvements up to 6.1% in average dialect performance. Furthermore, UNet fine-tuning approaches also lead to small gains of up to 5.7% in dialect performance, but at the cost of substantial drops in both general SAE and polysemy scores. In contrast, our method, corresponding to the last row of the table and incorporating all three loss components described in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.SS2" title="5.2 Our Method ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Section</span>˜<span class="ltx_text ltx_ref_tag">5.2</span></a>, significantly improves dialect robustness across all five dialects. Its average dialect performance of 77.68% closely approaches the base model’s SAE score of 77.91%, while causing negligible degradation in SAE MSCOCO and polysemy performance.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.2 </span>Ablation Study</h4>
<div class="ltx_para ltx_noindent" id="S5.SS3.SSS2.p1">
<p class="ltx_p">To evaluate the contribution of each component in our method, we conduct an ablation study here.</p>
</div>
<section class="ltx_paragraph" id="S5.SS3.SSS2.Px1">
<h5 class="ltx_title ltx_title_paragraph">Base Model vs. Dialect Learning</h5>
<div class="ltx_para ltx_noindent" id="S5.SS3.SSS2.Px1.p1">
<p class="ltx_p">As shown in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.T3" title="In Polysemy Control ‣ 5.2 Our Method ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">3</span></a>, applying the Dialect Learning loss (<math alttext="\mathcal{L}_{\text{DL}}" class="ltx_Math" display="inline" id="S5.SS3.SSS2.Px1.p1.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mtext>DL</mtext></msub><annotation encoding="application/x-tex">\mathcal{L}_{\text{DL}}</annotation></semantics></math>) alone yields huge improvements in the base model’s dialect performance, but also degrades SAE MSCOCO and polysemy performance.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS3.SSS2.Px2">
<h5 class="ltx_title ltx_title_paragraph">Cosine Reg. vs. KL Reg.</h5>
<div class="ltx_para ltx_noindent" id="S5.SS3.SSS2.Px2.p1">
<p class="ltx_p">To solve this issue, simply maximizing cosine similarity between the target text encoder’s text embeddings and the corresponding text/image embeddings from the frozen text/image encoder (denoted as Text/Image Cosine Reg.), which is computed over the same caption-image pairs used in our KL regularization, does not effectively recover the base model’s SAE MSCOCO and polysemy performance. In contrast, adding our KL regularization loss (<math alttext="\mathcal{L}_{\text{KL}}" class="ltx_Math" display="inline" id="S5.SS3.SSS2.Px2.p1.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mtext>KL</mtext></msub><annotation encoding="application/x-tex">\mathcal{L}_{\text{KL}}</annotation></semantics></math>) improves both metrics while preserving dialect gains.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS3.SSS2.Px3">
<h5 class="ltx_title ltx_title_paragraph">Adding Polysemy Ctrl.</h5>
<div class="ltx_para ltx_noindent" id="S5.SS3.SSS2.Px3.p1">
<p class="ltx_p">Finally, incorporating the Polysemy Control loss (<math alttext="\mathcal{L}_{\text{PC}}" class="ltx_Math" display="inline" id="S5.SS3.SSS2.Px3.p1.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mtext>PC</mtext></msub><annotation encoding="application/x-tex">\mathcal{L}_{\text{PC}}</annotation></semantics></math>) yields substantial gains in polysemy performance, improving it by 17.43% and 17.76% for Text and Image KL Reg. respectively, underscoring the importance of this component in recognizing polysemous lexemes within SAE contexts.</p>
</div>
</section>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p">Our study focuses on the lexical variations that characterize dialects, motivated by the empirical observation that such variations exert much greater influence on multimodal generative model performance than grammatical variations (see <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A7" title="Appendix G Grammatical vs. Lexical Robustness in Multimodal Models ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Appendix</span>˜<span class="ltx_text ltx_ref_tag">G</span></a>). Furthermore, grammatical variation has already been the subject of extensive investigation in text-only contexts <cite class="ltx_cite ltx_citemacro_citep">(Hudson, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib26" title="">1996</a>; Chambers &amp; Trudgill, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib9" title="">1998</a>; Fromkin et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib18" title="">1998</a>; Nerbonne, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib33" title="">2009</a>; Wardhaugh &amp; Fuller, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib48" title="">2021</a>)</cite>. These considerations jointly motivate our decision to prioritize the evaluation of lexical dialect variation, which appears especially consequential in the multimodal generative setting.
Furthermore, our evaluation of text-image alignment utilizes reference-free metrics, namely VQAScore <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib32" title="">2024</a>)</cite> and CLIPScore <cite class="ltx_cite ltx_citemacro_citep">(Hessel et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib24" title="">2021</a>)</cite>. We recognize that these pretrained vision-language models are not perfect. To address this potential weakness, we conducted a thorough human evaluation and found very high statistical correlation between our automatic metrics and human judgment (Pearson correlation coefficient <math alttext="r" class="ltx_Math" display="inline" id="S6.p1.m1" intent=":literal"><semantics><mi>r</mi><annotation encoding="application/x-tex">r</annotation></semantics></math> = 0.968 for VQAScore and <math alttext="r" class="ltx_Math" display="inline" id="S6.p1.m2" intent=":literal"><semantics><mi>r</mi><annotation encoding="application/x-tex">r</annotation></semantics></math> = 0.924 for CLIPScore). Therefore, while acknowledging the imperfections of automated metrics, this high degree of human correlation provides strong evidence for the validity of our evaluation metrics and associated analysis conclusions.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusions</h2>
<div class="ltx_para ltx_noindent" id="S7.p1">
<p class="ltx_p">In this work, we create <span class="ltx_text ltx_font_bold">DialectGen</span>, a large-scale multi-dialectal benchmark evaluating the dialect robustness of multimodal generative models. Our experiments on 17 widely used text-to-image and text-to-video generative models reveal severe performance drops up to 38.63% and 48.17% for image and video generative models, respectively. We further design an encoder-based mitigation strategy to enhance dialect robustness while preserving performance on Standard American English.</p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Ethics Statement</h2>
<div class="ltx_para ltx_noindent" id="S8.p1">
<p class="ltx_p">This work makes use of human subjects for annotation and evaluation. All procedures were subject to ethical review and were approved by the IRB from the authors’ institution. Consent was gathered in accordance with the authors’ institution guidelines, and annotators had access to a data use statement when giving consent. The purpose of <span class="ltx_text ltx_font_bold">DialectGen</span> is to provide tools that enable researchers and practitioners to evaluate and improve dialect robustness in their models. We will release these data responsibly, ensuring that users sign a Data Use Agreement that forbids the use of <span class="ltx_text ltx_font_bold">DialectGen</span> for deception, impersonation, mockery, discrimination, hate speech, targeted harassment, and cultural appropriation. In the agreement, researchers and practitioners will also acknowledge the limitations of this work, that <span class="ltx_text ltx_font_bold">DialectGen</span> may not fully or accurately represent the natural usage patterns of all sub-communities of speakers. <span class="ltx_text ltx_font_bold">DialectGen</span> is designed to be easily updatable and configurable, such that it can be extended by and for specific sub-communities and updated as dialects evolve over time. We have carefully checked our data to make sure no personally identifying information or offensive content is included. When utilizing existing artifacts and models, we make sure to follow all relevant regulations and licenses.</p>
</div>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Reproducibility Statement</h2>
<div class="ltx_para ltx_noindent" id="S9.p1">
<p class="ltx_p">We have taken several steps to ensure the reproducibility of our work. Detailed descriptions of dataset construction, annotation procedures, evaluation protocols, and mitigation methods are provided in the main paper (see Sections <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S3" title="3 DialectGen Benchmark ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4" title="4 Experiments ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">4</span></a>, etc.), with further implementation details, training configurations, and additional qualitative results included in the appendix (see Sections <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A2" title="Appendix B Implementation Details ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">B</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A1" title="Appendix A Qualitative Comparison ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">A</span></a>, etc.). To facilitate independent verification, we also provide as anonymized supplementary material both the DialectGen benchmark dataset and the source code used for data processing, model training, and evaluation. The dataset files include all validated dialect–SAE prompt pairs, while the code folder contains scripts for dataset generation, automatic and human evaluation, and reproduction of all tables and figures reported in the paper. Together, these resources enable researchers to replicate our experimental results and extend the benchmark for future work.</p>
</div>
</section>
<section class="ltx_section" id="S10">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">10 </span>Acknowledgements</h2>
<div class="ltx_para ltx_noindent" id="S10.p1">
<p class="ltx_p">We would like to thank Connor Couture and Allen Cheung for designing the initial version of our MTurk annotation interface, and Xinrong Du for providing feedback. We also thank Prof. Diyi Yang, Prof. Xiang Chen, Caleb Ziems, Julia Kruk, Hritik Bansal, Jiachen Gu, Zongyu Lin, and Amita Kamath for valuable discussions and pointers; and especially Caleb Ziems for sharing the grammar-based dialect-speaker quiz he created. Finally, we appreciate Wenbo Hu, Lucas Bandarkar, Mohsen Fayyaz, and Tanmay Parekh for their helpful feedback on the paper draft.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aeni et al. (2021)</span>
<span class="ltx_bibblock">
Nur Aeni, Like Raskova Octaberlina, Nenni Dwi Aprianti Lubis, et al.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">A literature review of English Language Variation on Sociolinguistics</em>.

</span>
<span class="ltx_bibblock">OSF, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agarwal et al. (2025)</span>
<span class="ltx_bibblock">
Niket Agarwal, Arslan Ali, Maciej Bala, Yogesh Balaji, Erik Barker, Tiffany Cai, Prithvijit Chattopadhyay, Yongxin Chen, Yin Cui, Yifan Ding, et al.

</span>
<span class="ltx_bibblock">Cosmos world foundation model platform for physical ai.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2501.03575</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender et al. (2021)</span>
<span class="ltx_bibblock">
Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell.

</span>
<span class="ltx_bibblock">On the dangers of stochastic parrots: Can language models be too big?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the 2021 ACM conference on fairness, accountability, and transparency</em>, pp.  610–623, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Betker et al. (2023)</span>
<span class="ltx_bibblock">
James Betker, Gabriel Goh, Li Jing, Tim Brooks, Jianfeng Wang, Linjie Li, Long Ouyang, Juntang Zhuang, Joyce Lee, Yufei Guo, et al.

</span>
<span class="ltx_bibblock">Improving image generation with better captions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf</em>, 2(3):8, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Black et al. (2023)</span>
<span class="ltx_bibblock">
Kevin Black, Michael Janner, Yilun Du, Ilya Kostrikov, and Sergey Levine.

</span>
<span class="ltx_bibblock">Training diffusion models with reinforcement learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.13301</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Black Forest Labs (2024)</span>
<span class="ltx_bibblock">
Black Forest Labs.

</span>
<span class="ltx_bibblock">Flux.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/black-forest-labs/flux" title="">https://github.com/black-forest-labs/flux</a>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blodgett et al. (2018)</span>
<span class="ltx_bibblock">
Su Lin Blodgett, Johnny Wei, and Brendan O’Connor.

</span>
<span class="ltx_bibblock">Twitter universal dependency parsing for african-american and mainstream american english.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pp.  1415–1425, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cassidy et al. (1985)</span>
<span class="ltx_bibblock">
Frederic G Cassidy, Joan Houston Hall, and Luanne Von Schneidemesser.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Dictionary of American regional english</em>, volume 1.

</span>
<span class="ltx_bibblock">Belknap Press of Harvard University Press Cambridge, Mass., 1985.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chambers &amp; Trudgill (1998)</span>
<span class="ltx_bibblock">
Jack K Chambers and Peter Trudgill.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Dialectology</em>.

</span>
<span class="ltx_bibblock">Cambridge University Press, 1998.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
Zijie Chen, Lichao Zhang, Fangsheng Weng, Lili Pan, and Zhenzhong Lan.

</span>
<span class="ltx_bibblock">Tailored visions: Enhancing text-to-image generation with personalized prompt rewriting.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  7727–7736, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et al. (2023)</span>
<span class="ltx_bibblock">
Kevin Clark, Paul Vicol, Kevin Swersky, and David J Fleet.

</span>
<span class="ltx_bibblock">Directly fine-tuning diffusion models on differentiable rewards.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.17400</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Crystal (2003)</span>
<span class="ltx_bibblock">
David Crystal.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">English as a Global Language</em>.

</span>
<span class="ltx_bibblock">Cambridge University Press, Cambridge, 2 edition, 2003.

</span>
<span class="ltx_bibblock">ISBN 9780521823470.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al. (2023)</span>
<span class="ltx_bibblock">
Xiaoliang Dai, Ji Hou, Chih-Yao Ma, Sam Tsai, Jialiang Wang, Rui Wang, Peizhao Zhang, Simon Vandenhende, Xiaofang Wang, Abhimanyu Dubey, et al.

</span>
<span class="ltx_bibblock">Emu: Enhancing image generation models using photogenic needles in a haystack.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.15807</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dang et al. (2025)</span>
<span class="ltx_bibblock">
Meihua Dang, Anikait Singh, Linqi Zhou, Stefano Ermon, and Jiaming Song.

</span>
<span class="ltx_bibblock">Personalized preference fine-tuning of diffusion models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2501.06655</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dayma et al. (2021)</span>
<span class="ltx_bibblock">
Boris Dayma, Suraj Patil, Pedro Cuenca, Khalid Saifullah, Tanishq Abraham, Phúc Lê Khac, Luke Melas, and Ritobrata Ghosh.

</span>
<span class="ltx_bibblock">Dall·e mini, 7 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/borisdayma/dalle-mini" title="">https://github.com/borisdayma/dalle-mini</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Esser et al. (2024)</span>
<span class="ltx_bibblock">
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Müller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et al.

</span>
<span class="ltx_bibblock">Scaling rectified flow transformers for high-resolution image synthesis, 2024.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">URL https://arxiv. org/abs/2403.03206</em>, 2, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al. (2023)</span>
<span class="ltx_bibblock">
Ying Fan, Olivia Watkins, Yuqing Du, Hao Liu, Moonkyung Ryu, Craig Boutilier, Pieter Abbeel, Mohammad Ghavamzadeh, Kangwook Lee, and Kimin Lee.

</span>
<span class="ltx_bibblock">Dpok: Reinforcement learning for fine-tuning text-to-image diffusion models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 36:79858–79885, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fromkin et al. (1998)</span>
<span class="ltx_bibblock">
VA Fromkin, Robert Rodman, and V Hyams.

</span>
<span class="ltx_bibblock">An introduction to language 6e.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Hartcourt Brace College Publishers: Orlando, FL, USA</em>, 1998.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gates et al. (2023)</span>
<span class="ltx_bibblock">
Henry Louis Gates, James Murray, et al.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">The Oxford Regional English Dictionary</em>.

</span>
<span class="ltx_bibblock">Oxford University Press, Oxford, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grattafiori et al. (2024)</span>
<span class="ltx_bibblock">
Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, et al.

</span>
<span class="ltx_bibblock">The llama 3 herd of models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2407.21783</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gururangan et al. (2022)</span>
<span class="ltx_bibblock">
Suchin Gururangan, Dallas Card, Sarah K Dreier, Emily K Gade, Leroy Z Wang, Zeyu Wang, Luke Zettlemoyer, and Noah A Smith.

</span>
<span class="ltx_bibblock">Whose language counts as high quality? measuring language ideologies in text data selection.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.10474</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hao et al. (2023)</span>
<span class="ltx_bibblock">
Yaru Hao, Zewen Chi, Li Dong, and Furu Wei.

</span>
<span class="ltx_bibblock">Optimizing prompts for text-to-image generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 36:66923–66939, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heinmiller (2023)</span>
<span class="ltx_bibblock">
Jennifer KN Heinmiller.

</span>
<span class="ltx_bibblock">Compiling the oxford dictionary of african american english: A progress report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Dictionaries: Journal of the Dictionary Society of North America</em>, 44(1):91–104, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hessel et al. (2021)</span>
<span class="ltx_bibblock">
Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Joseph Le Bras, and Yejin Choi.

</span>
<span class="ltx_bibblock">Clipscore: A reference-free evaluation metric for image captioning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language Processing</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hovy &amp; Spruit (2016)</span>
<span class="ltx_bibblock">
Dirk Hovy and Shannon L Spruit.

</span>
<span class="ltx_bibblock">The social impact of natural language processing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, pp.  591–598, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hudson (1996)</span>
<span class="ltx_bibblock">
Richard A Hudson.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Sociolinguistics</em>.

</span>
<span class="ltx_bibblock">Cambridge university press, 1996.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hurst et al. (2024)</span>
<span class="ltx_bibblock">
Aaron Hurst, Adam Lerer, Adam P Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al.

</span>
<span class="ltx_bibblock">Gpt-4o system card.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2410.21276</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jørgensen et al. (2015)</span>
<span class="ltx_bibblock">
Anna Jørgensen, Dirk Hovy, and Anders Søgaard.

</span>
<span class="ltx_bibblock">Challenges of studying and processing dialects in social media.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the workshop on noisy user-generated text</em>, pp.  9–18, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee (2004)</span>
<span class="ltx_bibblock">
Jack Tsen-Ta Lee.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">A Dictionary of Singlish and Singapore English</em>.

</span>
<span class="ltx_bibblock">Lee, Jack Tsen-Ta, 2004.

</span>
<span class="ltx_bibblock">Accessed 2025-05-16.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2023)</span>
<span class="ltx_bibblock">
Tony Lee, Michihiro Yasunaga, Chenlin Meng, Yifan Mai, Joon Sung Park, Agrim Gupta, Yunzhi Zhang, Deepak Narayanan, Hannah Teufel, Marco Bellagente, et al.

</span>
<span class="ltx_bibblock">Holistic evaluation of text-to-image models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 36:69981–70011, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2014)</span>
<span class="ltx_bibblock">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick.

</span>
<span class="ltx_bibblock">Microsoft coco: Common objects in context.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">European Conference on Computer Vision (ECCV)</em>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2024)</span>
<span class="ltx_bibblock">
Zhiqiu Lin, Deepak Pathak, Baiqi Li, Jiayao Li, Xide Xia, Graham Neubig, Pengchuan Zhang, and Deva Ramanan.

</span>
<span class="ltx_bibblock">Evaluating text-to-visual generation with image-to-text generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">European Conference on Computer Vision</em>, pp.  366–384. Springer, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nerbonne (2009)</span>
<span class="ltx_bibblock">
John Nerbonne.

</span>
<span class="ltx_bibblock">Data-driven dialectology.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Language and linguistics compass</em>, 3(1):175–198, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2025)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Introducing 4o image generation.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/index/introducing-4o-image-generation/" title="">https://openai.com/index/introducing-4o-image-generation/</a>, 2025.

</span>
<span class="ltx_bibblock">Accessed: 2025-05-19.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2025)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4.1.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/index/gpt-4-1/" title="">https://openai.com/index/gpt-4-1/</a>, April 2025.

</span>
<span class="ltx_bibblock">Accessed 18 May 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pearson (1895)</span>
<span class="ltx_bibblock">
Karl Pearson.

</span>
<span class="ltx_bibblock">Notes on regression and inheritance in the case of two parents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Proceedings of the Royal Society of London</em>, 58:240–242, 1895.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1098/rspl.1895.0041</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Podell et al. (2023)</span>
<span class="ltx_bibblock">
Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna, and Robin Rombach.

</span>
<span class="ltx_bibblock">Sdxl: Improving latent diffusion models for high-resolution image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.01952</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prabhudesai et al. (2023)</span>
<span class="ltx_bibblock">
Mihir Prabhudesai, Anirudh Goyal, Deepak Pathak, and Katerina Fragkiadaki.

</span>
<span class="ltx_bibblock">Aligning text-to-image diffusion models with reward backpropagation (2023).

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.03739</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2021)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramesh et al. (2022)</span>
<span class="ltx_bibblock">
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.

</span>
<span class="ltx_bibblock">Dall·e 2: A new ai system that can create realistic images and art from a description in natural language.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/research/dall-e-2" title="">https://openai.com/research/dall-e-2</a>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rombach et al. (2022)</span>
<span class="ltx_bibblock">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer.

</span>
<span class="ltx_bibblock">High-resolution image synthesis with latent diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.  10684–10695, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Segalis et al. (2023)</span>
<span class="ltx_bibblock">
Eyal Segalis, Dani Valevski, Danny Lumen, Yossi Matias, and Yaniv Leviathan.

</span>
<span class="ltx_bibblock">A picture is worth a thousand words: Principled recaptioning improves image generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2310.16656, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:266003242" title="">https://api.semanticscholar.org/CorpusID:266003242</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Subhash (2020)</span>
<span class="ltx_bibblock">
V. Subhash.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Dictionary of Indian English</em>.

</span>
<span class="ltx_bibblock">V. Subhash, Hyderabad, 2020.

</span>
<span class="ltx_bibblock">ISBN 9789354374487.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wallace et al. (2024)</span>
<span class="ltx_bibblock">
Bram Wallace, Meihua Dang, Rafael Rafailov, Linqi Zhou, Aaron Lou, Senthil Purushwalkam, Stefano Ermon, Caiming Xiong, Shafiq Joty, and Nikhil Naik.

</span>
<span class="ltx_bibblock">Diffusion model alignment using direct preference optimization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  8228–8238, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al. (2024)</span>
<span class="ltx_bibblock">
Yixin Wan, Arjun Subramonian, Anaelia Ovalle, Zongyu Lin, Ashima Suvarna, Christina Chance, Hritik Bansal, Rebecca Pattichis, and Kai-Wei Chang.

</span>
<span class="ltx_bibblock">Survey of bias in text-to-image generation: Definition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Evaluation, and Mitigation</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2025)</span>
<span class="ltx_bibblock">
Ang Wang, Baole Ai, Bin Wen, Chaojie Mao, Chen-Wei Xie, Di Chen, Feiwu Yu, Haiming Zhao, Jianxiao Yang, Jianyuan Zeng, Jiayu Wang, Jingfeng Zhang, Jingren Zhou, Jinkai Wang, Jixuan Chen, Kai Zhu, Kang Zhao, Keyu Yan, Lianghua Huang, Mengyang Feng, Ningyi Zhang, Pandeng Li, Pingyu Wu, Ruihang Chu, Ruili Feng, Shiwei Zhang, Siyang Sun, Tao Fang, Tianxing Wang, Tianyi Gui, Tingyu Weng, Tong Shen, Wei Lin, Wei Wang, Wei Wang, Wenmeng Zhou, Wente Wang, Wenting Shen, Wenyuan Yu, Xianzhong Shi, Xiaoming Huang, Xin Xu, Yan Kou, Yangyu Lv, Yifei Li, Yijing Liu, Yiming Wang, Yingya Zhang, Yitong Huang, Yong Li, You Wu, Yu Liu, Yulin Pan, Yun Zheng, Yuntao Hong, Yupeng Shi, Yutong Feng, Zeyinzi Jiang, Zhen Han, Zhi-Fan Wu, and Ziyu Liu.

</span>
<span class="ltx_bibblock">Wan: Open and advanced large-scale video generative models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2503.20314</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024)</span>
<span class="ltx_bibblock">
Zhijie Wang, Yuheng Huang, Da Song, Lei Ma, and Tianyi Zhang.

</span>
<span class="ltx_bibblock">Promptcharm: Text-to-image generation through multi-modal prompting and refinement.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems</em>, pp.  1–21, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wardhaugh &amp; Fuller (2021)</span>
<span class="ltx_bibblock">
Ronald Wardhaugh and Janet M Fuller.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">An introduction to sociolinguistics</em>.

</span>
<span class="ltx_bibblock">John Wiley &amp; Sons, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Webster (1869)</span>
<span class="ltx_bibblock">
Noah Webster.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">An American dictionary of the English language</em>.

</span>
<span class="ltx_bibblock">Merriam, 1869.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2024)</span>
<span class="ltx_bibblock">
Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, et al.

</span>
<span class="ltx_bibblock">Cogvideox: Text-to-video diffusion models with an expert transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2408.06072</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhai et al. (2023)</span>
<span class="ltx_bibblock">
Xiaohua Zhai, Basil Mustafa, Alexander Kolesnikov, and Lucas Beyer.

</span>
<span class="ltx_bibblock">Sigmoid loss for language image pre-training.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF international conference on computer vision</em>, pp.  11975–11986, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023)</span>
<span class="ltx_bibblock">
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.

</span>
<span class="ltx_bibblock">Adding conditional control to text-to-image diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF international conference on computer vision</em>, pp.  3836–3847, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2025)</span>
<span class="ltx_bibblock">
Yu Zhou, Bingxuan Li, Mohan Tang, Xiaomeng Jin, Te-Lin Wu, Kuan-Hao Huang, Heng Ji, Kai-Wei Chang, and Nanyun Peng.

</span>
<span class="ltx_bibblock">Contrastive visual data augmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">ICML 2025</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ziems et al. (2022)</span>
<span class="ltx_bibblock">
Caleb Ziems, Jiaao Chen, Camille Harris, Jessica Brooke Anderson, and Diyi Yang.

</span>
<span class="ltx_bibblock">Value: Understanding dialect disparity in nlu.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational Linguistics</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ziems et al. (2023)</span>
<span class="ltx_bibblock">
Caleb Ziems, William B. Held, Jingfeng Yang, and Diyi Yang.

</span>
<span class="ltx_bibblock">Multi-value: A framework for cross-dialectal english nlp.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ACL 2023</em>, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Qualitative Comparison</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p">In <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A1.F3" title="In Appendix A Qualitative Comparison ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">3</span></a>, we provide additional qualitative examples to demonstrate the performances of the baseline mitigation strategy, Diffusion DPO <cite class="ltx_cite ltx_citemacro_citep">(Wallace et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib44" title="">2024</a>)</cite>, compared with our method. Specifically, we update the Stable Diffusion 1.5 model encoder using Dialect Learning, Polysemy Control, and Image KL. After mitigation, we ask each model to generate images based on the four dialect prompts first mentioned in  <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S0.F1" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">1</span></a>. The Stable Diffusion 1.5 Base model struggles to generate correct images for most of these prompts, including "Two ang pows on a table", "A man selling brinjal", and "A man hiking with his carnal". While the model is able to generate moderately reasonable images for the prompt "A man driving his whip", it commonly generates physically implausible details such as the man’s torso protruding through the car. Fine-tuning the UNet with Diffusion DPO is able to slightly improve generation alignment with the text prompt (<span class="ltx_text ltx_font_italic">e.g.</span>, occasionally generating two people for the prompt "A man hiking with his carnal"). However, it more often blends visual elements within the desired target images with other irrelevant objects (<span class="ltx_text ltx_font_italic">e.g.</span>, generating a man selling purple pastries in place of eggplants or a man wearing a purple shirt holding vegetables). Our method generates higher-quality and better aligned images compared to the base model and Diffusion DPO by accurately learning to generate the target concepts without negatively impacting image quality. A significant majority of images in our sampled generations are able to generate images that correctly depict the target prompts, in line with quantitative evaluation results.</p>
</div>
<figure class="ltx_figure" id="A1.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="469" id="A1.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>
<span class="ltx_text ltx_font_bold">Qualitative Comparison of Mitigation Strategies</span> using the Stable Diffusion 1.5 model <cite class="ltx_cite ltx_citemacro_citep">(Rombach et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib41" title="">2022</a>)</cite> on four different dialect prompts. Specifically, we compare the dialect prompt image generation results of the Stable Diffusion 1.5 Base Model, Stable Diffusion 1.5 fine-tuned with Diffusion DPO <cite class="ltx_cite ltx_citemacro_citep">(Wallace et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib44" title="">2024</a>)</cite>, and Stable Diffusion 1.5 updated via our best performing method (Dialect Learning + Image KL Regularization + Polysemy Control).</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Implementation Details</h2>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Data Preparation</h5>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px1.p1">
<p class="ltx_p">We first split the <span class="ltx_text ltx_font_bold">DialectGen</span> dataset into training, validation, and test sets in a ratio of 80%, 10%, and 10%, respectively. These training and validation splits of <span class="ltx_text ltx_font_bold">DialectGen</span> are used to compute the Dialect Learning loss and the Polysemy Control loss. For KL Regularization loss, we randomly sample 1,024 and 256 image-caption pairs from the MSCOCO validation set <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib31" title="">2014</a>)</cite> for use in training and validation, respectively. The target text encoder is evaluated on the validation set at the end of each epoch, and the checkpoint with the lowest validation loss is selected and saved for final evaluation. We then evaluate SAE polysemy and per-dialect performance using the test split of <span class="ltx_text ltx_font_bold">DialectGen</span>, and assess SAE MSCOCO performance on 50 randomly sampled captions from the MSCOCO validation set.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Training</h5>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px2.p1">
<p class="ltx_p">We employ the pretrained text encoder and fine-tune it for 30 epochs using the AdamW optimizer with an initial learning rate of <math alttext="1\times 10^{-4}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.m1" intent=":literal"><semantics><mrow><mn>1</mn><mo lspace="0.222em" rspace="0.222em">×</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup></mrow><annotation encoding="application/x-tex">1\times 10^{-4}</annotation></semantics></math>, <math alttext="\beta_{1}=0.9" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.m2" intent=":literal"><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn></mrow><annotation encoding="application/x-tex">\beta_{1}=0.9</annotation></semantics></math>, <math alttext="\beta_{2}=0.999" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.m3" intent=":literal"><semantics><mrow><msub><mi>β</mi><mn>2</mn></msub><mo>=</mo><mn>0.999</mn></mrow><annotation encoding="application/x-tex">\beta_{2}=0.999</annotation></semantics></math>, and <math alttext="\epsilon=1\times 10^{-8}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.m4" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mrow><mn>1</mn><mo lspace="0.222em" rspace="0.222em">×</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>8</mn></mrow></msup></mrow></mrow><annotation encoding="application/x-tex">\epsilon=1\times 10^{-8}</annotation></semantics></math>. A cosine annealing learning rate scheduler is applied across the 30 training epochs.
The batch size, <span class="ltx_text ltx_font_italic">i.e.</span>, <math alttext="N" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.m5" intent=":literal"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.E4" title="In Dialect Learning ‣ 5.2 Our Method ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Equation</span>˜<span class="ltx_text ltx_ref_tag">4</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.E5" title="In Polysemy Control ‣ 5.2 Our Method ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Equation</span>˜<span class="ltx_text ltx_ref_tag">5</span></a>, is set to 32, and the number of image-caption pairs used for KL regularization, <span class="ltx_text ltx_font_italic">i.e.</span>, <math alttext="M" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.m6" intent=":literal"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S5.E7" title="In KL Regularization ‣ 5.2 Our Method ‣ 5 Mitigation Methods ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Equation</span>˜<span class="ltx_text ltx_ref_tag">7</span></a>, is set to 1,024. Training is completed in less than one hour on a single NVIDIA RTX A6000 GPU. In the case of SDXL, which includes both Base and Refiner encoders, the number of pairs <math alttext="M" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.m7" intent=":literal"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> for the Refiner encoder is set to 512 due to its larger size, and training takes approximately one hour using four NVIDIA RTX A6000 GPUs, with all other configurations kept the same as in the Stable Diffusion 1.5 and SDXL Base encoder settings.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">About T2Video Models</h5>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px3.p1">
<p class="ltx_p">Video‐generation models incur substantially higher computational cost than their image counterparts. Since our primary goal is to assess the models’ ability to interpret and render textual prompts, we generate only a small, fixed number of frames per video. This strategy is justified by two observations: (i) the first few frames typically suffice to judge prompt fidelity, and (ii) our prompts do not exhibit extensive motion, so long sequences offer diminishing returns.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px3.p2">
<p class="ltx_p">All models were obtained by cloning their official repositories and following the authors’ installation instructions. Frame numbers were uniformly reduced frame counts when possible, and in some cases, spatial resolution was also reduced to facilitate efficient evaluation—see <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A3.T5" title="In Appendix C Model Details ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">5</span></a> for the precise settings.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px3.p3">
<p class="ltx_p">Average time per video was measured on a single NVIDIA RTX A6000 GPU; the Wan2.1‐T2V‐14B model, which does not fit in single‐GPU memory, was benchmarked using six A6000 GPUs under Fully Sharded Data Parallel (FSDP) supported by the repository under the xdit framework.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px3.p4">
<p class="ltx_p">All models except Wan2.1 fit under a single A6000 GPU and use approximately 20-30 GB of VRAM max. Wan2.1 takes at least 3 GPUs, taking an approximate memory usage of  100GB of combined VRAM.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Model Details</h2>
<div class="ltx_para ltx_noindent" id="A3.p1">
<p class="ltx_p">We provide detailed information on the multimodal generative models and key experimental settings used in our benchmark.</p>
</div>
<div class="ltx_para ltx_noindent" id="A3.p2">
<p class="ltx_p"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A3.T4" title="In Appendix C Model Details ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">4</span></a> lists the comprehensive specifications for all models evaluated in our work, including both text-to-image and text-to-video models. For each model, we provide details such as its creator organization, initial release date, hosting platform, availability type (<span class="ltx_text ltx_font_italic">e.g.</span>, open source, proprietary), and model size.</p>
</div>
<div class="ltx_para" id="A3.p3">
<p class="ltx_p"><a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A3.T5" title="In Appendix C Model Details ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">5</span></a> describes in detail the key generation parameters used for the text-to-video models. This includes the specific resolution, number of frames, and inference steps used for each model. Furthermore, we specify the average time required to generate a single video and the total time needed to generate our full video dataset to aid in understanding the reproducibility and computational cost of our experiments.</p>
</div>
<figure class="ltx_table" id="A3.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span><span class="ltx_text ltx_font_bold">Detailed Model Specifications</span> for all multimodal generative models (text-to-image and text-to-video generative models) benchmarked in this work. For reference and reproducibility, we include model name, model type, creator organization, initial release date, hosting platform, availability type, and model size.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:397.5pt;height:136pt;vertical-align:-66.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-118.6pt,40.6pt) scale(0.626288459215155,0.626288459215155) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Model Name</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Model Type</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Created by</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Release Date</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Hosted by</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Availability Type</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Model Size</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t">Stable Diffusion 1.4</td>
<td class="ltx_td ltx_align_left ltx_border_t">Text to Image</td>
<td class="ltx_td ltx_align_left ltx_border_t">CompVis</td>
<td class="ltx_td ltx_align_left ltx_border_t">8/22/2022</td>
<td class="ltx_td ltx_align_left ltx_border_t">Hugging Face</td>
<td class="ltx_td ltx_align_left ltx_border_t">Open Source</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">1B</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Stable Diffusion 1.5</td>
<td class="ltx_td ltx_align_left">Text to Image</td>
<td class="ltx_td ltx_align_left">Runway ML</td>
<td class="ltx_td ltx_align_left">10/20/2022</td>
<td class="ltx_td ltx_align_left">Hugging Face</td>
<td class="ltx_td ltx_align_left">Open Weights</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">1.3 B</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Stable Diffusion 2.1</td>
<td class="ltx_td ltx_align_left">Text to Image</td>
<td class="ltx_td ltx_align_left">Stability AI</td>
<td class="ltx_td ltx_align_left">12/7/2022</td>
<td class="ltx_td ltx_align_left">Hugging Face</td>
<td class="ltx_td ltx_align_left">Open Weights</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">1.3 B</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Stable Diffusion XL</td>
<td class="ltx_td ltx_align_left">Text to Image</td>
<td class="ltx_td ltx_align_left">Stability AI</td>
<td class="ltx_td ltx_align_left">7/26/2023</td>
<td class="ltx_td ltx_align_left">Hugging Face</td>
<td class="ltx_td ltx_align_left">Open Weights</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">6.6 B</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Stable Diffusion 3 Medium</td>
<td class="ltx_td ltx_align_left">Text to Image</td>
<td class="ltx_td ltx_align_left">Stability AI</td>
<td class="ltx_td ltx_align_left">6/12/2024</td>
<td class="ltx_td ltx_align_left">Hugging Face</td>
<td class="ltx_td ltx_align_left">Open Weights</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">2 B</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Stable Diffusion 3.5 Large</td>
<td class="ltx_td ltx_align_left">Text to Image</td>
<td class="ltx_td ltx_align_left">Stability AI</td>
<td class="ltx_td ltx_align_left">10/22/2024</td>
<td class="ltx_td ltx_align_left">Hugging Face</td>
<td class="ltx_td ltx_align_left">Open Weights</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">8.1 B</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Stable Diffusion 3.5 Large Turbo</td>
<td class="ltx_td ltx_align_left">Text to Image</td>
<td class="ltx_td ltx_align_left">Stability AI</td>
<td class="ltx_td ltx_align_left">10/22/2024</td>
<td class="ltx_td ltx_align_left">Hugging Face</td>
<td class="ltx_td ltx_align_left">Open Weights</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">8.1 B</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Flux.1 [dev]</td>
<td class="ltx_td ltx_align_left">Text to Image</td>
<td class="ltx_td ltx_align_left">Black Forest Labs</td>
<td class="ltx_td ltx_align_left">4/2/2024</td>
<td class="ltx_td ltx_align_left">Hugging Face</td>
<td class="ltx_td ltx_align_left">Open Weights</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">12B</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">DALL-E Mini</td>
<td class="ltx_td ltx_align_left">Text to Image</td>
<td class="ltx_td ltx_align_left">Boris Dayma et al.</td>
<td class="ltx_td ltx_align_left">7/25/2022</td>
<td class="ltx_td ltx_align_left">Github</td>
<td class="ltx_td ltx_align_left">Open Weights</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">0.4 B</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">DALL-E 2</td>
<td class="ltx_td ltx_align_left">Text to Image</td>
<td class="ltx_td ltx_align_left">OpenAI</td>
<td class="ltx_td ltx_align_left">9/28/2022</td>
<td class="ltx_td ltx_align_left">OpenAI</td>
<td class="ltx_td ltx_align_left">Proprietary</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">N/A</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">DALL-E 3</td>
<td class="ltx_td ltx_align_left">Text to Image</td>
<td class="ltx_td ltx_align_left">OpenAI</td>
<td class="ltx_td ltx_align_left">8/20/2023</td>
<td class="ltx_td ltx_align_left">OpenAI</td>
<td class="ltx_td ltx_align_left">Proprietary</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">N/A</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">gpt-image-1</td>
<td class="ltx_td ltx_align_left">Text to Image</td>
<td class="ltx_td ltx_align_left">OpenAI</td>
<td class="ltx_td ltx_align_left">4/23/2025</td>
<td class="ltx_td ltx_align_left">OpenAI</td>
<td class="ltx_td ltx_align_left">Proprietary</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">N/A</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">VideoCrafter-2</td>
<td class="ltx_td ltx_align_left">Text to Video</td>
<td class="ltx_td ltx_align_left">Tencent</td>
<td class="ltx_td ltx_align_left">1/26/2024</td>
<td class="ltx_td ltx_align_left">Hugging Face</td>
<td class="ltx_td ltx_align_left">Open Weights</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">1.4 B</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Open-Sora</td>
<td class="ltx_td ltx_align_left">Text to Video</td>
<td class="ltx_td ltx_align_left">HPC-AI Tech</td>
<td class="ltx_td ltx_align_left">6/17/2024</td>
<td class="ltx_td ltx_align_left">Hugging Face</td>
<td class="ltx_td ltx_align_left">Open Weights</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">1.2 B</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">CogVideoX</td>
<td class="ltx_td ltx_align_left">Text to Video</td>
<td class="ltx_td ltx_align_left">THUDM Lab</td>
<td class="ltx_td ltx_align_left">8/27/2024</td>
<td class="ltx_td ltx_align_left">Hugging Face</td>
<td class="ltx_td ltx_align_left">Open Weights</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">5 B</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Cosmos-1</td>
<td class="ltx_td ltx_align_left">Text to Video</td>
<td class="ltx_td ltx_align_left">Nvidia</td>
<td class="ltx_td ltx_align_left">1/6/2025</td>
<td class="ltx_td ltx_align_left">Hugging Face</td>
<td class="ltx_td ltx_align_left">Open Weights</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">7 B</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb">Wan 2.1</td>
<td class="ltx_td ltx_align_left ltx_border_bb">Text to Video</td>
<td class="ltx_td ltx_align_left ltx_border_bb">Alibaba</td>
<td class="ltx_td ltx_align_left ltx_border_bb">2/22/2025</td>
<td class="ltx_td ltx_align_left ltx_border_bb">Hugging Face</td>
<td class="ltx_td ltx_align_left ltx_border_bb">Open Weights</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">14 B</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="A3.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span><span class="ltx_text ltx_font_bold">Key Generation Parameters for Text-to-Video Generative Models</span>. For reproducibility and computational cost estimation, we list GPU runtime per video in minutes and GPU runtime for the full video dataset (both concise and detailed = 4110 videos) in hours. All computational costs are estimated for NVIDIA-A6000 GPUs with 48 GB Memory.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:397.5pt;height:51.4pt;vertical-align:-23.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-84.3pt,10.9pt) scale(0.702178954715351,0.702178954715351) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Model Version</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Resolution</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Frames</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Steps</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Time / Video (min)</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Time / Dataset (h)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t">VideoCrafter2</td>
<td class="ltx_td ltx_align_center ltx_border_t"><math alttext="512\times 512" class="ltx_Math" display="inline" id="A3.T5.m1" intent=":literal"><semantics><mrow><mn>512</mn><mo lspace="0.222em" rspace="0.222em">×</mo><mn>512</mn></mrow><annotation encoding="application/x-tex">512\times 512</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t">16</td>
<td class="ltx_td ltx_align_center ltx_border_t">50</td>
<td class="ltx_td ltx_align_center ltx_border_t">5.0</td>
<td class="ltx_td ltx_align_right ltx_border_t">342.5</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">OpenSora‐STDiT‐v3</td>
<td class="ltx_td ltx_align_center"><math alttext="405\times 720" class="ltx_Math" display="inline" id="A3.T5.m2" intent=":literal"><semantics><mrow><mn>405</mn><mo lspace="0.222em" rspace="0.222em">×</mo><mn>720</mn></mrow><annotation encoding="application/x-tex">405\times 720</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center">51</td>
<td class="ltx_td ltx_align_center">30</td>
<td class="ltx_td ltx_align_center">8.3</td>
<td class="ltx_td ltx_align_right">570.8</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">CogVideoX‐5b</td>
<td class="ltx_td ltx_align_center"><math alttext="720\times 480" class="ltx_Math" display="inline" id="A3.T5.m3" intent=":literal"><semantics><mrow><mn>720</mn><mo lspace="0.222em" rspace="0.222em">×</mo><mn>480</mn></mrow><annotation encoding="application/x-tex">720\times 480</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center">10</td>
<td class="ltx_td ltx_align_center">10</td>
<td class="ltx_td ltx_align_center">6.1</td>
<td class="ltx_td ltx_align_right">416.7</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Cosmos‐1.0‐Diffusion‐7B‐Text2World</td>
<td class="ltx_td ltx_align_center"><math alttext="704\times 1280" class="ltx_Math" display="inline" id="A3.T5.m4" intent=":literal"><semantics><mrow><mn>704</mn><mo lspace="0.222em" rspace="0.222em">×</mo><mn>1280</mn></mrow><annotation encoding="application/x-tex">704\times 1280</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center">121</td>
<td class="ltx_td ltx_align_center">35</td>
<td class="ltx_td ltx_align_center">26.5</td>
<td class="ltx_td ltx_align_right">1815.3</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb">Wan2.1‐T2V‐14B</td>
<td class="ltx_td ltx_align_center ltx_border_bb"><math alttext="832\times 480" class="ltx_Math" display="inline" id="A3.T5.m5" intent=":literal"><semantics><mrow><mn>832</mn><mo lspace="0.222em" rspace="0.222em">×</mo><mn>480</mn></mrow><annotation encoding="application/x-tex">832\times 480</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb">10</td>
<td class="ltx_td ltx_align_center ltx_border_bb">12</td>
<td class="ltx_td ltx_align_center ltx_border_bb">4.8</td>
<td class="ltx_td ltx_align_right ltx_border_bb">329.4</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center"><span class="ltx_text ltx_font_italic">Note: The dataset‐scale timing for Wan2.1-T2V-14B was measured using 6 A6000 GPUs using xdit FSDP.</span></p>
</div>
</div>
</figure>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Dataset Details</h2>
<div class="ltx_para ltx_noindent" id="A4.p1">
<p class="ltx_p">The final <span class="ltx_text ltx_font_bold">DialectGen</span> Dataset contains a total of 4632 prompts, which include 2100 non-SAE dialect prompts, 2100 SAE prompts, and 432 polysemous SAE prompts. The entire dataset is split into three subsets: training, validation, and test. The data split ratio is train : validation : test = 8 : 1 : 1. All benchmarking experiments are performed on the entire dataset, while for mitigation experiments, models are trained on the <span class="ltx_text ltx_font_bold">DialectGen</span> training set while evaluated on the validation set.</p>
</div>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Human Annotation Details</h2>
<figure class="ltx_figure" id="A5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="700" id="A5.F4.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>
<span class="ltx_text ltx_font_bold">The Amazon Mechanical Turk Data Annotation Interface</span> for dialect speaker human filtering of generated prompts (prompt generation details in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S3" title="3 DialectGen Benchmark ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Section</span>˜<span class="ltx_text ltx_ref_tag">3</span></a>). Human annotators may use the "View Instructions" button to collapse / re-open detailed annotation instructions at any time. The annotation interface places no maximum time limit on each annotation question. Human annotators are allowed to return to previously annotated questions and update their answers at any time.
</figcaption>
</figure>
<figure class="ltx_figure" id="A5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="1000" id="A5.F5.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>
<span class="ltx_text ltx_font_bold">The English Dialect Speaker Assessment Quiz</span> used for matching dialect speaker annotators to specific dialects for prompt annotation. We adapt the assessment quiz from the existing English Dialect Speaker Survey first created in MultiVALUE <cite class="ltx_cite ltx_citemacro_citep">(Ziems et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib55" title="">2023</a>)</cite>, which asks the human annotator to select their linguistic acceptability preference for 10 different dialect excerpts.
</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A5.p1">
<p class="ltx_p">In the creation of the <span class="ltx_text ltx_font_bold">DialectGen</span> Dataset, we recruit a total of 17 dialect speaker human annotators from Amazon Mechanical Turk. The demographic involves six annotators from Asia, eight annotators from North America, and 3 annotators from Europe. Each selected annotator is given the option to complete any number of questions as they prefer. We encourage each annotator to take regular breaks during the task and not to work consecutively for more than 2 hours on our task. Our task is relatively simple for dialect speakers as it mainly involves judging the plausibility and meaning of a sentence in their native dialect. We estimate each HIT to take around 12 seconds, this corresponds to an hourly wage of $15 USD. Our total annotation time is 21.84 hours, costing a total of $327.6. We ran 4 rounds of annotations, with a combined total of 6552 prompts. 35.9% of total proposed prompts were rejected by the annotators while 64.1% of prompts were approved.</p>
</div>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Mitigation Results on Stable Diffusion XL</h2>
<div class="ltx_para ltx_noindent" id="A6.p1">
<p class="ltx_p">Stable Diffusion XL consists of two encoders: a Base encoder and a Refiner encoder. We fine-tuned both components as part of our method. However, since the corresponding CLIP-style image encoder for the Refiner is not publicly accessible, only Text KL Regularization can be applied in this case. Given the Refiner’s larger size and additional encoding modules, we evaluate our final method against other baselines within this more complex configuration.</p>
</div>
<div class="ltx_para" id="A6.p2">
<p class="ltx_p">We report the mitigation results on Stable Diffusion XL <cite class="ltx_cite ltx_citemacro_citep">(Podell et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib37" title="">2023</a>)</cite> in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A6.T6" title="In Appendix F Mitigation Results on Stable Diffusion XL ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">6</span></a>, under the experimental setup described above. Similar to the findings on Stable Diffusion 1.5, Prompt Revision methods preserve general SAE performance but yield only marginal improvements in dialect VQAScore, with gains of up to 7.8%. Additionally, UNet fine-tuning methods also result in small gains of up to 5.3% in dialect performance, but at the cost of noticeable degradation in both SAE MSCOCO and SAE polysemy performance. In contrast, our method substantially improves dialect robustness across all five dialects, achieving an average performance of 85.99%, which surpasses the base model’s SAE score of 84.43%, while inducing less than a 1% drop in both SAE MSCOCO and SAE polysemy performance.</p>
</div>
<figure class="ltx_table" id="A6.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>
<span class="ltx_text ltx_font_bold">Mitigation results on SDXL <cite class="ltx_cite ltx_citemacro_citep">(Podell et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib37" title="">2023</a>)</cite></span> for all methods, including <span class="ltx_text ltx_font_bold">Overall Performances</span> on SAE MSCOCO, SAE Polysemy, average Dialect performance, and <span class="ltx_text ltx_font_bold">Dialect Performance</span> for each dialect, all measured using VQAScore <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib32" title="">2024</a>)</cite>. Cell colors reflect column-normalized performance values, with darker green indicating higher VQAScore performance.
</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:397.5pt;height:107.6pt;vertical-align:-52.1pt;"><span class="ltx_transformed_inner" style="transform:translate(-92.2pt,25.0pt) scale(0.683196192250918,0.683196192250918) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" rowspan="3"><span class="ltx_text ltx_font_bold">Mitigation Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="3"><span class="ltx_text ltx_font_bold">Overall Performances <math alttext="\uparrow" class="ltx_Math" display="inline" id="A6.T6.m1" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5">
<span class="ltx_text ltx_font_bold">Dialect Performance</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="A6.T6.m2" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column">SAE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column">SAE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Dialect</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" rowspan="2">AAE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" rowspan="2">BrE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" rowspan="2">ChE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" rowspan="2">InE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" rowspan="2">SgE</th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column">MSCOCO</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column">Polysemy</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Avg.</th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Base Model (Stable Diffusion XL)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">86.21</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">78.21</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">61.55</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="--ltx-bg-color:#F8FDFA;"><span class="ltx_text" style="--ltx-bg-color:#F8FDFA;">61.17</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="--ltx-bg-color:#F1FAF5;"><span class="ltx_text" style="--ltx-bg-color:#F1FAF5;">77.58</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">47.04</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">53.21</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="--ltx-bg-color:#EDF9F3;"><span class="ltx_text" style="--ltx-bg-color:#EDF9F3;">68.76</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Prompt Revision</span></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_r ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">   DALL-E 3 Prompt Rewrite</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#86D5AC;"><span class="ltx_text" style="--ltx-bg-color:#86D5AC;">85.36</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#81D3A8;"><span class="ltx_text" style="--ltx-bg-color:#81D3A8;">78.01</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#E5F6ED;"><span class="ltx_text" style="--ltx-bg-color:#E5F6ED;">66.49</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">59.93</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EBF8F1;"><span class="ltx_text" style="--ltx-bg-color:#EBF8F1;">77.92</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D3F0E0;"><span class="ltx_text" style="--ltx-bg-color:#D3F0E0;">60.61</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DBF2E6;"><span class="ltx_text" style="--ltx-bg-color:#DBF2E6;">63.62</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E3F5EC;"><span class="ltx_text" style="--ltx-bg-color:#E3F5EC;">70.39</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">   LLaMA 3 Prompt Translate</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8BD7AF;"><span class="ltx_text" style="--ltx-bg-color:#8BD7AF;">84.72</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">77.60</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#F1FAF5;"><span class="ltx_text" style="--ltx-bg-color:#F1FAF5;">64.19</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E9F7F0;"><span class="ltx_text" style="--ltx-bg-color:#E9F7F0;">63.74</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EBF8F1;"><span class="ltx_text" style="--ltx-bg-color:#EBF8F1;">77.93</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DDF3E8;"><span class="ltx_text" style="--ltx-bg-color:#DDF3E8;">57.40</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F5FCF8;"><span class="ltx_text" style="--ltx-bg-color:#F5FCF8;">56.09</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">65.80</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">   GPT4.1 Prompt Translate</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#82D3A8;"><span class="ltx_text" style="--ltx-bg-color:#82D3A8;">85.93</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">78.12</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#D6F1E3;"><span class="ltx_text" style="--ltx-bg-color:#D6F1E3;">69.30</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F4FBF7;"><span class="ltx_text" style="--ltx-bg-color:#F4FBF7;">61.97</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A7E0C2;"><span class="ltx_text" style="--ltx-bg-color:#A7E0C2;">82.24</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C8ECD9;"><span class="ltx_text" style="--ltx-bg-color:#C8ECD9;">63.87</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">65.45</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">72.97</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_bold">UNet Fine-tuning</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_border_r"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">   Diffusion Finetune</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">70.49</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F6FCF8;"><span class="ltx_text" style="--ltx-bg-color:#F6FCF8;">52.37</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#ECF8F2;"><span class="ltx_text" style="--ltx-bg-color:#ECF8F2;">65.22</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E0F4EA;"><span class="ltx_text" style="--ltx-bg-color:#E0F4EA;">65.31</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">76.69</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">60.12</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EEF9F3;"><span class="ltx_text" style="--ltx-bg-color:#EEF9F3;">58.05</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FEFFFE;"><span class="ltx_text" style="--ltx-bg-color:#FEFFFE;">65.91</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">   Diffusion DPO</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F3FBF6;"><span class="ltx_text" style="--ltx-bg-color:#F3FBF6;">72.03</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FFFFFF;"><span class="ltx_text" style="--ltx-bg-color:#FFFFFF;">50.29</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#E3F5EC;"><span class="ltx_text" style="--ltx-bg-color:#E3F5EC;">66.89</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DDF3E7;"><span class="ltx_text" style="--ltx-bg-color:#DDF3E7;">65.97</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E8F7EF;"><span class="ltx_text" style="--ltx-bg-color:#E8F7EF;">78.12</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#CBEDDB;"><span class="ltx_text" style="--ltx-bg-color:#CBEDDB;">62.88</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E7F7EE;"><span class="ltx_text" style="--ltx-bg-color:#E7F7EE;">60.10</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F6FCF8;"><span class="ltx_text" style="--ltx-bg-color:#F6FCF8;">67.40</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_bold">Ours</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_border_r"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">    Dialect Learning + Text KL Reg.+ Polysemy Reg.</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#86D5AB;"><span class="ltx_text" style="--ltx-bg-color:#86D5AB;">85.45</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">78.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">85.99</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">82.43</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">84.71</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">85.97</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">89.70</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">87.14</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="A6.T7">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span><span class="ltx_text ltx_font_bold">Quantitative Effects of Grammatical and Lexical Variations on Multimodal Generation</span>, measured in VQAScore. We evaluate three text-to-image generative models under the following dialectal variation types: Grammatical, Lexical, and Grammatical + Lexical. Values in parentheses indicate the percentage performance drop in VQAScore compared to baseline SAE performance.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:397.5pt;height:46.1pt;vertical-align:-21.2pt;"><span class="ltx_transformed_inner" style="transform:translate(-66.5pt,7.7pt) scale(0.749165457796867,0.749165457796867) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" rowspan="2"><span class="ltx_text ltx_font_bold">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span class="ltx_text ltx_font_bold">SAE Performance (%)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3"><span class="ltx_text ltx_font_bold">Performance under Dialectal Variations (%)</span></th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Grammatical</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Lexical</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Grammatical + Lexical</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">DALL-E Mini</th>
<td class="ltx_td ltx_align_center ltx_border_t">75.63</td>
<td class="ltx_td ltx_align_center ltx_border_t">74.72 (-1.20)</td>
<td class="ltx_td ltx_align_center ltx_border_t">51.92 (-31.35)</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">51.26 (-32.22)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">FLUX.1 dev</th>
<td class="ltx_td ltx_align_center">82.94</td>
<td class="ltx_td ltx_align_center">82.40 (-0.65)</td>
<td class="ltx_td ltx_align_center">61.88 (-25.39)</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">61.02 (-26.43)</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Stable Diffusion 3.5 Large</th>
<td class="ltx_td ltx_align_center ltx_border_bb">85.18</td>
<td class="ltx_td ltx_align_center ltx_border_bb">83.91 (-1.49)</td>
<td class="ltx_td ltx_align_center ltx_border_bb">65.37 (-23.26)</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">63.80 (-25.10)</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_appendix" id="A7">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Grammatical vs. Lexical Robustness in Multimodal Models</h2>
<div class="ltx_para" id="A7.p1">
<p class="ltx_p">To establish the rationale for our study’s focus on lexical variations, we begin with an observation about multimodal generative models. These models often exhibit a notable insensitivity to grammatical or syntactic structure, a tendency that likely arises from the bag-of-words nature of their CLIP-style encoders.
This architectural trait means that variations in sentence construction, such as word order or verb tenses, tend to have a minimal effect on the final output. <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A7.T8" title="In Appendix G Grammatical vs. Lexical Robustness in Multimodal Models ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">8</span></a>, adapted from Multi-VALUE <cite class="ltx_cite ltx_citemacro_citep">(Ziems et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib55" title="">2023</a>)</cite>, showcases several examples of these grammatical variations.</p>
</div>
<figure class="ltx_table" id="A7.T8">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span><span class="ltx_text ltx_font_bold">Examples of Grammatical Dialect Variations</span> between Standard American English (SAE) sentences and African American English (AAE) dialect sentences. The <span class="ltx_text ltx_font_bold" style="--ltx-fg-color:#00B0F0;">blue</span> texts highlight unique features in SAE while the <span class="ltx_text ltx_font_bold" style="--ltx-fg-color:#A02B93;">purple</span> texts (if applicable) highlight corresponding features in AAE.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span class="ltx_text ltx_font_bold">Grammatical Variation Type</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">SAE Prompt</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">AAE Dialect Prompt</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Clause Structure</th>
<td class="ltx_td ltx_align_left ltx_border_t">A chair <span class="ltx_text ltx_font_bold" style="--ltx-fg-color:#00B0F0;">that</span> can be folded</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">A chair can be folded</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Negative Concord</th>
<td class="ltx_td ltx_align_left">There <span class="ltx_text ltx_font_bold" style="--ltx-fg-color:#00B0F0;">is</span> no food on the table</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">There <span class="ltx_text ltx_font_bold" style="--ltx-fg-color:#A02B93;">ain’t</span> no food on the table</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Word Order</th>
<td class="ltx_td ltx_align_left">A <span class="ltx_text ltx_font_bold" style="--ltx-fg-color:#00B0F0;">big and fresh</span> fish</td>
<td class="ltx_td ltx_nopad_r ltx_align_left">A fish <span class="ltx_text ltx_font_bold" style="--ltx-fg-color:#A02B93;">big and fresh</span>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Verb Morphology</th>
<td class="ltx_td ltx_align_left ltx_border_bb">Mom <span class="ltx_text ltx_font_bold" style="--ltx-fg-color:#00B0F0;">brought</span> rice to me</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">Mom <span class="ltx_text ltx_font_bold" style="--ltx-fg-color:#A02B93;">brin</span> rice give me</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="A7.p2">
<p class="ltx_p">To formally quantify this observation, we conducted a small-scale experiment with three representative models in the African American English evaluation setting. We used the Multi-VALUE <cite class="ltx_cite ltx_citemacro_citep">(Ziems et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib55" title="">2023</a>)</cite> translation system to apply grammatical variations to 300 SAE prompts from <span class="ltx_text ltx_font_bold">DialectGen</span> and evaluated their generation quality using VQAScore.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.p3">
<p class="ltx_p">The results, presented in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A6.T7" title="In Appendix F Mitigation Results on Stable Diffusion XL ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">7</span></a>, provide strong quantitative evidence supporting our initial analysis. While <span class="ltx_text ltx_font_bold">lexical feature variations cause significant performance drops</span> for existing text-to-image generative models, <span class="ltx_text ltx_font_bold">grammatical variations do not incur significant performance drops.</span> This clear distinction validates our decision to focus on the more impactful lexical variations throughout this work.</p>
</div>
<figure class="ltx_table" id="A7.T9">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9: </span><span class="ltx_text ltx_font_bold">Stable Diffusion 1.5 Mitigation Performance Breakdown</span> by dialect for different mitigation methods on the <span class="ltx_text ltx_font_bold">DialectGen</span> dataset for all baseline methods and ablations of our method. All performance scores are measured using VQAScore <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib32" title="">2024</a>)</cite>, higher score is better. </figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:397.5pt;height:144.3pt;vertical-align:-70.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-118.0pt,42.8pt) scale(0.627462281556471,0.627462281556471) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="3"><span class="ltx_text ltx_font_bold">Mitigation Methods</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="10">
<span class="ltx_text ltx_font_bold">Performance by Dialect (VQAScore)</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="A7.T9.m1" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">AAE</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">BrE</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">ChE</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">InE</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2">SgE</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">SAE</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">SAE</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">SAE</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">SAE</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">SAE</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Base Model (Stable Diffusion 1.5)</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#E3F5EC;"><span class="ltx_text" style="--ltx-bg-color:#E3F5EC;">57.34</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">72.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">69.51</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">76.40</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#E6F6ED;"><span class="ltx_text" style="--ltx-bg-color:#E6F6ED;">56.36</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">78.66</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#E3F5EC;"><span class="ltx_text" style="--ltx-bg-color:#E3F5EC;">57.54</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">81.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#C9ECDA;"><span class="ltx_text" style="--ltx-bg-color:#C9ECDA;">63.81</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">80.50</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Prompt Revision</span></th>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_r ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_r ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_r ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_r ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">   DALL-E 3 Prompt Rewrite</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E0F4EA;"><span class="ltx_text" style="--ltx-bg-color:#E0F4EA;">57.73</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">73.16</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">70.40</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">77.86</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F0FAF4;"><span class="ltx_text" style="--ltx-bg-color:#F0FAF4;">53.98</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">79.99</span></td>
<td class="ltx_td ltx_align_center">50.42</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">81.33</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D9F2E5;"><span class="ltx_text" style="--ltx-bg-color:#D9F2E5;">59.87</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">81.66</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">   LLaMA 3 Prompt Translate</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">60.87</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">70.36</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">74.39</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">76.49</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DBF3E6;"><span class="ltx_text" style="--ltx-bg-color:#DBF3E6;">59.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">78.15</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D6F1E3;"><span class="ltx_text" style="--ltx-bg-color:#D6F1E3;">60.22</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">81.09</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C4EBD6;"><span class="ltx_text" style="--ltx-bg-color:#C4EBD6;">64.98</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">79.84</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">   GPT4.1 Prompt Translate</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">65.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#ABE2C5;"><span class="ltx_text" style="--ltx-bg-color:#ABE2C5;">71.28</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">73.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">76.40</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DEF3E8;"><span class="ltx_text" style="--ltx-bg-color:#DEF3E8;">58.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">78.29</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F5FBF8;"><span class="ltx_text" style="--ltx-bg-color:#F5FBF8;">53.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">81.03</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">65.12</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">79.83</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span class="ltx_text ltx_font_bold">UNet Fine-tuning</span></th>
<td class="ltx_td"></td>
<td class="ltx_td ltx_border_r"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_border_r"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_border_r"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_border_r"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">   Diffusion Finetune</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C9ECDA;"><span class="ltx_text" style="--ltx-bg-color:#C9ECDA;">63.85</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#C7EBD8;"><span class="ltx_text" style="--ltx-bg-color:#C7EBD8;">64.34</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">70.14</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">68.35</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E3F5EC;"><span class="ltx_text" style="--ltx-bg-color:#E3F5EC;">57.30</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">69.55</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F5FBF8;"><span class="ltx_text" style="--ltx-bg-color:#F5FBF8;">52.84</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">70.72</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D6F1E3;"><span class="ltx_text" style="--ltx-bg-color:#D6F1E3;">60.56</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">72.42</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">   Diffusion DPO</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">66.31</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#CCEDDC;"><span class="ltx_text" style="--ltx-bg-color:#CCEDDC;">63.02</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B3E4CA;"><span class="ltx_text" style="--ltx-bg-color:#B3E4CA;">68.91</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#B3E4CA;"><span class="ltx_text" style="--ltx-bg-color:#B3E4CA;">69.17</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">61.22</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">67.83</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E6F6ED;"><span class="ltx_text" style="--ltx-bg-color:#E6F6ED;">56.38</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#ABE2C5;"><span class="ltx_text" style="--ltx-bg-color:#ABE2C5;">70.94</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C4EBD6;"><span class="ltx_text" style="--ltx-bg-color:#C4EBD6;">64.79</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">71.85</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span class="ltx_text ltx_font_bold">Ours</span></th>
<td class="ltx_td"></td>
<td class="ltx_td ltx_border_r"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_border_r"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_border_r"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_border_r"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">   Dialect Learning</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">75.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">74.31</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">78.33</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">78.34</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">79.31</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">80.20</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">78.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">79.90</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">79.15</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">78.33</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">    + Text Cosine Reg.</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">75.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">74.86</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">77.84</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">77.52</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">79.31</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">79.74</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">78.22</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">80.13</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">78.86</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">79.21</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">    + Image Cosine Reg.</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">74.91</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">74.83</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">78.20</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">78.22</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">79.45</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">80.32</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">78.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">80.00</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">79.11</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">78.72</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">    + Text KL Reg.</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">74.40</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">73.97</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">78.27</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">79.40</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">78.36</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">80.72</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">78.17</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">78.24</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">79.71</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">78.66</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">    + Image KL Reg.</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">73.77</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">74.36</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">77.23</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">77.60</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">79.06</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">80.43</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">79.25</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">80.99</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">81.29</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">79.54</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">    + Text KL Reg.+ Polysemy Ctrl.</th>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">72.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">72.25</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">75.76</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">79.57</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">78.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">79.27</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">80.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">79.89</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">81.07</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">79.84</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">    + Image KL Reg.+ Polysemy Ctrl.</th>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">72.61</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">74.30</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">76.74</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">76.77</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">77.51</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">78.83</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">80.41</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">80.85</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">81.14</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">78.15</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="A7.T10">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 10: </span><span class="ltx_text ltx_font_bold">Complete DialectGen Benchmark Performance Breakdown</span> by dialect for all text-to-image and text-to-video generative models. All performance scores are measured using VQAScore <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib32" title="">2024</a>)</cite>, higher score is better. Results complements <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4.T2" title="In 4 Experiments ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">2</span></a> in the main paper.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:397.5pt;height:296.7pt;vertical-align:-146.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-116.9pt,87.3pt) scale(0.62961033326047,0.62961033326047) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_border_tt" colspan="2"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="3"><span class="ltx_text ltx_font_bold">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="10"><span class="ltx_text ltx_font_bold">Performance by Dialect (VQAScore) <math alttext="\uparrow" class="ltx_Math" display="inline" id="A7.T10.m1" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td" colspan="2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">AAE</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">BrE</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">ChE</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">InE</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2">SgE</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td" colspan="2"></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">SAE</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">SAE</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">SAE</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">SAE</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">SAE</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="16">
<div class="ltx_inline-block ltx_transformed_outer" style="width:8.9pt;height:85.8pt;vertical-align:-40.4pt;"><span class="ltx_transformed_inner" style="width:85.7pt;transform:translate(-38.4pt,-38.4pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Concise Prompts</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="10">
<div class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:49.6pt;vertical-align:-21.3pt;"><span class="ltx_transformed_inner" style="width:49.6pt;transform:translate(-21.3pt,-21.3pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">T2I Models</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Stable Diffusion 1.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">60.66</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">76.47</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">71.46</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#CFEEDE;"><span class="ltx_text" style="--ltx-bg-color:#CFEEDE;">51.31</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">78.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#D6F1E3;"><span class="ltx_text" style="--ltx-bg-color:#D6F1E3;">47.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">80.88</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">57.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">78.92</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 1.5</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">62.31</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">77.41</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">72.59</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.47</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D1EFDF;"><span class="ltx_text" style="--ltx-bg-color:#D1EFDF;">50.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.37</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D6F1E3;"><span class="ltx_text" style="--ltx-bg-color:#D6F1E3;">47.03</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">81.29</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C4EBD6;"><span class="ltx_text" style="--ltx-bg-color:#C4EBD6;">56.36</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">78.8</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 2.1</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">60.97</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">80.59</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">76.37</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">84.21</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D9F2E5;"><span class="ltx_text" style="--ltx-bg-color:#D9F2E5;">45.88</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.15</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#CFEEDE;"><span class="ltx_text" style="--ltx-bg-color:#CFEEDE;">50.63</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">85.99</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">58.53</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">82.31</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion XL</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">62.97</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">82.17</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">80.49</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">87.44</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D1EFDF;"><span class="ltx_text" style="--ltx-bg-color:#D1EFDF;">49.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">84.75</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C9ECDA;"><span class="ltx_text" style="--ltx-bg-color:#C9ECDA;">53.66</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">87.6</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B3E4CA;"><span class="ltx_text" style="--ltx-bg-color:#B3E4CA;">65.56</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">84.23</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 3</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">60.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">84.46</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.22</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.71</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">48.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">84.29</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#CFEEDE;"><span class="ltx_text" style="--ltx-bg-color:#CFEEDE;">51.91</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">87.52</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">61.64</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">82.32</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 3.5 Large</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">60.16</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.91</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">80.53</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">89.22</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">48.93</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">85.33</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#CFEEDE;"><span class="ltx_text" style="--ltx-bg-color:#CFEEDE;">51.53</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">88.69</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">63.21</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.79</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 3.5 Large Turbo</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C4EBD6;"><span class="ltx_text" style="--ltx-bg-color:#C4EBD6;">57.27</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">82.2</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">87.51</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D6F1E3;"><span class="ltx_text" style="--ltx-bg-color:#D6F1E3;">47.16</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.62</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D1EFDF;"><span class="ltx_text" style="--ltx-bg-color:#D1EFDF;">50.07</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">87.06</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">61.72</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.09</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Flux.1 [dev]</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C7EBD8;"><span class="ltx_text" style="--ltx-bg-color:#C7EBD8;">55.63</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">80.17</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">72.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">81.53</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D9F2E5;"><span class="ltx_text" style="--ltx-bg-color:#D9F2E5;">45.85</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">82.82</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D6F1E3;"><span class="ltx_text" style="--ltx-bg-color:#D6F1E3;">46.73</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">81.39</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#CFEEDE;"><span class="ltx_text" style="--ltx-bg-color:#CFEEDE;">51.63</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">76.62</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E Mini</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#CFEEDE;"><span class="ltx_text" style="--ltx-bg-color:#CFEEDE;">50.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">76.96</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">73.55</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">80.1</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E0F4EA;"><span class="ltx_text" style="--ltx-bg-color:#E0F4EA;">41.51</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">78.48</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DBF3E6;"><span class="ltx_text" style="--ltx-bg-color:#DBF3E6;">44.07</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">77.11</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C9ECDA;"><span class="ltx_text" style="--ltx-bg-color:#C9ECDA;">54.11</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">72.64</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E 2</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#CCEDDC;"><span class="ltx_text" style="--ltx-bg-color:#CCEDDC;">52.07</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">81.19</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.03</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DEF3E8;"><span class="ltx_text" style="--ltx-bg-color:#DEF3E8;">42.54</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">83.05</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DEF3E8;"><span class="ltx_text" style="--ltx-bg-color:#DEF3E8;">43.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">81.66</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">61.65</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">81.27</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E 3</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">67.09</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">82.8</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">85.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">88.86</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D1EFDF;"><span class="ltx_text" style="--ltx-bg-color:#D1EFDF;">50.43</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.87</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">58.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.34</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">64.3</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.38</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E 3 w/ Rewrite</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">63.74</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">81.83</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">84.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">90.08</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">61.41</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.96</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">68.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">89.28</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">74.77</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">85.69</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">gpt-image-1</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">65.47</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">88.62</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">88.39</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">93.24</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">65.31</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">88.37</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">67.77</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">92.22</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">77.67</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">88.25</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="5">
<div class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:53.2pt;vertical-align:-23.1pt;"><span class="ltx_transformed_inner" style="width:53.2pt;transform:translate(-23.1pt,-23.1pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">T2V Models</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Cosmos-1</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">59.61</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">76.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">68.87</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">76.26</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#CCEDDC;"><span class="ltx_text" style="--ltx-bg-color:#CCEDDC;">53.27</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">72.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#C4EBD6;"><span class="ltx_text" style="--ltx-bg-color:#C4EBD6;">56.84</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">78.34</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#C9ECDA;"><span class="ltx_text" style="--ltx-bg-color:#C9ECDA;">54.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">65.18</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Open-Sora</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">65.46</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">84.56</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">75.56</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.21</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">48.49</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">85.21</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">59.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">87.59</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">59.19</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">80.56</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">VideoCrafter-2</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">61.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">82.13</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">76.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">84.12</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DEF3E8;"><span class="ltx_text" style="--ltx-bg-color:#DEF3E8;">42.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.43</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C9ECDA;"><span class="ltx_text" style="--ltx-bg-color:#C9ECDA;">53.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">88.76</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">61.73</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.51</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">CogVideoX</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EBF8F1;"><span class="ltx_text" style="--ltx-bg-color:#EBF8F1;">36.72</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">59.54</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DEF3E8;"><span class="ltx_text" style="--ltx-bg-color:#DEF3E8;">42.55</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#C7EBD8;"><span class="ltx_text" style="--ltx-bg-color:#C7EBD8;">55.8</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FAFDFB;"><span class="ltx_text" style="--ltx-bg-color:#FAFDFB;">27.71</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">61.82</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#FAFDFB;"><span class="ltx_text" style="--ltx-bg-color:#FAFDFB;">28.76</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">63.23</span></td>
<td class="ltx_td ltx_align_center">25.98</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DBF3E6;"><span class="ltx_text" style="--ltx-bg-color:#DBF3E6;">44</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">Wan 2.1</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F7FCFA;"><span class="ltx_text" style="--ltx-bg-color:#F7FCFA;">29.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">62.49</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D6F1E3;"><span class="ltx_text" style="--ltx-bg-color:#D6F1E3;">47.02</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">68.41</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F5FBF8;"><span class="ltx_text" style="--ltx-bg-color:#F5FBF8;">30.37</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#C9ECDA;"><span class="ltx_text" style="--ltx-bg-color:#C9ECDA;">54.07</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F5FBF8;"><span class="ltx_text" style="--ltx-bg-color:#F5FBF8;">30.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#B3E4CA;"><span class="ltx_text" style="--ltx-bg-color:#B3E4CA;">65.81</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F7FCFA;"><span class="ltx_text" style="--ltx-bg-color:#F7FCFA;">30.23</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">67.89</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="16">
<div class="ltx_inline-block ltx_transformed_outer" style="width:8.9pt;height:89.4pt;vertical-align:-42.2pt;"><span class="ltx_transformed_inner" style="width:89.4pt;transform:translate(-40.2pt,-40.2pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Detailed Prompts</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="10">
<div class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:49.6pt;vertical-align:-21.3pt;"><span class="ltx_transformed_inner" style="width:49.6pt;transform:translate(-21.3pt,-21.3pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">T2I Models</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Stable Diffusion 1.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#ABE2C5;"><span class="ltx_text" style="--ltx-bg-color:#ABE2C5;">70.07</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.31</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">74.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">77.58</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">65.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">78.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#C4EBD6;"><span class="ltx_text" style="--ltx-bg-color:#C4EBD6;">56.99</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">80.53</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">63.87</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">76.98</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 1.5</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">71.03</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.97</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">73.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">77.69</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">65.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">78.89</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C4EBD6;"><span class="ltx_text" style="--ltx-bg-color:#C4EBD6;">56.84</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.72</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">63.02</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">77.06</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion XL</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">72.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">84.76</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">80.84</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">85.6</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">68.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">85.85</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">61.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">87.44</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">70.93</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.55</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 2.1</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">69.41</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">81.72</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">77.51</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">82.03</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">63.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">82.68</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">59.39</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">84.07</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">64.71</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.95</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 3</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">74.27</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">87.11</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">82.58</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">88.48</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B3E4CA;"><span class="ltx_text" style="--ltx-bg-color:#B3E4CA;">66.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.95</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">62.59</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">88.08</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">67.32</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.13</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 3.5 Large</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">73.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.84</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">89.5</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">67.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">87.6</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">60.55</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">88.82</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">67.65</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">84.27</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 3.5 Large Turbo</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">73.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.23</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">81.07</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">88.24</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">64.83</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.37</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">58.46</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">87.81</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">65.05</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">82.98</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Flux.1 [dev]</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">72.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">85.56</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">77.43</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">85.19</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">61.47</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">82.72</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">58.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">85.31</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">59.56</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.66</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E Mini</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C9ECDA;"><span class="ltx_text" style="--ltx-bg-color:#C9ECDA;">53.69</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">74.12</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">69.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">73.38</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#CCEDDC;"><span class="ltx_text" style="--ltx-bg-color:#CCEDDC;">52.39</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">72.11</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D1EFDF;"><span class="ltx_text" style="--ltx-bg-color:#D1EFDF;">50.47</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">73.65</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">58.22</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">68.92</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E 2</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">64.72</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.34</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">80.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">85.79</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">62.33</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.66</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C7EBD8;"><span class="ltx_text" style="--ltx-bg-color:#C7EBD8;">55.51</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">82.6</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B3E4CA;"><span class="ltx_text" style="--ltx-bg-color:#B3E4CA;">66.07</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">80.34</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E 3</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">77.75</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">85.3</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">87.99</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">68.16</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.26</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">71.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">87.79</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">73.51</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">84.35</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E 3 w/ Rewrite</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">76.73</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">87.12</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">85.56</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">90.33</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">76.36</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">85.43</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">75.63</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">91.22</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">78.8</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.54</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">gpt-image-1</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">78.26</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">90.7</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.88</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">90.94</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.47</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">88.85</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">78.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">92.86</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.39</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">88.38</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="5">
<div class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:53.2pt;vertical-align:-23.1pt;"><span class="ltx_transformed_inner" style="width:53.2pt;transform:translate(-23.1pt,-23.1pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">T2V Models</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Cosmos-1</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">64.61</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">72.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">67.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">73.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">57.62</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">67.03</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#C4EBD6;"><span class="ltx_text" style="--ltx-bg-color:#C4EBD6;">56.58</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">73</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#D1EFDF;"><span class="ltx_text" style="--ltx-bg-color:#D1EFDF;">50.39</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">58.99</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Open-Sora</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">74.81</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.48</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">76.69</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">80.84</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">67.65</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.93</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ABE2C5;"><span class="ltx_text" style="--ltx-bg-color:#ABE2C5;">69.59</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.77</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">71.15</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">81.49</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">VideoCrafter-2</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ABE2C5;"><span class="ltx_text" style="--ltx-bg-color:#ABE2C5;">70.88</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">85.37</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.53</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">83</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B3E4CA;"><span class="ltx_text" style="--ltx-bg-color:#B3E4CA;">66.14</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">87.21</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">62.58</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">86.47</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">68.14</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">83.72</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">CogVideoX</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E3F5EC;"><span class="ltx_text" style="--ltx-bg-color:#E3F5EC;">39.83</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#CFEEDE;"><span class="ltx_text" style="--ltx-bg-color:#CFEEDE;">50.63</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D9F2E5;"><span class="ltx_text" style="--ltx-bg-color:#D9F2E5;">46.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#C9ECDA;"><span class="ltx_text" style="--ltx-bg-color:#C9ECDA;">54.35</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E6F6ED;"><span class="ltx_text" style="--ltx-bg-color:#E6F6ED;">38.89</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">57.82</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EBF8F1;"><span class="ltx_text" style="--ltx-bg-color:#EBF8F1;">35.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">62.68</span></td>
<td class="ltx_td ltx_align_center">25.51</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#E3F5EC;"><span class="ltx_text" style="--ltx-bg-color:#E3F5EC;">40.11</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_bb"></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">Wan 2.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#C7EBD8;"><span class="ltx_text" style="--ltx-bg-color:#C7EBD8;">55.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">79.96</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">62.14</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">73.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#E0F4EA;"><span class="ltx_text" style="--ltx-bg-color:#E0F4EA;">42.39</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">73.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">48.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">76.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">48.73</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">75.8</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="A7.T11">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 11: </span><span class="ltx_text ltx_font_bold">Complete DialectGen Benchmark Performance Breakdown</span> by dialect for all text-to-image and text-to-video generative models. All performance scores are measured using CLIPScore <cite class="ltx_cite ltx_citemacro_citep">(Hessel et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib24" title="">2021</a>)</cite>, higher score is better. Results complements <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4.T2" title="In 4 Experiments ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">2</span></a> in the main paper.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:397.5pt;height:296.7pt;vertical-align:-146.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-116.9pt,87.3pt) scale(0.62961033326047,0.62961033326047) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_border_tt" colspan="2"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="3"><span class="ltx_text ltx_font_bold">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="10"><span class="ltx_text ltx_font_bold">Performance by Dialect (CLIPScore) <math alttext="\uparrow" class="ltx_Math" display="inline" id="A7.T11.m1" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td" colspan="2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">AAE</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">BrE</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">ChE</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">InE</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2">SgE</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td" colspan="2"></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">SAE</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">SAE</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">SAE</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold">SAE</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Dialect</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">SAE</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="16">
<div class="ltx_inline-block ltx_transformed_outer" style="width:8.9pt;height:85.8pt;vertical-align:-40.4pt;"><span class="ltx_transformed_inner" style="width:85.7pt;transform:translate(-38.4pt,-38.4pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Concise Prompts</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="10">
<div class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:49.6pt;vertical-align:-21.3pt;"><span class="ltx_transformed_inner" style="width:49.6pt;transform:translate(-21.3pt,-21.3pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">T2I Models</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Stable Diffusion 1.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">25.46</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.83</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.65</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">24.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.34</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">24.34</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">29.38</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">25.97</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.64</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 1.5</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">25.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.95</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.66</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.91</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">24.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.32</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">24.38</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.44</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">25.86</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.65</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 2.1</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">25.72</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.74</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">30.88</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">24.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.44</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">25.31</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">30.69</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">26.46</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.54</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion XL</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">25.81</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.69</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.97</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.21</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">25.37</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.57</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">25.85</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.15</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">27.45</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.23</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 3</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">25.45</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.42</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.89</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">30.97</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">25.01</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.74</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">25.02</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">30.31</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">26.8</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.67</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 3.5 Large</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">25.62</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.78</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.25</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">31.5</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">25.22</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">29.42</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">25.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.14</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">27.18</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.22</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 3.5 Large Turbo</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">25.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.4</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.16</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">24.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">28.9</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">25.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">30.78</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ABE2C5;"><span class="ltx_text" style="--ltx-bg-color:#ABE2C5;">26.96</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.82</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Flux.1 [dev]</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">24.74</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">27.54</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.88</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C4EBD6;"><span class="ltx_text" style="--ltx-bg-color:#C4EBD6;">24.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.97</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">24.78</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.48</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">25.4</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.31</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E Mini</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">24.77</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">28.15</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.48</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">30.65</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C9ECDA;"><span class="ltx_text" style="--ltx-bg-color:#C9ECDA;">23.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.81</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">24.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.56</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">25.74</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.6</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E 2</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">24.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">27.4</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">30.56</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C7EBD8;"><span class="ltx_text" style="--ltx-bg-color:#C7EBD8;">23.98</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">27.3</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C4EBD6;"><span class="ltx_text" style="--ltx-bg-color:#C4EBD6;">24.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">29.3</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">26.44</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.53</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E 3</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">25.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">27.51</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">28.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.75</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">24.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">28.11</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">25.71</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.66</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B3E4CA;"><span class="ltx_text" style="--ltx-bg-color:#B3E4CA;">26.3</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">29.08</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E 3 w/ Rewrite</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">24.92</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#ABE2C5;"><span class="ltx_text" style="--ltx-bg-color:#ABE2C5;">26.91</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">29.41</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.11</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">25.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">27.57</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">26.87</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.93</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ABE2C5;"><span class="ltx_text" style="--ltx-bg-color:#ABE2C5;">27.12</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.47</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">gpt-image-1</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">25.96</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.33</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">30.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">31.62</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">26.51</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.48</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">27.51</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.21</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.57</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">30.33</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="5">
<div class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:53.2pt;vertical-align:-23.1pt;"><span class="ltx_transformed_inner" style="width:53.2pt;transform:translate(-23.1pt,-23.1pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">T2V Models</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Cosmos-1</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#C9ECDA;"><span class="ltx_text" style="--ltx-bg-color:#C9ECDA;">23.49</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">25.42</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#B3E4CA;"><span class="ltx_text" style="--ltx-bg-color:#B3E4CA;">26.17</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#ABE2C5;"><span class="ltx_text" style="--ltx-bg-color:#ABE2C5;">27.16</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#D1EFDF;"><span class="ltx_text" style="--ltx-bg-color:#D1EFDF;">22.89</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#BFE9D3;"><span class="ltx_text" style="--ltx-bg-color:#BFE9D3;">24.62</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#C4EBD6;"><span class="ltx_text" style="--ltx-bg-color:#C4EBD6;">24.18</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#ABE2C5;"><span class="ltx_text" style="--ltx-bg-color:#ABE2C5;">27.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#D9F2E5;"><span class="ltx_text" style="--ltx-bg-color:#D9F2E5;">21.89</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#D1EFDF;"><span class="ltx_text" style="--ltx-bg-color:#D1EFDF;">22.91</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Open-Sora</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">25.02</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">27.3</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.63</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.73</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">24.34</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#ABE2C5;"><span class="ltx_text" style="--ltx-bg-color:#ABE2C5;">27.09</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">25.35</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">29.36</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">25.55</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">28.01</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">VideoCrafter-2</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">25.88</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.83</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">29.41</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">30.69</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">25.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">29.04</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">25.88</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">30.56</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ABE2C5;"><span class="ltx_text" style="--ltx-bg-color:#ABE2C5;">27</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.69</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">CogVideoX</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">22.62</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">25.71</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C4EBD6;"><span class="ltx_text" style="--ltx-bg-color:#C4EBD6;">24.14</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">25.84</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D9F2E5;"><span class="ltx_text" style="--ltx-bg-color:#D9F2E5;">22.03</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">24.61</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#CFEEDE;"><span class="ltx_text" style="--ltx-bg-color:#CFEEDE;">22.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">27.4</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EBF8F1;"><span class="ltx_text" style="--ltx-bg-color:#EBF8F1;">19.99</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D6F1E3;"><span class="ltx_text" style="--ltx-bg-color:#D6F1E3;">22.18</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">Wan 2.1</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">22.37</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">25.49</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">25.45</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">28.27</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D6F1E3;"><span class="ltx_text" style="--ltx-bg-color:#D6F1E3;">22.14</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">24.55</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">22.55</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">27.57</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D1EFDF;"><span class="ltx_text" style="--ltx-bg-color:#D1EFDF;">22.75</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">26.85</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="16">
<div class="ltx_inline-block ltx_transformed_outer" style="width:8.9pt;height:89.4pt;vertical-align:-42.2pt;"><span class="ltx_transformed_inner" style="width:89.4pt;transform:translate(-40.2pt,-40.2pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Detailed Prompts</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="10">
<div class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:49.6pt;vertical-align:-21.3pt;"><span class="ltx_transformed_inner" style="width:49.6pt;transform:translate(-21.3pt,-21.3pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">T2I Models</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Stable Diffusion 1.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.98</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.84</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.59</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.23</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.61</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">26.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.83</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">28.12</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.78</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 1.5</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">28.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">28.99</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.54</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">30.29</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.18</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">26.87</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.94</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.98</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.82</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 2.1</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.9</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">30.83</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">31.69</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">31.51</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">28.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">31.47</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.54</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.32</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion XL</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.46</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.68</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">30.49</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.33</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">29.12</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.14</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">30.96</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.65</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">30.52</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 3</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.69</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.82</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">30.76</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">31.59</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">29.13</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.15</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">31</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">29.13</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">31.04</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 3.5 Large</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.01</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">31.02</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#80D3A7;"><span class="ltx_text" style="--ltx-bg-color:#80D3A7;">31.84</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.48</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">31.64</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">28.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">31.61</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">29.29</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.19</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Stable Diffusion 3.5 Large Turbo</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.61</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.58</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">30.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">31.6</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">29.09</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.23</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.18</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.76</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">30.78</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Flux.1 [dev]</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.97</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.69</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.54</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">30.37</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">28.17</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.17</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ABE2C5;"><span class="ltx_text" style="--ltx-bg-color:#ABE2C5;">27.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.01</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">27.72</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.46</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E Mini</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">27.26</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">29.18</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.84</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">30.56</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.75</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.23</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">26.71</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.93</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">27.42</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.59</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E 2</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">27.66</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">29.02</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">30.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.3</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">30.54</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#B0E4C8;"><span class="ltx_text" style="--ltx-bg-color:#B0E4C8;">26.48</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.17</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.69</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.88</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E 3</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.3</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.55</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.21</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.04</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">27.48</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.83</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.67</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.03</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">DALL-E 3 w/ Rewrite</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">27.71</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">28.23</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.75</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8CD7B0;"><span class="ltx_text" style="--ltx-bg-color:#8CD7B0;">30.46</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">28.88</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.85</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.98</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.61</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">29.42</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">gpt-image-1</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.65</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.45</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#82D4A9;"><span class="ltx_text" style="--ltx-bg-color:#82D4A9;">31.6</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.98</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.29</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">29.41</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">30.81</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.18</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#85D4AA;"><span class="ltx_text" style="--ltx-bg-color:#85D4AA;">31.27</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="5">
<div class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:53.2pt;vertical-align:-23.1pt;"><span class="ltx_transformed_inner" style="width:53.2pt;transform:translate(-23.1pt,-23.1pt) rotate(-90deg) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">T2V Models</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Cosmos-1</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#CFEEDE;"><span class="ltx_text" style="--ltx-bg-color:#CFEEDE;">23.07</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#C7EBD8;"><span class="ltx_text" style="--ltx-bg-color:#C7EBD8;">23.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">25.98</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#ADE3C7;"><span class="ltx_text" style="--ltx-bg-color:#ADE3C7;">26.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#C4EBD6;"><span class="ltx_text" style="--ltx-bg-color:#C4EBD6;">24.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#BDE8D1;"><span class="ltx_text" style="--ltx-bg-color:#BDE8D1;">24.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#CCEDDC;"><span class="ltx_text" style="--ltx-bg-color:#CCEDDC;">23.35</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">25.29</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#EBF8F1;"><span class="ltx_text" style="--ltx-bg-color:#EBF8F1;">19.99</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#E0F4EA;"><span class="ltx_text" style="--ltx-bg-color:#E0F4EA;">21.09</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">Open-Sora</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A8E1C3;"><span class="ltx_text" style="--ltx-bg-color:#A8E1C3;">27.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.36</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.93</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A1DEBE;"><span class="ltx_text" style="--ltx-bg-color:#A1DEBE;">28.07</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#94DAB5;"><span class="ltx_text" style="--ltx-bg-color:#94DAB5;">29.46</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">27.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.04</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A6E0C1;"><span class="ltx_text" style="--ltx-bg-color:#A6E0C1;">27.64</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">29.19</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r">VideoCrafter-2</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9EDDBC;"><span class="ltx_text" style="--ltx-bg-color:#9EDDBC;">28.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#91D9B3;"><span class="ltx_text" style="--ltx-bg-color:#91D9B3;">29.76</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8FD8B1;"><span class="ltx_text" style="--ltx-bg-color:#8FD8B1;">30.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">30.98</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">28.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">31</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.83</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#87D5AC;"><span class="ltx_text" style="--ltx-bg-color:#87D5AC;">30.88</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.74</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#8AD6AE;"><span class="ltx_text" style="--ltx-bg-color:#8AD6AE;">30.61</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left ltx_border_r">CogVideoX</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#DEF3E8;"><span class="ltx_text" style="--ltx-bg-color:#DEF3E8;">21.42</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">22.55</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">24.38</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">25.74</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D1EFDF;"><span class="ltx_text" style="--ltx-bg-color:#D1EFDF;">22.89</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#C2EAD5;"><span class="ltx_text" style="--ltx-bg-color:#C2EAD5;">24.6</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#D4F0E1;"><span class="ltx_text" style="--ltx-bg-color:#D4F0E1;">22.37</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#B8E6CE;"><span class="ltx_text" style="--ltx-bg-color:#B8E6CE;">25.51</span></td>
<td class="ltx_td ltx_align_center">17.67</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EBF8F1;"><span class="ltx_text" style="--ltx-bg-color:#EBF8F1;">19.82</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_bb"></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">Wan 2.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#B5E5CC;"><span class="ltx_text" style="--ltx-bg-color:#B5E5CC;">25.85</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.89</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.96</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#96DBB7;"><span class="ltx_text" style="--ltx-bg-color:#96DBB7;">29.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#B3E4CA;"><span class="ltx_text" style="--ltx-bg-color:#B3E4CA;">26.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#9CDCBA;"><span class="ltx_text" style="--ltx-bg-color:#9CDCBA;">28.83</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">25.25</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#99DCB8;"><span class="ltx_text" style="--ltx-bg-color:#99DCB8;">28.92</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#BAE7CF;"><span class="ltx_text" style="--ltx-bg-color:#BAE7CF;">25.45</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#A3DFC0;"><span class="ltx_text" style="--ltx-bg-color:#A3DFC0;">27.98</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_appendix" id="A8">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix H </span>Performance by Dialect</h2>
<div class="ltx_para ltx_noindent" id="A8.p1">
<p class="ltx_p">Due to space constraints, we report performance by dialect in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A7.T9" title="In Appendix G Grammatical vs. Lexical Robustness in Multimodal Models ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">9</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A7.T10" title="In Appendix G Grammatical vs. Lexical Robustness in Multimodal Models ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">10</span></a>, and <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A7.T11" title="In Appendix G Grammatical vs. Lexical Robustness in Multimodal Models ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">11</span></a>.
As described in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4.SS1" title="4.1 Evaluation Metrics ‣ 4 Experiments ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Section</span>˜<span class="ltx_text ltx_ref_tag">4.1</span></a>, the scoring functions are based on reference-free image-text alignment metrics, including VQAScore and CLIPScore.
We denote the subset of <span class="ltx_text ltx_font_bold">DialectGen</span> prompts corresponding to a given dialect as <math alttext="\mathcal{P}" class="ltx_Math" display="inline" id="A8.p1.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒫</mi><annotation encoding="application/x-tex">\mathcal{P}</annotation></semantics></math>, which consists of multiple SAE Prompt / Dialect Prompt pairs <math alttext="p=(p^{s},p^{d})" class="ltx_Math" display="inline" id="A8.p1.m2" intent=":literal"><semantics><mrow><mi>p</mi><mo>=</mo><mrow><mo stretchy="false">(</mo><msup><mi>p</mi><mi>s</mi></msup><mo>,</mo><msup><mi>p</mi><mi>d</mi></msup><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">p=(p^{s},p^{d})</annotation></semantics></math>.
For each individual text prompt <math alttext="p^{s}" class="ltx_Math" display="inline" id="A8.p1.m3" intent=":literal"><semantics><msup><mi>p</mi><mi>s</mi></msup><annotation encoding="application/x-tex">p^{s}</annotation></semantics></math> or <math alttext="p^{d}" class="ltx_Math" display="inline" id="A8.p1.m4" intent=":literal"><semantics><msup><mi>p</mi><mi>d</mi></msup><annotation encoding="application/x-tex">p^{d}</annotation></semantics></math>, we generate <math alttext="n" class="ltx_Math" display="inline" id="A8.p1.m5" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> images under different random seeds for text-to-image generative models, or uniformly sample <math alttext="n" class="ltx_Math" display="inline" id="A8.p1.m6" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> frames for text-to-video generative models.
Accordingly, for each SAE Prompt / Dialect Prompt pair <math alttext="p=(p^{s},p^{d})\in\mathcal{P}" class="ltx_Math" display="inline" id="A8.p1.m7" intent=":literal"><semantics><mrow><mi>p</mi><mo>=</mo><mrow><mo stretchy="false">(</mo><msup><mi>p</mi><mi>s</mi></msup><mo>,</mo><msup><mi>p</mi><mi>d</mi></msup><mo stretchy="false">)</mo></mrow><mo>∈</mo><mi class="ltx_font_mathcaligraphic">𝒫</mi></mrow><annotation encoding="application/x-tex">p=(p^{s},p^{d})\in\mathcal{P}</annotation></semantics></math>, we compute its SAE and Dialect performance using <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4.E1" title="In Automatic Evaluation ‣ 4.1 Evaluation Metrics ‣ 4 Experiments ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Equation</span>˜<span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4.E2" title="In Automatic Evaluation ‣ 4.1 Evaluation Metrics ‣ 4 Experiments ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Equation</span>˜<span class="ltx_text ltx_ref_tag">2</span></a>, respectively.
More concretely, <math alttext="SAE(p,\ \mathcal{G})" class="ltx_Math" display="inline" id="A8.p1.m8" intent=":literal"><semantics><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mi>A</mi><mo lspace="0em" rspace="0em">​</mo><mi>E</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>p</mi><mo rspace="0.667em">,</mo><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">SAE(p,\ \mathcal{G})</annotation></semantics></math> in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4.E1" title="In Automatic Evaluation ‣ 4.1 Evaluation Metrics ‣ 4 Experiments ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Equation</span>˜<span class="ltx_text ltx_ref_tag">1</span></a> denotes the average VQAScore (as reported in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A7.T9" title="In Appendix G Grammatical vs. Lexical Robustness in Multimodal Models ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">9</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A7.T10" title="In Appendix G Grammatical vs. Lexical Robustness in Multimodal Models ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">10</span></a>) or CLIPScore (in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#A7.T11" title="In Appendix G Grammatical vs. Lexical Robustness in Multimodal Models ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">11</span></a>) computed over the <math alttext="n" class="ltx_Math" display="inline" id="A8.p1.m9" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> images generated from the SAE prompt <math alttext="p^{s}" class="ltx_Math" display="inline" id="A8.p1.m10" intent=":literal"><semantics><msup><mi>p</mi><mi>s</mi></msup><annotation encoding="application/x-tex">p^{s}</annotation></semantics></math>.
Similarly, <math alttext="Dialect(p,\ \mathcal{G})" class="ltx_Math" display="inline" id="A8.p1.m11" intent=":literal"><semantics><mrow><mi>D</mi><mo lspace="0em" rspace="0em">​</mo><mi>i</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>l</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>c</mi><mo lspace="0em" rspace="0em">​</mo><mi>t</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>p</mi><mo rspace="0.667em">,</mo><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">Dialect(p,\ \mathcal{G})</annotation></semantics></math> in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S4.E2" title="In Automatic Evaluation ‣ 4.1 Evaluation Metrics ‣ 4 Experiments ‣ DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Equation</span>˜<span class="ltx_text ltx_ref_tag">2</span></a> is computed using the same evaluation pipeline, but with the corresponding dialect prompt <math alttext="p^{d}" class="ltx_Math" display="inline" id="A8.p1.m12" intent=":literal"><semantics><msup><mi>p</mi><mi>d</mi></msup><annotation encoding="application/x-tex">p^{d}</annotation></semantics></math> from the same pair.
Each value of <math alttext="SAE(p,\ \mathcal{G})" class="ltx_Math" display="inline" id="A8.p1.m13" intent=":literal"><semantics><mrow><mi>S</mi><mo lspace="0em" rspace="0em">​</mo><mi>A</mi><mo lspace="0em" rspace="0em">​</mo><mi>E</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>p</mi><mo rspace="0.667em">,</mo><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">SAE(p,\ \mathcal{G})</annotation></semantics></math> and <math alttext="Dialect(p,\ \mathcal{G})" class="ltx_Math" display="inline" id="A8.p1.m14" intent=":literal"><semantics><mrow><mi>D</mi><mo lspace="0em" rspace="0em">​</mo><mi>i</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>l</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>c</mi><mo lspace="0em" rspace="0em">​</mo><mi>t</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>p</mi><mo rspace="0.667em">,</mo><mi class="ltx_font_mathcaligraphic">𝒢</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">Dialect(p,\ \mathcal{G})</annotation></semantics></math> is reported as <span class="ltx_text ltx_font_bold">SAE</span> and <span class="ltx_text ltx_font_bold">Dialect</span>, respectively, in the tables.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A9">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix I </span>Use of AI tools</h2>
<div class="ltx_para ltx_noindent" id="A9.p1">
<p class="ltx_p">We employed large language models (LLMs), including OpenAI’s GPT-5 and GPT-4o, as auxiliary tools to refine the manuscript and identify grammatical errors. All LLM-assisted content was critically reviewed, fact-checked, and revised by the authors to ensure scientific validity and originality. The authors retain full responsibility for all statements and conclusions presented in this work. Specifically, LLMs were used only to improve wording and clarity of expression.</p>
</div>
</section>
<section class="ltx_appendix" id="A10">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix J </span>Future Work</h2>
<div class="ltx_para ltx_noindent" id="A10.p1">
<p class="ltx_p">Our work highlights several promising directions for future research, which we encourage the community to explore.</p>
</div>
<section class="ltx_paragraph" id="A10.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Investigating Cultural and Representational Biases</h5>
<div class="ltx_para ltx_noindent" id="A10.SS0.SSS0.Px1.p1">
<p class="ltx_p">It would be interesting for future works to explore and evaluate the significance of representational and skin tone shifts induced by dialect inputs. For instance, as noted in <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#S0.F1" title="In DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">1</span></a>, we observed that FLUX.1 [dev] <cite class="ltx_cite ltx_citemacro_citep">(Black Forest Labs, <a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib6" title="">2024</a>)</cite> image generations for the prompt “A man selling eggplant” depict more upscale and decorated environments compared to generations for “A man selling brinjal.” Furthermore, individuals depicted in the images for “brinjal” are darker-skinned. A systematic study of these shifts would provide valuable insights into the inherent biases of large-scale multimodal models.</p>
</div>
</section>
<section class="ltx_paragraph" id="A10.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Exploring Grammatical and Joint Dialect Variations</h5>
<div class="ltx_para ltx_noindent" id="A10.SS0.SSS0.Px2.p1">
<p class="ltx_p">While this work concentrated on lexical variations, we welcome future works in this line to carefully study the impacts of grammatical dialect variations and their joint effects with lexical variations. Such research could reveal more complex interactions and failure modes in the performance of multimodal generative models.</p>
</div>
</section>
<section class="ltx_paragraph" id="A10.SS0.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Investigating Downstream Impacts of Dialectal Performance Gaps</h5>
<div class="ltx_para ltx_noindent" id="A10.SS0.SSS0.Px3.p1">
<p class="ltx_p">Many existing studies rely on the accurate semantic understanding and high-fidelity generation capabilities of multimodal text-to-image and text-to-video generative models <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib52" title="">2023</a>); Wallace et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib44" title="">2024</a>); Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.14949v1#bib.bib53" title="">2025</a>)</cite>. It would be interesting to investigate the downstream research impacts of dialectal performance gaps on these works as well as downstream societal impacts to dialect speaker user groups.</p>
</div>
</section>
<section class="ltx_paragraph" id="A10.SS0.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Extending Evaluation to Multi-Lexeme Prompts</h5>
<div class="ltx_para ltx_noindent" id="A10.SS0.SSS0.Px4.p1">
<p class="ltx_p">Another related area for future work is the extension of our evaluation to settings where multiple dialect lexemes are used. This would test the models’ compositional understanding of dialectal language, and we encourage future works to explore such possibilities. However, it should be noted that creating high-quality, controlled data at scale for such experiments is a non-trivial problem that needs to be addressed.</p>
</div>
</section>
<section class="ltx_paragraph" id="A10.SS0.SSS0.Px5">
<h5 class="ltx_title ltx_title_paragraph">Applying the Mitigation Strategy to Text-to-Video Models</h5>
<div class="ltx_para ltx_noindent" id="A10.SS0.SSS0.Px5.p1">
<p class="ltx_p">While our proposed mitigation strategy is designed to be broadly compatible with most multimodal models, it would be interesting to apply our method to text-to-video generative models. Our experiments were limited to text-to-image models due to resource constraints. Therefore, we encourage future researchers with the necessary computing resources to experiment in this domain, as it would serve as a strong test of our method’s generalizability.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Oct 16 17:56:11 2025 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
